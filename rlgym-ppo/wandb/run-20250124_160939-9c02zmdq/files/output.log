Created new wandb run! 9c02zmdq
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 10.00000
Policy Entropy: 4.49957
Value Function Loss:     nan
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11251
Value Function Update Magnitude: 0.12343
Collected Steps per Second: 28633.41139
Overall Steps per Second: 15487.49181
Timestep Collection Time: 1.74789
Timestep Consumption Time: 1.48362
PPO Batch Consumption Time: 0.90348
Total Iteration Time: 3.23151
Cumulative Model Updates: 1
Cumulative Timesteps: 50048
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.27484
Policy Entropy: 4.49956
Value Function Loss: 0.04884
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.16320
Value Function Update Magnitude: 0.20231
Collected Steps per Second: 35710.61555
Overall Steps per Second: 15209.46859
Timestep Collection Time: 1.40115
Timestep Consumption Time: 1.88864
PPO Batch Consumption Time: 0.62188
Total Iteration Time: 3.28979
Cumulative Model Updates: 3
Cumulative Timesteps: 100084
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00719
Policy Entropy: 4.49954
Value Function Loss: 0.03794
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.19822
Value Function Update Magnitude: 0.26625
Collected Steps per Second: 29320.11582
Overall Steps per Second: 11840.59555
Timestep Collection Time: 1.70641
Timestep Consumption Time: 2.51906
PPO Batch Consumption Time: 0.62897
Total Iteration Time: 4.22546
Cumulative Model Updates: 6
Cumulative Timesteps: 150116
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08539
Policy Entropy: 4.49951
Value Function Loss: 0.03728
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.16435
Value Function Update Magnitude: 0.24882
Collected Steps per Second: 36120.13394
Overall Steps per Second: 12930.66843
Timestep Collection Time: 1.38527
Timestep Consumption Time: 2.48429
PPO Batch Consumption Time: 0.63605
Total Iteration Time: 3.86956
Cumulative Model Updates: 9
Cumulative Timesteps: 200152
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17361
Policy Entropy: 4.49947
Value Function Loss: 0.03211
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.14827
Value Function Update Magnitude: 0.24369
Collected Steps per Second: 33424.70849
Overall Steps per Second: 12589.24218
Timestep Collection Time: 1.49746
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.61899
Total Iteration Time: 3.97578
Cumulative Model Updates: 12
Cumulative Timesteps: 250204
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00549
Policy Entropy: 4.49942
Value Function Loss: 0.03098
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.14271
Value Function Update Magnitude: 0.21705
Collected Steps per Second: 29901.29552
Overall Steps per Second: 12043.68110
Timestep Collection Time: 1.67270
Timestep Consumption Time: 2.48018
PPO Batch Consumption Time: 0.63625
Total Iteration Time: 4.15288
Cumulative Model Updates: 15
Cumulative Timesteps: 300220
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00302
Policy Entropy: 4.49937
Value Function Loss: 0.01096
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12722
Value Function Update Magnitude: 0.15436
Collected Steps per Second: 29581.93084
Overall Steps per Second: 11712.29717
Timestep Collection Time: 1.69157
Timestep Consumption Time: 2.58086
PPO Batch Consumption Time: 0.61537
Total Iteration Time: 4.27243
Cumulative Model Updates: 18
Cumulative Timesteps: 350260
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37119
Policy Entropy: 4.49932
Value Function Loss: 0.00735
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10995
Value Function Update Magnitude: 0.11618
Collected Steps per Second: 31716.32328
Overall Steps per Second: 12493.19386
Timestep Collection Time: 1.57698
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.62244
Total Iteration Time: 4.00346
Cumulative Model Updates: 21
Cumulative Timesteps: 400276
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15722
Policy Entropy: 4.49928
Value Function Loss: 0.00467
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09363
Value Function Update Magnitude: 0.09191
Collected Steps per Second: 34690.63715
Overall Steps per Second: 12985.17781
Timestep Collection Time: 1.44212
Timestep Consumption Time: 2.41058
PPO Batch Consumption Time: 0.61913
Total Iteration Time: 3.85270
Cumulative Model Updates: 24
Cumulative Timesteps: 450304
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03470
Policy Entropy: 4.49923
Value Function Loss: 0.00579
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08450
Value Function Update Magnitude: 0.07986
Collected Steps per Second: 33567.31631
Overall Steps per Second: 12577.82859
Timestep Collection Time: 1.49121
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.61514
Total Iteration Time: 3.97970
Cumulative Model Updates: 27
Cumulative Timesteps: 500360
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02214
Policy Entropy: 4.49918
Value Function Loss: 0.00495
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08271
Value Function Update Magnitude: 0.07196
Collected Steps per Second: 28831.91381
Overall Steps per Second: 12043.72697
Timestep Collection Time: 1.73599
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.61339
Total Iteration Time: 4.15586
Cumulative Model Updates: 30
Cumulative Timesteps: 550412
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01123
Policy Entropy: 4.49913
Value Function Loss: 0.00357
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07867
Value Function Update Magnitude: 0.06852
Collected Steps per Second: 32060.75952
Overall Steps per Second: 12281.04226
Timestep Collection Time: 1.56178
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.61680
Total Iteration Time: 4.07718
Cumulative Model Updates: 33
Cumulative Timesteps: 600484
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.34663
Policy Entropy: 4.49910
Value Function Loss: 0.00315
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07144
Value Function Update Magnitude: 0.06590
Collected Steps per Second: 31266.45387
Overall Steps per Second: 12307.31721
Timestep Collection Time: 1.59916
Timestep Consumption Time: 2.46347
PPO Batch Consumption Time: 0.62278
Total Iteration Time: 4.06262
Cumulative Model Updates: 36
Cumulative Timesteps: 650484
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18094
Policy Entropy: 4.49910
Value Function Loss: 0.00639
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07333
Value Function Update Magnitude: 0.05902
Collected Steps per Second: 35528.93959
Overall Steps per Second: 13201.85362
Timestep Collection Time: 1.40730
Timestep Consumption Time: 2.38004
PPO Batch Consumption Time: 0.62099
Total Iteration Time: 3.78735
Cumulative Model Updates: 39
Cumulative Timesteps: 700484
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01365
Policy Entropy: 4.49912
Value Function Loss: 0.00545
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08207
Value Function Update Magnitude: 0.06399
Collected Steps per Second: 32421.71473
Overall Steps per Second: 12307.67916
Timestep Collection Time: 1.54329
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.62572
Total Iteration Time: 4.06543
Cumulative Model Updates: 42
Cumulative Timesteps: 750520
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02041
Policy Entropy: 4.49914
Value Function Loss: 0.00521
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08371
Value Function Update Magnitude: 0.06706
Collected Steps per Second: 35799.14512
Overall Steps per Second: 13219.63590
Timestep Collection Time: 1.39769
Timestep Consumption Time: 2.38729
PPO Batch Consumption Time: 0.61168
Total Iteration Time: 3.78498
Cumulative Model Updates: 45
Cumulative Timesteps: 800556
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15489
Policy Entropy: 4.49914
Value Function Loss: 0.00580
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08027
Value Function Update Magnitude: 0.06784
Collected Steps per Second: 34730.95767
Overall Steps per Second: 12830.06439
Timestep Collection Time: 1.44044
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.39923
Total Iteration Time: 3.89928
Cumulative Model Updates: 48
Cumulative Timesteps: 850584
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01154
Policy Entropy: 4.49912
Value Function Loss: 0.00567
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08738
Value Function Update Magnitude: 0.07571
Collected Steps per Second: 29371.31954
Overall Steps per Second: 12066.85262
Timestep Collection Time: 1.70261
Timestep Consumption Time: 2.44163
PPO Batch Consumption Time: 0.61252
Total Iteration Time: 4.14425
Cumulative Model Updates: 51
Cumulative Timesteps: 900592
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00244
Policy Entropy: 4.49908
Value Function Loss: 0.00424
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09251
Value Function Update Magnitude: 0.07277
Collected Steps per Second: 34884.79162
Overall Steps per Second: 13292.36631
Timestep Collection Time: 1.43386
Timestep Consumption Time: 2.32920
PPO Batch Consumption Time: 0.61118
Total Iteration Time: 3.76306
Cumulative Model Updates: 54
Cumulative Timesteps: 950612
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00333
Policy Entropy: 4.49903
Value Function Loss: 0.00214
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07973
Value Function Update Magnitude: 0.06468
Collected Steps per Second: 33497.25949
Overall Steps per Second: 12453.00894
Timestep Collection Time: 1.49338
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.63239
Total Iteration Time: 4.01702
Cumulative Model Updates: 57
Cumulative Timesteps: 1000636
Timesteps Collected: 50024
--------END ITERATION REPORT--------
Saving checkpoint 1000636...
Checkpoint 1000636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01268
Policy Entropy: 4.49900
Value Function Loss: 0.00290
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07031
Value Function Update Magnitude: 0.06369
Collected Steps per Second: 35242.00505
Overall Steps per Second: 13056.00428
Timestep Collection Time: 1.42103
Timestep Consumption Time: 2.41475
PPO Batch Consumption Time: 0.60407
Total Iteration Time: 3.83578
Cumulative Model Updates: 60
Cumulative Timesteps: 1050716
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06130
Policy Entropy: 4.49900
Value Function Loss: 0.00343
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07316
Value Function Update Magnitude: 0.05758
Collected Steps per Second: 31304.06932
Overall Steps per Second: 12481.31896
Timestep Collection Time: 1.59915
Timestep Consumption Time: 2.41164
PPO Batch Consumption Time: 0.61806
Total Iteration Time: 4.01079
Cumulative Model Updates: 63
Cumulative Timesteps: 1100776
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00683
Policy Entropy: 4.49903
Value Function Loss: 0.00175
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07184
Value Function Update Magnitude: 0.05268
Collected Steps per Second: 33116.79391
Overall Steps per Second: 12590.50810
Timestep Collection Time: 1.51126
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.60358
Total Iteration Time: 3.97506
Cumulative Model Updates: 66
Cumulative Timesteps: 1150824
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01475
Policy Entropy: 4.49907
Value Function Loss: 0.00184
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.05088
Collected Steps per Second: 34500.80577
Overall Steps per Second: 13227.27006
Timestep Collection Time: 1.45052
Timestep Consumption Time: 2.33288
PPO Batch Consumption Time: 0.59669
Total Iteration Time: 3.78340
Cumulative Model Updates: 69
Cumulative Timesteps: 1200868
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01788
Policy Entropy: 4.49913
Value Function Loss: 0.00189
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.05049
Collected Steps per Second: 33583.91935
Overall Steps per Second: 12727.69908
Timestep Collection Time: 1.48905
Timestep Consumption Time: 2.44002
PPO Batch Consumption Time: 0.63367
Total Iteration Time: 3.92907
Cumulative Model Updates: 72
Cumulative Timesteps: 1250876
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14001
Policy Entropy: 4.49918
Value Function Loss: 0.00329
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.05113
Collected Steps per Second: 36007.55333
Overall Steps per Second: 12822.20523
Timestep Collection Time: 1.39060
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.64649
Total Iteration Time: 3.90510
Cumulative Model Updates: 75
Cumulative Timesteps: 1300948
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00027
Policy Entropy: 4.49923
Value Function Loss: 0.00311
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07302
Value Function Update Magnitude: 0.05703
Collected Steps per Second: 33384.64196
Overall Steps per Second: 12385.93987
Timestep Collection Time: 1.49889
Timestep Consumption Time: 2.54117
PPO Batch Consumption Time: 0.66051
Total Iteration Time: 4.04006
Cumulative Model Updates: 78
Cumulative Timesteps: 1350988
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02344
Policy Entropy: 4.49925
Value Function Loss: 0.00235
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.05926
Collected Steps per Second: 34188.15504
Overall Steps per Second: 12483.17272
Timestep Collection Time: 1.46285
Timestep Consumption Time: 2.54351
PPO Batch Consumption Time: 0.63416
Total Iteration Time: 4.00635
Cumulative Model Updates: 81
Cumulative Timesteps: 1401000
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.30928
Policy Entropy: 4.49927
Value Function Loss: 0.00177
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07146
Value Function Update Magnitude: 0.05313
Collected Steps per Second: 36067.07834
Overall Steps per Second: 13087.34572
Timestep Collection Time: 1.38797
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.63655
Total Iteration Time: 3.82507
Cumulative Model Updates: 84
Cumulative Timesteps: 1451060
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21392
Policy Entropy: 4.49931
Value Function Loss: 0.00193
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.05538
Collected Steps per Second: 30072.11973
Overall Steps per Second: 12525.57850
Timestep Collection Time: 1.66440
Timestep Consumption Time: 2.33158
PPO Batch Consumption Time: 0.59938
Total Iteration Time: 3.99598
Cumulative Model Updates: 87
Cumulative Timesteps: 1501112
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.44371
Policy Entropy: 4.49934
Value Function Loss: 0.00340
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.05430
Collected Steps per Second: 32091.23737
Overall Steps per Second: 12468.65410
Timestep Collection Time: 1.56005
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.61529
Total Iteration Time: 4.01519
Cumulative Model Updates: 90
Cumulative Timesteps: 1551176
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00128
Policy Entropy: 4.49938
Value Function Loss: 0.00424
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07887
Value Function Update Magnitude: 0.05403
Collected Steps per Second: 31499.77710
Overall Steps per Second: 12541.43193
Timestep Collection Time: 1.58896
Timestep Consumption Time: 2.40197
PPO Batch Consumption Time: 0.61513
Total Iteration Time: 3.99093
Cumulative Model Updates: 93
Cumulative Timesteps: 1601228
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02308
Policy Entropy: 4.49940
Value Function Loss: 0.00581
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09031
Value Function Update Magnitude: 0.07001
Collected Steps per Second: 34064.89907
Overall Steps per Second: 12783.71659
Timestep Collection Time: 1.46779
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.62657
Total Iteration Time: 3.91123
Cumulative Model Updates: 96
Cumulative Timesteps: 1651228
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00365
Policy Entropy: 4.49939
Value Function Loss: 0.00573
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09990
Value Function Update Magnitude: 0.09110
Collected Steps per Second: 32060.61995
Overall Steps per Second: 12199.02402
Timestep Collection Time: 1.56217
Timestep Consumption Time: 2.54341
PPO Batch Consumption Time: 0.63732
Total Iteration Time: 4.10557
Cumulative Model Updates: 99
Cumulative Timesteps: 1701312
Timesteps Collected: 50084
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12367
Policy Entropy: 4.49935
Value Function Loss: 0.00488
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10190
Value Function Update Magnitude: 0.09095
Collected Steps per Second: 33358.66556
Overall Steps per Second: 13065.88500
Timestep Collection Time: 1.50030
Timestep Consumption Time: 2.33013
PPO Batch Consumption Time: 0.60395
Total Iteration Time: 3.83043
Cumulative Model Updates: 102
Cumulative Timesteps: 1751360
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00625
Policy Entropy: 4.49929
Value Function Loss: 0.00331
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09357
Value Function Update Magnitude: 0.07602
Collected Steps per Second: 35634.86470
Overall Steps per Second: 13056.64330
Timestep Collection Time: 1.40391
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.61256
Total Iteration Time: 3.83161
Cumulative Model Updates: 105
Cumulative Timesteps: 1801388
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01670
Policy Entropy: 4.49923
Value Function Loss: 0.00273
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08690
Value Function Update Magnitude: 0.07840
Collected Steps per Second: 32756.18026
Overall Steps per Second: 12676.68344
Timestep Collection Time: 1.52899
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.62754
Total Iteration Time: 3.95088
Cumulative Model Updates: 108
Cumulative Timesteps: 1851472
Timesteps Collected: 50084
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00464
Policy Entropy: 4.49919
Value Function Loss: 0.00260
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08070
Value Function Update Magnitude: 0.08304
Collected Steps per Second: 30919.41761
Overall Steps per Second: 12081.83207
Timestep Collection Time: 1.61788
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.62420
Total Iteration Time: 4.14043
Cumulative Model Updates: 111
Cumulative Timesteps: 1901496
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00481
Policy Entropy: 4.49919
Value Function Loss: 0.00185
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07566
Value Function Update Magnitude: 0.08083
Collected Steps per Second: 33883.42159
Overall Steps per Second: 12510.64298
Timestep Collection Time: 1.47600
Timestep Consumption Time: 2.52155
PPO Batch Consumption Time: 0.63152
Total Iteration Time: 3.99756
Cumulative Model Updates: 114
Cumulative Timesteps: 1951508
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00051
Policy Entropy: 4.49921
Value Function Loss: 0.00104
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.07422
Collected Steps per Second: 33617.82082
Overall Steps per Second: 12988.35914
Timestep Collection Time: 1.48909
Timestep Consumption Time: 2.36513
PPO Batch Consumption Time: 0.61735
Total Iteration Time: 3.85422
Cumulative Model Updates: 117
Cumulative Timesteps: 2001568
Timesteps Collected: 50060
--------END ITERATION REPORT--------
Saving checkpoint 2001568...
Checkpoint 2001568 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03590
Policy Entropy: 4.49926
Value Function Loss: 0.00104
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.06619
Collected Steps per Second: 36732.90373
Overall Steps per Second: 13165.14822
Timestep Collection Time: 1.36238
Timestep Consumption Time: 2.43887
PPO Batch Consumption Time: 0.62073
Total Iteration Time: 3.80125
Cumulative Model Updates: 120
Cumulative Timesteps: 2051612
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00212
Policy Entropy: 4.49931
Value Function Loss: 0.00104
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.06093
Collected Steps per Second: 31201.43884
Overall Steps per Second: 12439.96453
Timestep Collection Time: 1.60249
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.62432
Total Iteration Time: 4.01930
Cumulative Model Updates: 123
Cumulative Timesteps: 2101612
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02476
Policy Entropy: 4.49935
Value Function Loss: 0.00101
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.05722
Collected Steps per Second: 37911.96639
Overall Steps per Second: 13488.35077
Timestep Collection Time: 1.32011
Timestep Consumption Time: 2.39035
PPO Batch Consumption Time: 0.62538
Total Iteration Time: 3.71046
Cumulative Model Updates: 126
Cumulative Timesteps: 2151660
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13931
Policy Entropy: 4.49939
Value Function Loss: 0.00114
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.05351
Collected Steps per Second: 30587.93417
Overall Steps per Second: 12010.37754
Timestep Collection Time: 1.63529
Timestep Consumption Time: 2.52945
PPO Batch Consumption Time: 0.61005
Total Iteration Time: 4.16473
Cumulative Model Updates: 129
Cumulative Timesteps: 2201680
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01761
Policy Entropy: 4.49942
Value Function Loss: 0.00211
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.05089
Collected Steps per Second: 34843.31672
Overall Steps per Second: 13158.86572
Timestep Collection Time: 1.43580
Timestep Consumption Time: 2.36605
PPO Batch Consumption Time: 0.61212
Total Iteration Time: 3.80185
Cumulative Model Updates: 132
Cumulative Timesteps: 2251708
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26396
Policy Entropy: 4.49945
Value Function Loss: 0.00410
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.05444
Collected Steps per Second: 34373.03601
Overall Steps per Second: 12919.97096
Timestep Collection Time: 1.45521
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.61544
Total Iteration Time: 3.87153
Cumulative Model Updates: 135
Cumulative Timesteps: 2301728
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03266
Policy Entropy: 4.49949
Value Function Loss: 0.00386
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07710
Value Function Update Magnitude: 0.05966
Collected Steps per Second: 33849.39716
Overall Steps per Second: 13083.80979
Timestep Collection Time: 1.47855
Timestep Consumption Time: 2.34664
PPO Batch Consumption Time: 0.60596
Total Iteration Time: 3.82519
Cumulative Model Updates: 138
Cumulative Timesteps: 2351776
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00957
Policy Entropy: 4.49951
Value Function Loss: 0.00290
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08055
Value Function Update Magnitude: 0.05763
Collected Steps per Second: 33693.97766
Overall Steps per Second: 13163.23344
Timestep Collection Time: 1.48418
Timestep Consumption Time: 2.31488
PPO Batch Consumption Time: 0.60115
Total Iteration Time: 3.79907
Cumulative Model Updates: 141
Cumulative Timesteps: 2401784
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09762
Policy Entropy: 4.49952
Value Function Loss: 0.00297
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07600
Value Function Update Magnitude: 0.05242
Collected Steps per Second: 32382.09196
Overall Steps per Second: 12281.00025
Timestep Collection Time: 1.54579
Timestep Consumption Time: 2.53010
PPO Batch Consumption Time: 0.62992
Total Iteration Time: 4.07589
Cumulative Model Updates: 144
Cumulative Timesteps: 2451840
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16084
Policy Entropy: 4.49953
Value Function Loss: 0.00412
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07657
Value Function Update Magnitude: 0.05623
Collected Steps per Second: 32900.41014
Overall Steps per Second: 12948.67000
Timestep Collection Time: 1.52095
Timestep Consumption Time: 2.34354
PPO Batch Consumption Time: 0.60101
Total Iteration Time: 3.86449
Cumulative Model Updates: 147
Cumulative Timesteps: 2501880
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02206
Policy Entropy: 4.49953
Value Function Loss: 0.00501
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08933
Value Function Update Magnitude: 0.06988
Collected Steps per Second: 33156.54620
Overall Steps per Second: 12759.50729
Timestep Collection Time: 1.50908
Timestep Consumption Time: 2.41238
PPO Batch Consumption Time: 0.59770
Total Iteration Time: 3.92147
Cumulative Model Updates: 150
Cumulative Timesteps: 2551916
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00034
Policy Entropy: 4.49953
Value Function Loss: 0.00485
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09434
Value Function Update Magnitude: 0.08093
Collected Steps per Second: 36546.94077
Overall Steps per Second: 13672.43128
Timestep Collection Time: 1.36953
Timestep Consumption Time: 2.29127
PPO Batch Consumption Time: 0.60433
Total Iteration Time: 3.66080
Cumulative Model Updates: 153
Cumulative Timesteps: 2601968
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00037
Policy Entropy: 4.49951
Value Function Loss: 0.00394
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09381
Value Function Update Magnitude: 0.08193
Collected Steps per Second: 36560.94664
Overall Steps per Second: 13533.18684
Timestep Collection Time: 1.36813
Timestep Consumption Time: 2.32797
PPO Batch Consumption Time: 0.61138
Total Iteration Time: 3.69610
Cumulative Model Updates: 156
Cumulative Timesteps: 2651988
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01724
Policy Entropy: 4.49949
Value Function Loss: 0.00302
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09254
Value Function Update Magnitude: 0.07563
Collected Steps per Second: 38050.41610
Overall Steps per Second: 13557.16068
Timestep Collection Time: 1.31405
Timestep Consumption Time: 2.37404
PPO Batch Consumption Time: 0.61044
Total Iteration Time: 3.68809
Cumulative Model Updates: 159
Cumulative Timesteps: 2701988
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00927
Policy Entropy: 4.49946
Value Function Loss: 0.00213
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08302
Value Function Update Magnitude: 0.07656
Collected Steps per Second: 37525.70144
Overall Steps per Second: 13794.56575
Timestep Collection Time: 1.33327
Timestep Consumption Time: 2.29366
PPO Batch Consumption Time: 0.59886
Total Iteration Time: 3.62694
Cumulative Model Updates: 162
Cumulative Timesteps: 2752020
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00294
Policy Entropy: 4.49943
Value Function Loss: 0.00113
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07181
Value Function Update Magnitude: 0.07728
Collected Steps per Second: 37149.34617
Overall Steps per Second: 13253.61793
Timestep Collection Time: 1.34635
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.61727
Total Iteration Time: 3.77376
Cumulative Model Updates: 165
Cumulative Timesteps: 2802036
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00776
Policy Entropy: 4.49939
Value Function Loss: 0.00108
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06639
Value Function Update Magnitude: 0.07381
Collected Steps per Second: 39972.06188
Overall Steps per Second: 13677.21707
Timestep Collection Time: 1.25117
Timestep Consumption Time: 2.40542
PPO Batch Consumption Time: 0.61118
Total Iteration Time: 3.65659
Cumulative Model Updates: 168
Cumulative Timesteps: 2852048
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01999
Policy Entropy: 4.49937
Value Function Loss: 0.00015
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.06713
Collected Steps per Second: 35100.38137
Overall Steps per Second: 13256.72660
Timestep Collection Time: 1.42449
Timestep Consumption Time: 2.34718
PPO Batch Consumption Time: 0.61258
Total Iteration Time: 3.77167
Cumulative Model Updates: 171
Cumulative Timesteps: 2902048
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00063
Policy Entropy: 4.49936
Value Function Loss: 0.00217
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.05266
Collected Steps per Second: 36086.96516
Overall Steps per Second: 13307.63498
Timestep Collection Time: 1.38554
Timestep Consumption Time: 2.37170
PPO Batch Consumption Time: 0.60318
Total Iteration Time: 3.75724
Cumulative Model Updates: 174
Cumulative Timesteps: 2952048
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05178
Policy Entropy: 4.49936
Value Function Loss: 0.00318
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.04742
Collected Steps per Second: 31936.29617
Overall Steps per Second: 12678.24209
Timestep Collection Time: 1.56562
Timestep Consumption Time: 2.37815
PPO Batch Consumption Time: 0.61207
Total Iteration Time: 3.94376
Cumulative Model Updates: 177
Cumulative Timesteps: 3002048
Timesteps Collected: 50000
--------END ITERATION REPORT--------
Saving checkpoint 3002048...
Checkpoint 3002048 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01093
Policy Entropy: 4.49937
Value Function Loss: 0.00518
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08265
Value Function Update Magnitude: 0.06241
Collected Steps per Second: 34995.29889
Overall Steps per Second: 12841.63731
Timestep Collection Time: 1.43002
Timestep Consumption Time: 2.46699
PPO Batch Consumption Time: 0.61091
Total Iteration Time: 3.89701
Cumulative Model Updates: 180
Cumulative Timesteps: 3052092
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01482
Policy Entropy: 4.49938
Value Function Loss: 0.00314
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08999
Value Function Update Magnitude: 0.06805
Collected Steps per Second: 38917.75156
Overall Steps per Second: 13637.61821
Timestep Collection Time: 1.28641
Timestep Consumption Time: 2.38462
PPO Batch Consumption Time: 0.60720
Total Iteration Time: 3.67102
Cumulative Model Updates: 183
Cumulative Timesteps: 3102156
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04394
Policy Entropy: 4.49937
Value Function Loss: 0.00421
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09200
Value Function Update Magnitude: 0.06588
Collected Steps per Second: 36450.13736
Overall Steps per Second: 13530.09015
Timestep Collection Time: 1.37218
Timestep Consumption Time: 2.32447
PPO Batch Consumption Time: 0.60471
Total Iteration Time: 3.69665
Cumulative Model Updates: 186
Cumulative Timesteps: 3152172
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00483
Policy Entropy: 4.49934
Value Function Loss: 0.00229
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08839
Value Function Update Magnitude: 0.05681
Collected Steps per Second: 37708.37125
Overall Steps per Second: 13452.23579
Timestep Collection Time: 1.32745
Timestep Consumption Time: 2.39357
PPO Batch Consumption Time: 0.60758
Total Iteration Time: 3.72102
Cumulative Model Updates: 189
Cumulative Timesteps: 3202228
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00114
Policy Entropy: 4.49932
Value Function Loss: 0.00222
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08843
Value Function Update Magnitude: 0.05650
Collected Steps per Second: 40304.21388
Overall Steps per Second: 13762.94335
Timestep Collection Time: 1.24057
Timestep Consumption Time: 2.39238
PPO Batch Consumption Time: 0.60668
Total Iteration Time: 3.63294
Cumulative Model Updates: 192
Cumulative Timesteps: 3252228
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02863
Policy Entropy: 4.49929
Value Function Loss: 0.00217
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07798
Value Function Update Magnitude: 0.05301
Collected Steps per Second: 37343.49365
Overall Steps per Second: 13595.81330
Timestep Collection Time: 1.33935
Timestep Consumption Time: 2.33943
PPO Batch Consumption Time: 0.60150
Total Iteration Time: 3.67878
Cumulative Model Updates: 195
Cumulative Timesteps: 3302244
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00518
Policy Entropy: 4.49927
Value Function Loss: 0.00213
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07405
Value Function Update Magnitude: 0.05426
Collected Steps per Second: 36618.32392
Overall Steps per Second: 13324.36335
Timestep Collection Time: 1.36708
Timestep Consumption Time: 2.38995
PPO Batch Consumption Time: 0.61522
Total Iteration Time: 3.75703
Cumulative Model Updates: 198
Cumulative Timesteps: 3352304
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04795
Policy Entropy: 4.49926
Value Function Loss: 0.00413
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08440
Value Function Update Magnitude: 0.06273
Collected Steps per Second: 38314.90814
Overall Steps per Second: 13777.64674
Timestep Collection Time: 1.30633
Timestep Consumption Time: 2.32651
PPO Batch Consumption Time: 0.61271
Total Iteration Time: 3.63284
Cumulative Model Updates: 201
Cumulative Timesteps: 3402356
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01599
Policy Entropy: 4.49924
Value Function Loss: 0.00315
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08645
Value Function Update Magnitude: 0.06326
Collected Steps per Second: 36890.93338
Overall Steps per Second: 13366.91532
Timestep Collection Time: 1.35545
Timestep Consumption Time: 2.38542
PPO Batch Consumption Time: 0.60813
Total Iteration Time: 3.74088
Cumulative Model Updates: 204
Cumulative Timesteps: 3452360
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01042
Policy Entropy: 4.49920
Value Function Loss: 0.00314
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09037
Value Function Update Magnitude: 0.06682
Collected Steps per Second: 39166.45662
Overall Steps per Second: 13665.84932
Timestep Collection Time: 1.27660
Timestep Consumption Time: 2.38215
PPO Batch Consumption Time: 0.60768
Total Iteration Time: 3.65876
Cumulative Model Updates: 207
Cumulative Timesteps: 3502360
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00023
Policy Entropy: 4.49916
Value Function Loss: 0.00114
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08484
Value Function Update Magnitude: 0.06210
Collected Steps per Second: 34330.54056
Overall Steps per Second: 13177.50639
Timestep Collection Time: 1.45690
Timestep Consumption Time: 2.33866
PPO Batch Consumption Time: 0.60914
Total Iteration Time: 3.79556
Cumulative Model Updates: 210
Cumulative Timesteps: 3552376
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00209
Policy Entropy: 4.49914
Value Function Loss: 0.00015
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06746
Value Function Update Magnitude: 0.05582
Collected Steps per Second: 37506.45320
Overall Steps per Second: 13326.10230
Timestep Collection Time: 1.33321
Timestep Consumption Time: 2.41912
PPO Batch Consumption Time: 0.61573
Total Iteration Time: 3.75233
Cumulative Model Updates: 213
Cumulative Timesteps: 3602380
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05532
Policy Entropy: 4.49915
Value Function Loss: 0.00221
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.04980
Collected Steps per Second: 40052.03120
Overall Steps per Second: 13605.83309
Timestep Collection Time: 1.24908
Timestep Consumption Time: 2.42788
PPO Batch Consumption Time: 0.62052
Total Iteration Time: 3.67695
Cumulative Model Updates: 216
Cumulative Timesteps: 3652408
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01652
Policy Entropy: 4.49920
Value Function Loss: 0.00321
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06935
Value Function Update Magnitude: 0.05060
Collected Steps per Second: 26389.81454
Overall Steps per Second: 11498.97029
Timestep Collection Time: 1.89679
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.62133
Total Iteration Time: 4.35309
Cumulative Model Updates: 219
Cumulative Timesteps: 3702464
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01315
Policy Entropy: 4.49927
Value Function Loss: 0.00319
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08589
Value Function Update Magnitude: 0.06330
Collected Steps per Second: 30740.68037
Overall Steps per Second: 12041.99179
Timestep Collection Time: 1.62911
Timestep Consumption Time: 2.52967
PPO Batch Consumption Time: 0.61694
Total Iteration Time: 4.15878
Cumulative Model Updates: 222
Cumulative Timesteps: 3752544
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00239
Policy Entropy: 4.49934
Value Function Loss: 0.00113
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08309
Value Function Update Magnitude: 0.06065
Collected Steps per Second: 33089.54760
Overall Steps per Second: 12942.09404
Timestep Collection Time: 1.51178
Timestep Consumption Time: 2.35344
PPO Batch Consumption Time: 0.61149
Total Iteration Time: 3.86522
Cumulative Model Updates: 225
Cumulative Timesteps: 3802568
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01315
Policy Entropy: 4.49939
Value Function Loss: 0.00020
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06867
Value Function Update Magnitude: 0.05956
Collected Steps per Second: 33131.40804
Overall Steps per Second: 12760.45501
Timestep Collection Time: 1.51035
Timestep Consumption Time: 2.41114
PPO Batch Consumption Time: 0.60837
Total Iteration Time: 3.92149
Cumulative Model Updates: 228
Cumulative Timesteps: 3852608
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14669
Policy Entropy: 4.49944
Value Function Loss: 0.00315
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.05198
Collected Steps per Second: 38858.51013
Overall Steps per Second: 13301.23874
Timestep Collection Time: 1.28785
Timestep Consumption Time: 2.47450
PPO Batch Consumption Time: 0.62158
Total Iteration Time: 3.76236
Cumulative Model Updates: 231
Cumulative Timesteps: 3902652
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00292
Policy Entropy: 4.49948
Value Function Loss: 0.00312
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07617
Value Function Update Magnitude: 0.06162
Collected Steps per Second: 29817.89188
Overall Steps per Second: 11971.74309
Timestep Collection Time: 1.67698
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.63127
Total Iteration Time: 4.17684
Cumulative Model Updates: 234
Cumulative Timesteps: 3952656
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00398
Policy Entropy: 4.49952
Value Function Loss: 0.00462
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08864
Value Function Update Magnitude: 0.08549
Collected Steps per Second: 31111.86746
Overall Steps per Second: 12052.27249
Timestep Collection Time: 1.60723
Timestep Consumption Time: 2.54169
PPO Batch Consumption Time: 0.62980
Total Iteration Time: 4.14893
Cumulative Model Updates: 237
Cumulative Timesteps: 4002660
Timesteps Collected: 50004
--------END ITERATION REPORT--------
Saving checkpoint 4002660...
Checkpoint 4002660 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01674
Policy Entropy: 4.49953
Value Function Loss: 0.00273
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08773
Value Function Update Magnitude: 0.08315
Collected Steps per Second: 38116.10075
Overall Steps per Second: 13512.80160
Timestep Collection Time: 1.31262
Timestep Consumption Time: 2.38994
PPO Batch Consumption Time: 0.60384
Total Iteration Time: 3.70256
Cumulative Model Updates: 240
Cumulative Timesteps: 4052692
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01162
Policy Entropy: 4.49954
Value Function Loss: 0.00384
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08961
Value Function Update Magnitude: 0.08280
Collected Steps per Second: 36693.56265
Overall Steps per Second: 13597.44773
Timestep Collection Time: 1.36438
Timestep Consumption Time: 2.31749
PPO Batch Consumption Time: 0.60879
Total Iteration Time: 3.68187
Cumulative Model Updates: 243
Cumulative Timesteps: 4102756
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00996
Policy Entropy: 4.49954
Value Function Loss: 0.00231
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09007
Value Function Update Magnitude: 0.08899
Collected Steps per Second: 37921.48204
Overall Steps per Second: 13389.26611
Timestep Collection Time: 1.31946
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.61805
Total Iteration Time: 3.73702
Cumulative Model Updates: 246
Cumulative Timesteps: 4152792
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00494
Policy Entropy: 4.49953
Value Function Loss: 0.00237
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08442
Value Function Update Magnitude: 0.08833
Collected Steps per Second: 33886.88410
Overall Steps per Second: 12495.66158
Timestep Collection Time: 1.47750
Timestep Consumption Time: 2.52933
PPO Batch Consumption Time: 0.62321
Total Iteration Time: 4.00683
Cumulative Model Updates: 249
Cumulative Timesteps: 4202860
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03857
Policy Entropy: 4.49951
Value Function Loss: 0.00427
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07955
Value Function Update Magnitude: 0.07792
Collected Steps per Second: 28404.46563
Overall Steps per Second: 11761.10550
Timestep Collection Time: 1.76184
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.61310
Total Iteration Time: 4.25504
Cumulative Model Updates: 252
Cumulative Timesteps: 4252904
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00358
Policy Entropy: 4.49948
Value Function Loss: 0.00517
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09211
Value Function Update Magnitude: 0.09924
Collected Steps per Second: 31428.35700
Overall Steps per Second: 12110.59487
Timestep Collection Time: 1.59321
Timestep Consumption Time: 2.54135
PPO Batch Consumption Time: 0.62882
Total Iteration Time: 4.13456
Cumulative Model Updates: 255
Cumulative Timesteps: 4302976
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21620
Policy Entropy: 4.49942
Value Function Loss: 0.00663
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10389
Value Function Update Magnitude: 0.12967
Collected Steps per Second: 24709.26693
Overall Steps per Second: 10746.50209
Timestep Collection Time: 2.02645
Timestep Consumption Time: 2.63293
PPO Batch Consumption Time: 0.63053
Total Iteration Time: 4.65938
Cumulative Model Updates: 258
Cumulative Timesteps: 4353048
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00043
Policy Entropy: 4.49936
Value Function Loss: 0.00405
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10728
Value Function Update Magnitude: 0.12390
Collected Steps per Second: 31576.58856
Overall Steps per Second: 12213.53700
Timestep Collection Time: 1.58421
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.62042
Total Iteration Time: 4.09578
Cumulative Model Updates: 261
Cumulative Timesteps: 4403072
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.34372
Policy Entropy: 4.49931
Value Function Loss: 0.00483
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10864
Value Function Update Magnitude: 0.12493
Collected Steps per Second: 28988.74922
Overall Steps per Second: 11997.10555
Timestep Collection Time: 1.72563
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.61988
Total Iteration Time: 4.16967
Cumulative Model Updates: 264
Cumulative Timesteps: 4453096
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00750
Policy Entropy: 4.49924
Value Function Loss: 0.00411
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10396
Value Function Update Magnitude: 0.12071
Collected Steps per Second: 32281.30383
Overall Steps per Second: 12466.01638
Timestep Collection Time: 1.54975
Timestep Consumption Time: 2.46340
PPO Batch Consumption Time: 0.62888
Total Iteration Time: 4.01315
Cumulative Model Updates: 267
Cumulative Timesteps: 4503124
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05613
Policy Entropy: 4.49915
Value Function Loss: 0.00567
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11000
Value Function Update Magnitude: 0.13348
Collected Steps per Second: 33336.71415
Overall Steps per Second: 12484.77879
Timestep Collection Time: 1.50093
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.63108
Total Iteration Time: 4.00776
Cumulative Model Updates: 270
Cumulative Timesteps: 4553160
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01372
Policy Entropy: 4.49906
Value Function Loss: 0.00501
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11227
Value Function Update Magnitude: 0.13927
Collected Steps per Second: 29642.50889
Overall Steps per Second: 12013.54408
Timestep Collection Time: 1.68704
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.62595
Total Iteration Time: 4.16264
Cumulative Model Updates: 273
Cumulative Timesteps: 4603168
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00862
Policy Entropy: 4.49898
Value Function Loss: 0.00424
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11135
Value Function Update Magnitude: 0.12257
Collected Steps per Second: 28593.51178
Overall Steps per Second: 11722.75291
Timestep Collection Time: 1.74963
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.62367
Total Iteration Time: 4.26760
Cumulative Model Updates: 276
Cumulative Timesteps: 4653196
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00553
Policy Entropy: 4.49895
Value Function Loss: 0.00251
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10608
Value Function Update Magnitude: 0.11652
Collected Steps per Second: 29038.20615
Overall Steps per Second: 11766.49291
Timestep Collection Time: 1.72435
Timestep Consumption Time: 2.53112
PPO Batch Consumption Time: 0.61502
Total Iteration Time: 4.25547
Cumulative Model Updates: 279
Cumulative Timesteps: 4703268
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00094
Policy Entropy: 4.49895
Value Function Loss: 0.00327
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09563
Value Function Update Magnitude: 0.10070
Collected Steps per Second: 27876.89027
Overall Steps per Second: 11693.50626
Timestep Collection Time: 1.79489
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.62160
Total Iteration Time: 4.27896
Cumulative Model Updates: 282
Cumulative Timesteps: 4753304
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25163
Policy Entropy: 4.49898
Value Function Loss: 0.00511
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09396
Value Function Update Magnitude: 0.10916
Collected Steps per Second: 21724.90911
Overall Steps per Second: 10390.89746
Timestep Collection Time: 2.30169
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.62262
Total Iteration Time: 4.81229
Cumulative Model Updates: 285
Cumulative Timesteps: 4803308
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01352
Policy Entropy: 4.49898
Value Function Loss: 0.00619
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10720
Value Function Update Magnitude: 0.12598
Collected Steps per Second: 23228.79073
Overall Steps per Second: 10604.70778
Timestep Collection Time: 2.15250
Timestep Consumption Time: 2.56239
PPO Batch Consumption Time: 0.63000
Total Iteration Time: 4.71489
Cumulative Model Updates: 288
Cumulative Timesteps: 4853308
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03694
Policy Entropy: 4.49893
Value Function Loss: 0.00605
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11790
Value Function Update Magnitude: 0.13090
Collected Steps per Second: 12569.44583
Overall Steps per Second: 7040.36717
Timestep Collection Time: 3.97885
Timestep Consumption Time: 3.12475
PPO Batch Consumption Time: 0.76991
Total Iteration Time: 7.10361
Cumulative Model Updates: 291
Cumulative Timesteps: 4903320
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00874
Policy Entropy: 4.49885
Value Function Loss: 0.00401
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11865
Value Function Update Magnitude: 0.13417
Collected Steps per Second: 18822.58129
Overall Steps per Second: 7591.28458
Timestep Collection Time: 2.65978
Timestep Consumption Time: 3.93515
PPO Batch Consumption Time: 0.98774
Total Iteration Time: 6.59493
Cumulative Model Updates: 294
Cumulative Timesteps: 4953384
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01092
Policy Entropy: 4.49879
Value Function Loss: 0.00372
Mean KL Divergence: 0.00005
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11270
Value Function Update Magnitude: 0.12837
Collected Steps per Second: 18672.87973
Overall Steps per Second: 7586.92535
Timestep Collection Time: 2.68239
Timestep Consumption Time: 3.91949
PPO Batch Consumption Time: 1.08112
Total Iteration Time: 6.60188
Cumulative Model Updates: 297
Cumulative Timesteps: 5003472
Timesteps Collected: 50088
--------END ITERATION REPORT--------
Saving checkpoint 5003472...
Checkpoint 5003472 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03709
Policy Entropy: 4.49876
Value Function Loss: 0.00340
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10699
Value Function Update Magnitude: 0.12541
Collected Steps per Second: 19149.40277
Overall Steps per Second: 7938.80661
Timestep Collection Time: 2.61105
Timestep Consumption Time: 3.68713
PPO Batch Consumption Time: 0.97356
Total Iteration Time: 6.29818
Cumulative Model Updates: 300
Cumulative Timesteps: 5053472
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00162
Policy Entropy: 4.49879
Value Function Loss: 0.00308
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10431
Value Function Update Magnitude: 0.13103
Collected Steps per Second: 21242.30251
Overall Steps per Second: 8299.12053
Timestep Collection Time: 2.35492
Timestep Consumption Time: 3.67270
PPO Batch Consumption Time: 0.99503
Total Iteration Time: 6.02763
Cumulative Model Updates: 303
Cumulative Timesteps: 5103496
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.34389
Policy Entropy: 4.49885
Value Function Loss: 0.00301
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10521
Value Function Update Magnitude: 0.13167
Collected Steps per Second: 20616.48324
Overall Steps per Second: 8326.40865
Timestep Collection Time: 2.42718
Timestep Consumption Time: 3.58261
PPO Batch Consumption Time: 0.98728
Total Iteration Time: 6.00979
Cumulative Model Updates: 306
Cumulative Timesteps: 5153536
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00000
Policy Entropy: 4.49893
Value Function Loss: 0.00133
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09450
Value Function Update Magnitude: 0.12028
Collected Steps per Second: 21224.61510
Overall Steps per Second: 9910.97420
Timestep Collection Time: 2.35689
Timestep Consumption Time: 2.69045
PPO Batch Consumption Time: 0.63846
Total Iteration Time: 5.04733
Cumulative Model Updates: 309
Cumulative Timesteps: 5203560
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06058
Policy Entropy: 4.49901
Value Function Loss: 0.00229
Mean KL Divergence: 0.00004
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08926
Value Function Update Magnitude: 0.11257
Collected Steps per Second: 29483.41460
Overall Steps per Second: 10529.00863
Timestep Collection Time: 1.69763
Timestep Consumption Time: 3.05609
PPO Batch Consumption Time: 0.81778
Total Iteration Time: 4.75372
Cumulative Model Updates: 312
Cumulative Timesteps: 5253612
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06657
Policy Entropy: 4.49909
Value Function Loss: 0.00217
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08315
Value Function Update Magnitude: 0.09339
Collected Steps per Second: 19853.24729
Overall Steps per Second: 7853.18777
Timestep Collection Time: 2.52049
Timestep Consumption Time: 3.85144
PPO Batch Consumption Time: 1.04749
Total Iteration Time: 6.37193
Cumulative Model Updates: 315
Cumulative Timesteps: 5303652
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00680
Policy Entropy: 4.49915
Value Function Loss: 0.00307
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08597
Value Function Update Magnitude: 0.09243
Collected Steps per Second: 21462.78222
Overall Steps per Second: 8079.88176
Timestep Collection Time: 2.33129
Timestep Consumption Time: 3.86137
PPO Batch Consumption Time: 1.05177
Total Iteration Time: 6.19266
Cumulative Model Updates: 318
Cumulative Timesteps: 5353688
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14839
Policy Entropy: 4.49918
Value Function Loss: 0.00376
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08726
Value Function Update Magnitude: 0.11635
Collected Steps per Second: 19868.34449
Overall Steps per Second: 7920.06782
Timestep Collection Time: 2.51677
Timestep Consumption Time: 3.79681
PPO Batch Consumption Time: 1.05363
Total Iteration Time: 6.31358
Cumulative Model Updates: 321
Cumulative Timesteps: 5403692
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02760
Policy Entropy: 4.49916
Value Function Loss: 0.00405
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09251
Value Function Update Magnitude: 0.11198
Collected Steps per Second: 19601.44221
Overall Steps per Second: 7548.79830
Timestep Collection Time: 2.55287
Timestep Consumption Time: 4.07600
PPO Batch Consumption Time: 0.87541
Total Iteration Time: 6.62887
Cumulative Model Updates: 324
Cumulative Timesteps: 5453732
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01024
Policy Entropy: 4.49914
Value Function Loss: 0.00320
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09499
Value Function Update Magnitude: 0.12180
Collected Steps per Second: 20542.92954
Overall Steps per Second: 8109.58211
Timestep Collection Time: 2.43763
Timestep Consumption Time: 3.73729
PPO Batch Consumption Time: 1.03214
Total Iteration Time: 6.17492
Cumulative Model Updates: 327
Cumulative Timesteps: 5503808
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01324
Policy Entropy: 4.49912
Value Function Loss: 0.00224
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08949
Value Function Update Magnitude: 0.11678
Collected Steps per Second: 20316.09050
Overall Steps per Second: 8223.59724
Timestep Collection Time: 2.46307
Timestep Consumption Time: 3.62186
PPO Batch Consumption Time: 0.99143
Total Iteration Time: 6.08493
Cumulative Model Updates: 330
Cumulative Timesteps: 5553848
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00064
Policy Entropy: 4.49913
Value Function Loss: 0.00117
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07711
Value Function Update Magnitude: 0.09306
Collected Steps per Second: 21951.61491
Overall Steps per Second: 8250.31361
Timestep Collection Time: 2.27828
Timestep Consumption Time: 3.78355
PPO Batch Consumption Time: 1.02588
Total Iteration Time: 6.06183
Cumulative Model Updates: 333
Cumulative Timesteps: 5603860
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.35182
Policy Entropy: 4.49917
Value Function Loss: 0.00201
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07184
Value Function Update Magnitude: 0.07549
Collected Steps per Second: 20079.81665
Overall Steps per Second: 8404.36948
Timestep Collection Time: 2.49026
Timestep Consumption Time: 3.45950
PPO Batch Consumption Time: 0.93479
Total Iteration Time: 5.94976
Cumulative Model Updates: 336
Cumulative Timesteps: 5653864
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00690
Policy Entropy: 4.49922
Value Function Loss: 0.00220
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07240
Value Function Update Magnitude: 0.07860
Collected Steps per Second: 22902.63139
Overall Steps per Second: 8843.22451
Timestep Collection Time: 2.18560
Timestep Consumption Time: 3.47478
PPO Batch Consumption Time: 0.92566
Total Iteration Time: 5.66038
Cumulative Model Updates: 339
Cumulative Timesteps: 5703920
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00361
Policy Entropy: 4.49929
Value Function Loss: 0.00316
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08074
Value Function Update Magnitude: 0.09269
Collected Steps per Second: 23029.82720
Overall Steps per Second: 8404.16201
Timestep Collection Time: 2.17197
Timestep Consumption Time: 3.77985
PPO Batch Consumption Time: 1.05940
Total Iteration Time: 5.95181
Cumulative Model Updates: 342
Cumulative Timesteps: 5753940
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02477
Policy Entropy: 4.49934
Value Function Loss: 0.00320
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08742
Value Function Update Magnitude: 0.09723
Collected Steps per Second: 18395.16675
Overall Steps per Second: 7371.93330
Timestep Collection Time: 2.72006
Timestep Consumption Time: 4.06730
PPO Batch Consumption Time: 1.13044
Total Iteration Time: 6.78736
Cumulative Model Updates: 345
Cumulative Timesteps: 5803976
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06749
Policy Entropy: 4.49938
Value Function Loss: 0.00584
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09243
Value Function Update Magnitude: 0.12579
Collected Steps per Second: 20182.42229
Overall Steps per Second: 7788.81477
Timestep Collection Time: 2.47939
Timestep Consumption Time: 3.94521
PPO Batch Consumption Time: 1.06537
Total Iteration Time: 6.42460
Cumulative Model Updates: 348
Cumulative Timesteps: 5854016
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.24614
Policy Entropy: 4.49941
Value Function Loss: 0.00665
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10326
Value Function Update Magnitude: 0.13695
Collected Steps per Second: 19711.60027
Overall Steps per Second: 7803.78407
Timestep Collection Time: 2.53861
Timestep Consumption Time: 3.87367
PPO Batch Consumption Time: 1.06535
Total Iteration Time: 6.41227
Cumulative Model Updates: 351
Cumulative Timesteps: 5904056
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00702
Policy Entropy: 4.49943
Value Function Loss: 0.00660
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11789
Value Function Update Magnitude: 0.14836
Collected Steps per Second: 19986.29911
Overall Steps per Second: 7771.91928
Timestep Collection Time: 2.50392
Timestep Consumption Time: 3.93516
PPO Batch Consumption Time: 1.05770
Total Iteration Time: 6.43908
Cumulative Model Updates: 354
Cumulative Timesteps: 5954100
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00016
Policy Entropy: 4.49941
Value Function Loss: 0.00425
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11372
Value Function Update Magnitude: 0.14954
Collected Steps per Second: 21584.04794
Overall Steps per Second: 8045.06896
Timestep Collection Time: 2.31653
Timestep Consumption Time: 3.89846
PPO Batch Consumption Time: 1.06074
Total Iteration Time: 6.21499
Cumulative Model Updates: 357
Cumulative Timesteps: 6004100
Timesteps Collected: 50000
--------END ITERATION REPORT--------
Saving checkpoint 6004100...
Checkpoint 6004100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03426
Policy Entropy: 4.49938
Value Function Loss: 0.00230
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10233
Value Function Update Magnitude: 0.13267
Collected Steps per Second: 20419.60498
Overall Steps per Second: 8141.72635
Timestep Collection Time: 2.45000
Timestep Consumption Time: 3.69464
PPO Batch Consumption Time: 1.02289
Total Iteration Time: 6.14464
Cumulative Model Updates: 360
Cumulative Timesteps: 6054128
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02150
Policy Entropy: 4.49934
Value Function Loss: 0.00224
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09119
Value Function Update Magnitude: 0.11039
Collected Steps per Second: 20766.77121
Overall Steps per Second: 7913.13595
Timestep Collection Time: 2.40904
Timestep Consumption Time: 3.91311
PPO Batch Consumption Time: 1.05780
Total Iteration Time: 6.32215
Cumulative Model Updates: 363
Cumulative Timesteps: 6104156
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23959
Policy Entropy: 4.49931
Value Function Loss: 0.00319
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08361
Value Function Update Magnitude: 0.10270
Collected Steps per Second: 20323.12337
Overall Steps per Second: 7826.01939
Timestep Collection Time: 2.46124
Timestep Consumption Time: 3.93026
PPO Batch Consumption Time: 1.06651
Total Iteration Time: 6.39150
Cumulative Model Updates: 366
Cumulative Timesteps: 6154176
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06492
Policy Entropy: 4.49929
Value Function Loss: 0.00414
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09158
Value Function Update Magnitude: 0.11232
Collected Steps per Second: 18475.58899
Overall Steps per Second: 7783.16808
Timestep Collection Time: 2.70801
Timestep Consumption Time: 3.72023
PPO Batch Consumption Time: 1.02339
Total Iteration Time: 6.42823
Cumulative Model Updates: 369
Cumulative Timesteps: 6204208
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00462
Policy Entropy: 4.49927
Value Function Loss: 0.00407
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09881
Value Function Update Magnitude: 0.12293
Collected Steps per Second: 20474.59746
Overall Steps per Second: 7957.25085
Timestep Collection Time: 2.44283
Timestep Consumption Time: 3.84276
PPO Batch Consumption Time: 1.04268
Total Iteration Time: 6.28559
Cumulative Model Updates: 372
Cumulative Timesteps: 6254224
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02717
Policy Entropy: 4.49926
Value Function Loss: 0.00389
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09757
Value Function Update Magnitude: 0.12225
Collected Steps per Second: 20032.92060
Overall Steps per Second: 7867.58442
Timestep Collection Time: 2.49829
Timestep Consumption Time: 3.86300
PPO Batch Consumption Time: 1.05508
Total Iteration Time: 6.36129
Cumulative Model Updates: 375
Cumulative Timesteps: 6304272
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00043
Policy Entropy: 4.49924
Value Function Loss: 0.00379
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09549
Value Function Update Magnitude: 0.13484
Collected Steps per Second: 19321.66032
Overall Steps per Second: 7808.95658
Timestep Collection Time: 2.58984
Timestep Consumption Time: 3.81819
PPO Batch Consumption Time: 1.05936
Total Iteration Time: 6.40803
Cumulative Model Updates: 378
Cumulative Timesteps: 6354312
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01063
Policy Entropy: 4.49925
Value Function Loss: 0.00423
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09864
Value Function Update Magnitude: 0.15054
Collected Steps per Second: 19813.01673
Overall Steps per Second: 7533.32258
Timestep Collection Time: 2.52420
Timestep Consumption Time: 4.11457
PPO Batch Consumption Time: 1.10528
Total Iteration Time: 6.63877
Cumulative Model Updates: 381
Cumulative Timesteps: 6404324
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09903
Policy Entropy: 4.49928
Value Function Loss: 0.00444
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10437
Value Function Update Magnitude: 0.15270
Collected Steps per Second: 22118.18872
Overall Steps per Second: 8266.51368
Timestep Collection Time: 2.26094
Timestep Consumption Time: 3.78852
PPO Batch Consumption Time: 1.05813
Total Iteration Time: 6.04947
Cumulative Model Updates: 384
Cumulative Timesteps: 6454332
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00537
Policy Entropy: 4.49931
Value Function Loss: 0.00336
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10855
Value Function Update Magnitude: 0.15715
Collected Steps per Second: 20264.18980
Overall Steps per Second: 7923.69845
Timestep Collection Time: 2.46800
Timestep Consumption Time: 3.84370
PPO Batch Consumption Time: 1.04598
Total Iteration Time: 6.31170
Cumulative Model Updates: 387
Cumulative Timesteps: 6504344
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00038
Policy Entropy: 4.49931
Value Function Loss: 0.00213
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10103
Value Function Update Magnitude: 0.14049
Collected Steps per Second: 20377.93243
Overall Steps per Second: 8075.45970
Timestep Collection Time: 2.45579
Timestep Consumption Time: 3.74125
PPO Batch Consumption Time: 1.03237
Total Iteration Time: 6.19705
Cumulative Model Updates: 390
Cumulative Timesteps: 6554388
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00083
Policy Entropy: 4.49931
Value Function Loss: 0.00035
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08091
Value Function Update Magnitude: 0.11961
Collected Steps per Second: 21264.44683
Overall Steps per Second: 8301.25908
Timestep Collection Time: 2.35266
Timestep Consumption Time: 3.67390
PPO Batch Consumption Time: 1.01455
Total Iteration Time: 6.02656
Cumulative Model Updates: 393
Cumulative Timesteps: 6604416
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00429
Policy Entropy: 4.49933
Value Function Loss: 0.00114
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06784
Value Function Update Magnitude: 0.09267
Collected Steps per Second: 25066.90651
Overall Steps per Second: 9131.87054
Timestep Collection Time: 1.99610
Timestep Consumption Time: 3.48317
PPO Batch Consumption Time: 0.91678
Total Iteration Time: 5.47927
Cumulative Model Updates: 396
Cumulative Timesteps: 6654452
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00027
Policy Entropy: 4.49937
Value Function Loss: 0.00106
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.08663
Collected Steps per Second: 22045.52943
Overall Steps per Second: 8529.00658
Timestep Collection Time: 2.27039
Timestep Consumption Time: 3.59805
PPO Batch Consumption Time: 1.00190
Total Iteration Time: 5.86844
Cumulative Model Updates: 399
Cumulative Timesteps: 6704504
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11225
Policy Entropy: 4.49942
Value Function Loss: 0.00203
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06816
Value Function Update Magnitude: 0.09681
Collected Steps per Second: 19494.15828
Overall Steps per Second: 7707.15484
Timestep Collection Time: 2.56774
Timestep Consumption Time: 3.92700
PPO Batch Consumption Time: 1.07084
Total Iteration Time: 6.49474
Cumulative Model Updates: 402
Cumulative Timesteps: 6754560
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01789
Policy Entropy: 4.49946
Value Function Loss: 0.00122
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.09519
Collected Steps per Second: 21419.10912
Overall Steps per Second: 8064.24327
Timestep Collection Time: 2.33567
Timestep Consumption Time: 3.86801
PPO Batch Consumption Time: 1.05355
Total Iteration Time: 6.20368
Cumulative Model Updates: 405
Cumulative Timesteps: 6804588
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37136
Policy Entropy: 4.49950
Value Function Loss: 0.00330
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07402
Value Function Update Magnitude: 0.10455
Collected Steps per Second: 21094.42013
Overall Steps per Second: 8096.13418
Timestep Collection Time: 2.37067
Timestep Consumption Time: 3.80610
PPO Batch Consumption Time: 1.05010
Total Iteration Time: 6.17678
Cumulative Model Updates: 408
Cumulative Timesteps: 6854596
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37204
Policy Entropy: 4.49951
Value Function Loss: 0.00446
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08099
Value Function Update Magnitude: 0.11870
Collected Steps per Second: 20942.53061
Overall Steps per Second: 7757.95050
Timestep Collection Time: 2.39035
Timestep Consumption Time: 4.06238
PPO Batch Consumption Time: 1.11105
Total Iteration Time: 6.45274
Cumulative Model Updates: 411
Cumulative Timesteps: 6904656
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00862
Policy Entropy: 4.49952
Value Function Loss: 0.00688
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09779
Value Function Update Magnitude: 0.15243
Collected Steps per Second: 19892.66077
Overall Steps per Second: 7853.35984
Timestep Collection Time: 2.51389
Timestep Consumption Time: 3.85383
PPO Batch Consumption Time: 1.07334
Total Iteration Time: 6.36772
Cumulative Model Updates: 414
Cumulative Timesteps: 6954664
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00873
Policy Entropy: 4.49951
Value Function Loss: 0.00508
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10503
Value Function Update Magnitude: 0.15284
Collected Steps per Second: 19850.81762
Overall Steps per Second: 7711.17306
Timestep Collection Time: 2.52221
Timestep Consumption Time: 3.97070
PPO Batch Consumption Time: 1.08238
Total Iteration Time: 6.49292
Cumulative Model Updates: 417
Cumulative Timesteps: 7004732
Timesteps Collected: 50068
--------END ITERATION REPORT--------
Saving checkpoint 7004732...
Checkpoint 7004732 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02341
Policy Entropy: 4.49951
Value Function Loss: 0.00410
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10527
Value Function Update Magnitude: 0.15939
Collected Steps per Second: 20927.21316
Overall Steps per Second: 7898.50278
Timestep Collection Time: 2.39000
Timestep Consumption Time: 3.94234
PPO Batch Consumption Time: 1.07556
Total Iteration Time: 6.33234
Cumulative Model Updates: 420
Cumulative Timesteps: 7054748
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01879
Policy Entropy: 4.49951
Value Function Loss: 0.00187
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09368
Value Function Update Magnitude: 0.14078
Collected Steps per Second: 20327.09063
Overall Steps per Second: 8018.39331
Timestep Collection Time: 2.46115
Timestep Consumption Time: 3.77801
PPO Batch Consumption Time: 1.04745
Total Iteration Time: 6.23916
Cumulative Model Updates: 423
Cumulative Timesteps: 7104776
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00758
Policy Entropy: 4.49951
Value Function Loss: 0.00156
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08384
Value Function Update Magnitude: 0.11221
Collected Steps per Second: 18433.26107
Overall Steps per Second: 7673.79337
Timestep Collection Time: 2.71596
Timestep Consumption Time: 3.80806
PPO Batch Consumption Time: 1.02333
Total Iteration Time: 6.52402
Cumulative Model Updates: 426
Cumulative Timesteps: 7154840
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05867
Policy Entropy: 4.49951
Value Function Loss: 0.00355
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07529
Value Function Update Magnitude: 0.09196
Collected Steps per Second: 20416.88908
Overall Steps per Second: 7916.04740
Timestep Collection Time: 2.44974
Timestep Consumption Time: 3.86857
PPO Batch Consumption Time: 1.07396
Total Iteration Time: 6.31830
Cumulative Model Updates: 429
Cumulative Timesteps: 7204856
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05831
Policy Entropy: 4.49951
Value Function Loss: 0.00830
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08719
Value Function Update Magnitude: 0.14183
Collected Steps per Second: 20223.20287
Overall Steps per Second: 7707.03065
Timestep Collection Time: 2.47340
Timestep Consumption Time: 4.01678
PPO Batch Consumption Time: 1.12379
Total Iteration Time: 6.49018
Cumulative Model Updates: 432
Cumulative Timesteps: 7254876
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00050
Policy Entropy: 4.49949
Value Function Loss: 0.00845
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11293
Value Function Update Magnitude: 0.17619
Collected Steps per Second: 20060.85198
Overall Steps per Second: 7725.71421
Timestep Collection Time: 2.49381
Timestep Consumption Time: 3.98171
PPO Batch Consumption Time: 1.08354
Total Iteration Time: 6.47552
Cumulative Model Updates: 435
Cumulative Timesteps: 7304904
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02102
Policy Entropy: 4.49945
Value Function Loss: 0.00689
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.12673
Value Function Update Magnitude: 0.18694
Collected Steps per Second: 19791.80901
Overall Steps per Second: 7783.38853
Timestep Collection Time: 2.52690
Timestep Consumption Time: 3.89858
PPO Batch Consumption Time: 1.07732
Total Iteration Time: 6.42548
Cumulative Model Updates: 438
Cumulative Timesteps: 7354916
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00150
Policy Entropy: 4.49939
Value Function Loss: 0.00304
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11865
Value Function Update Magnitude: 0.17924
Collected Steps per Second: 20062.49284
Overall Steps per Second: 7763.95958
Timestep Collection Time: 2.49221
Timestep Consumption Time: 3.94780
PPO Batch Consumption Time: 1.08212
Total Iteration Time: 6.44001
Cumulative Model Updates: 441
Cumulative Timesteps: 7404916
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01755
Policy Entropy: 4.49932
Value Function Loss: 0.00325
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11114
Value Function Update Magnitude: 0.15977
Collected Steps per Second: 20347.00924
Overall Steps per Second: 8748.09671
Timestep Collection Time: 2.46012
Timestep Consumption Time: 3.26181
PPO Batch Consumption Time: 0.88866
Total Iteration Time: 5.72193
Cumulative Model Updates: 444
Cumulative Timesteps: 7454972
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04261
Policy Entropy: 4.49923
Value Function Loss: 0.00336
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10002
Value Function Update Magnitude: 0.14124
Collected Steps per Second: 24217.16578
Overall Steps per Second: 9599.86579
Timestep Collection Time: 2.06482
Timestep Consumption Time: 3.14401
PPO Batch Consumption Time: 0.84378
Total Iteration Time: 5.20882
Cumulative Model Updates: 447
Cumulative Timesteps: 7504976
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01029
Policy Entropy: 4.49913
Value Function Loss: 0.00337
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09964
Value Function Update Magnitude: 0.13859
Collected Steps per Second: 23390.46120
Overall Steps per Second: 8714.32375
Timestep Collection Time: 2.13865
Timestep Consumption Time: 3.60178
PPO Batch Consumption Time: 0.97551
Total Iteration Time: 5.74043
Cumulative Model Updates: 450
Cumulative Timesteps: 7555000
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01553
Policy Entropy: 4.49906
Value Function Loss: 0.00272
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09670
Value Function Update Magnitude: 0.12818
Collected Steps per Second: 21646.18641
Overall Steps per Second: 8079.78770
Timestep Collection Time: 2.31376
Timestep Consumption Time: 3.88492
PPO Batch Consumption Time: 1.08039
Total Iteration Time: 6.19868
Cumulative Model Updates: 453
Cumulative Timesteps: 7605084
Timesteps Collected: 50084
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00351
Policy Entropy: 4.49902
Value Function Loss: 0.00161
Mean KL Divergence: 0.00003
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08753
Value Function Update Magnitude: 0.10502
Collected Steps per Second: 19420.73454
Overall Steps per Second: 7818.63773
Timestep Collection Time: 2.57601
Timestep Consumption Time: 3.82255
PPO Batch Consumption Time: 1.03792
Total Iteration Time: 6.39856
Cumulative Model Updates: 456
Cumulative Timesteps: 7655112
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01686
Policy Entropy: 4.49904
Value Function Loss: 0.00263
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07947
Value Function Update Magnitude: 0.11216
Collected Steps per Second: 22211.59667
Overall Steps per Second: 8398.60795
Timestep Collection Time: 2.25414
Timestep Consumption Time: 3.70733
PPO Batch Consumption Time: 1.02820
Total Iteration Time: 5.96146
Cumulative Model Updates: 459
Cumulative Timesteps: 7705180
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00132
Policy Entropy: 4.49908
Value Function Loss: 0.00438
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08653
Value Function Update Magnitude: 0.14563
Collected Steps per Second: 20664.13632
Overall Steps per Second: 8136.67454
Timestep Collection Time: 2.42139
Timestep Consumption Time: 3.72805
PPO Batch Consumption Time: 1.02323
Total Iteration Time: 6.14944
Cumulative Model Updates: 462
Cumulative Timesteps: 7755216
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01255
Policy Entropy: 4.49912
Value Function Loss: 0.00494
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09782
Value Function Update Magnitude: 0.14695
Collected Steps per Second: 20964.66896
Overall Steps per Second: 8095.16739
Timestep Collection Time: 2.38706
Timestep Consumption Time: 3.79490
PPO Batch Consumption Time: 1.02771
Total Iteration Time: 6.18196
Cumulative Model Updates: 465
Cumulative Timesteps: 7805260
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03899
Policy Entropy: 4.49913
Value Function Loss: 0.00437
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10175
Value Function Update Magnitude: 0.15768
Collected Steps per Second: 20678.83865
Overall Steps per Second: 7720.69222
Timestep Collection Time: 2.41793
Timestep Consumption Time: 4.05817
PPO Batch Consumption Time: 1.13832
Total Iteration Time: 6.47610
Cumulative Model Updates: 468
Cumulative Timesteps: 7855260
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01053
Policy Entropy: 4.49914
Value Function Loss: 0.00336
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09959
Value Function Update Magnitude: 0.14725
Collected Steps per Second: 25483.12356
Overall Steps per Second: 11117.15309
Timestep Collection Time: 1.96459
Timestep Consumption Time: 2.53872
PPO Batch Consumption Time: 0.63367
Total Iteration Time: 4.50331
Cumulative Model Updates: 471
Cumulative Timesteps: 7905324
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01288
Policy Entropy: 4.49917
Value Function Loss: 0.00246
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09659
Value Function Update Magnitude: 0.13715
Collected Steps per Second: 31593.09503
Overall Steps per Second: 9028.34249
Timestep Collection Time: 1.58262
Timestep Consumption Time: 3.95549
PPO Batch Consumption Time: 1.09476
Total Iteration Time: 5.53812
Cumulative Model Updates: 474
Cumulative Timesteps: 7955324
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00037
Policy Entropy: 4.49922
Value Function Loss: 0.00154
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08999
Value Function Update Magnitude: 0.12578
Collected Steps per Second: 20634.34875
Overall Steps per Second: 8277.27429
Timestep Collection Time: 2.42450
Timestep Consumption Time: 3.61952
PPO Batch Consumption Time: 0.99579
Total Iteration Time: 6.04402
Cumulative Model Updates: 477
Cumulative Timesteps: 8005352
Timesteps Collected: 50028
--------END ITERATION REPORT--------
Saving checkpoint 8005352...
Checkpoint 8005352 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14175
Policy Entropy: 4.49929
Value Function Loss: 0.00397
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08418
Value Function Update Magnitude: 0.11581
Collected Steps per Second: 21474.60520
Overall Steps per Second: 8231.37849
Timestep Collection Time: 2.33206
Timestep Consumption Time: 3.75198
PPO Batch Consumption Time: 1.00566
Total Iteration Time: 6.08404
Cumulative Model Updates: 480
Cumulative Timesteps: 8055432
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00136
Policy Entropy: 4.49936
Value Function Loss: 0.00448
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09334
Value Function Update Magnitude: 0.13843
Collected Steps per Second: 22545.82986
Overall Steps per Second: 8310.20136
Timestep Collection Time: 2.21824
Timestep Consumption Time: 3.79991
PPO Batch Consumption Time: 1.02810
Total Iteration Time: 6.01815
Cumulative Model Updates: 483
Cumulative Timesteps: 8105444
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01656
Policy Entropy: 4.49941
Value Function Loss: 0.00416
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10895
Value Function Update Magnitude: 0.16148
Collected Steps per Second: 19599.97222
Overall Steps per Second: 8036.34402
Timestep Collection Time: 2.55143
Timestep Consumption Time: 3.67130
PPO Batch Consumption Time: 1.01441
Total Iteration Time: 6.22273
Cumulative Model Updates: 486
Cumulative Timesteps: 8155452
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00391
Policy Entropy: 4.49943
Value Function Loss: 0.00152
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10229
Value Function Update Magnitude: 0.16293
Collected Steps per Second: 21562.41439
Overall Steps per Second: 7653.58465
Timestep Collection Time: 2.32015
Timestep Consumption Time: 4.21640
PPO Batch Consumption Time: 1.16874
Total Iteration Time: 6.53654
Cumulative Model Updates: 489
Cumulative Timesteps: 8205480
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21479
Policy Entropy: 4.49945
Value Function Loss: 0.00405
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08896
Value Function Update Magnitude: 0.11770
Collected Steps per Second: 25314.53314
Overall Steps per Second: 7509.59538
Timestep Collection Time: 1.97657
Timestep Consumption Time: 4.68637
PPO Batch Consumption Time: 1.32007
Total Iteration Time: 6.66294
Cumulative Model Updates: 492
Cumulative Timesteps: 8255516
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00010
Policy Entropy: 4.49945
Value Function Loss: 0.00481
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09414
Value Function Update Magnitude: 0.11603
Collected Steps per Second: 21932.94258
Overall Steps per Second: 7416.06425
Timestep Collection Time: 2.28004
Timestep Consumption Time: 4.46316
PPO Batch Consumption Time: 1.25676
Total Iteration Time: 6.74320
Cumulative Model Updates: 495
Cumulative Timesteps: 8305524
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00104
Policy Entropy: 4.49945
Value Function Loss: 0.00469
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10574
Value Function Update Magnitude: 0.11549
Collected Steps per Second: 22318.18545
Overall Steps per Second: 8066.54276
Timestep Collection Time: 2.24122
Timestep Consumption Time: 3.95970
PPO Batch Consumption Time: 1.07768
Total Iteration Time: 6.20092
Cumulative Model Updates: 498
Cumulative Timesteps: 8355544
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14637
Policy Entropy: 4.49945
Value Function Loss: 0.00343
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09826
Value Function Update Magnitude: 0.10989
Collected Steps per Second: 20509.54747
Overall Steps per Second: 8209.00701
Timestep Collection Time: 2.44101
Timestep Consumption Time: 3.65766
PPO Batch Consumption Time: 1.01266
Total Iteration Time: 6.09867
Cumulative Model Updates: 501
Cumulative Timesteps: 8405608
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00429
Policy Entropy: 4.49945
Value Function Loss: 0.00251
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09020
Value Function Update Magnitude: 0.11498
Collected Steps per Second: 20957.11733
Overall Steps per Second: 8308.43715
Timestep Collection Time: 2.38945
Timestep Consumption Time: 3.63768
PPO Batch Consumption Time: 0.97959
Total Iteration Time: 6.02713
Cumulative Model Updates: 504
Cumulative Timesteps: 8455684
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00957
Policy Entropy: 4.49945
Value Function Loss: 0.00284
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08695
Value Function Update Magnitude: 0.12367
Collected Steps per Second: 30967.27904
Overall Steps per Second: 11993.18778
Timestep Collection Time: 1.61525
Timestep Consumption Time: 2.55545
PPO Batch Consumption Time: 0.62467
Total Iteration Time: 4.17070
Cumulative Model Updates: 507
Cumulative Timesteps: 8505704
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01071
Policy Entropy: 4.49944
Value Function Loss: 0.00160
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08026
Value Function Update Magnitude: 0.12312
Collected Steps per Second: 20538.65237
Overall Steps per Second: 7563.39556
Timestep Collection Time: 2.43599
Timestep Consumption Time: 4.17903
PPO Batch Consumption Time: 1.05498
Total Iteration Time: 6.61502
Cumulative Model Updates: 510
Cumulative Timesteps: 8555736
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00256
Policy Entropy: 4.49944
Value Function Loss: 0.00255
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07723
Value Function Update Magnitude: 0.11735
Collected Steps per Second: 20210.81418
Overall Steps per Second: 7605.76520
Timestep Collection Time: 2.47610
Timestep Consumption Time: 4.10365
PPO Batch Consumption Time: 0.93038
Total Iteration Time: 6.57975
Cumulative Model Updates: 513
Cumulative Timesteps: 8605780
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02652
Policy Entropy: 4.49943
Value Function Loss: 0.00264
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07454
Value Function Update Magnitude: 0.09486
Collected Steps per Second: 19407.58123
Overall Steps per Second: 7728.69253
Timestep Collection Time: 2.57734
Timestep Consumption Time: 3.89464
PPO Batch Consumption Time: 1.08373
Total Iteration Time: 6.47199
Cumulative Model Updates: 516
Cumulative Timesteps: 8655800
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01970
Policy Entropy: 4.49943
Value Function Loss: 0.00341
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07898
Value Function Update Magnitude: 0.07869
Collected Steps per Second: 18900.81843
Overall Steps per Second: 7448.65722
Timestep Collection Time: 2.64877
Timestep Consumption Time: 4.07244
PPO Batch Consumption Time: 1.13381
Total Iteration Time: 6.72121
Cumulative Model Updates: 519
Cumulative Timesteps: 8705864
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02455
Policy Entropy: 4.49943
Value Function Loss: 0.00334
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08315
Value Function Update Magnitude: 0.07897
Collected Steps per Second: 20194.87850
Overall Steps per Second: 7608.62759
Timestep Collection Time: 2.47845
Timestep Consumption Time: 4.09987
PPO Batch Consumption Time: 1.11707
Total Iteration Time: 6.57832
Cumulative Model Updates: 522
Cumulative Timesteps: 8755916
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00071
Policy Entropy: 4.49943
Value Function Loss: 0.00212
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08477
Value Function Update Magnitude: 0.09095
Collected Steps per Second: 18657.54860
Overall Steps per Second: 7112.94123
Timestep Collection Time: 2.68117
Timestep Consumption Time: 4.35165
PPO Batch Consumption Time: 1.21452
Total Iteration Time: 7.03282
Cumulative Model Updates: 525
Cumulative Timesteps: 8805940
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00828
Policy Entropy: 4.49943
Value Function Loss: 0.00125
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07946
Value Function Update Magnitude: 0.08995
Collected Steps per Second: 18647.66775
Overall Steps per Second: 7189.94966
Timestep Collection Time: 2.68430
Timestep Consumption Time: 4.27764
PPO Batch Consumption Time: 1.16973
Total Iteration Time: 6.96194
Cumulative Model Updates: 528
Cumulative Timesteps: 8855996
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00663
Policy Entropy: 4.49942
Value Function Loss: 0.00012
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.07715
Collected Steps per Second: 19802.86940
Overall Steps per Second: 7503.93546
Timestep Collection Time: 2.52549
Timestep Consumption Time: 4.13928
PPO Batch Consumption Time: 1.12056
Total Iteration Time: 6.66477
Cumulative Model Updates: 531
Cumulative Timesteps: 8906008
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04116
Policy Entropy: 4.49943
Value Function Loss: 0.00126
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.06490
Collected Steps per Second: 19400.30728
Overall Steps per Second: 7667.13065
Timestep Collection Time: 2.57852
Timestep Consumption Time: 3.94596
PPO Batch Consumption Time: 1.10057
Total Iteration Time: 6.52447
Cumulative Model Updates: 534
Cumulative Timesteps: 8956032
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00772
Policy Entropy: 4.49945
Value Function Loss: 0.00248
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.06164
Collected Steps per Second: 19786.35239
Overall Steps per Second: 7489.65158
Timestep Collection Time: 2.53124
Timestep Consumption Time: 4.15585
PPO Batch Consumption Time: 1.13836
Total Iteration Time: 6.68709
Cumulative Model Updates: 537
Cumulative Timesteps: 9006116
Timesteps Collected: 50084
--------END ITERATION REPORT--------
Saving checkpoint 9006116...
Checkpoint 9006116 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02663
Policy Entropy: 4.49947
Value Function Loss: 0.00356
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07262
Value Function Update Magnitude: 0.06405
Collected Steps per Second: 20357.34836
Overall Steps per Second: 7606.73894
Timestep Collection Time: 2.45788
Timestep Consumption Time: 4.11997
PPO Batch Consumption Time: 1.13249
Total Iteration Time: 6.57785
Cumulative Model Updates: 540
Cumulative Timesteps: 9056152
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04557
Policy Entropy: 4.49949
Value Function Loss: 0.00344
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07749
Value Function Update Magnitude: 0.06299
Collected Steps per Second: 20457.36924
Overall Steps per Second: 8118.71912
Timestep Collection Time: 2.44489
Timestep Consumption Time: 3.71569
PPO Batch Consumption Time: 1.01461
Total Iteration Time: 6.16058
Cumulative Model Updates: 543
Cumulative Timesteps: 9106168
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00414
Policy Entropy: 4.49949
Value Function Loss: 0.00221
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07725
Value Function Update Magnitude: 0.05692
Collected Steps per Second: 20216.08416
Overall Steps per Second: 7684.95289
Timestep Collection Time: 2.47585
Timestep Consumption Time: 4.03714
PPO Batch Consumption Time: 1.10580
Total Iteration Time: 6.51299
Cumulative Model Updates: 546
Cumulative Timesteps: 9156220
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00035
Policy Entropy: 4.49948
Value Function Loss: 0.00112
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07118
Value Function Update Magnitude: 0.05031
Collected Steps per Second: 19608.52301
Overall Steps per Second: 7555.20947
Timestep Collection Time: 2.55114
Timestep Consumption Time: 4.06999
PPO Batch Consumption Time: 1.13902
Total Iteration Time: 6.62113
Cumulative Model Updates: 549
Cumulative Timesteps: 9206244
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12598
Policy Entropy: 4.49949
Value Function Loss: 0.00227
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.04439
Collected Steps per Second: 19362.19119
Overall Steps per Second: 7711.41496
Timestep Collection Time: 2.58586
Timestep Consumption Time: 3.90685
PPO Batch Consumption Time: 1.09035
Total Iteration Time: 6.49271
Cumulative Model Updates: 552
Cumulative Timesteps: 9256312
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02412
Policy Entropy: 4.49950
Value Function Loss: 0.00342
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07117
Value Function Update Magnitude: 0.04822
Collected Steps per Second: 18548.36995
Overall Steps per Second: 7446.39855
Timestep Collection Time: 2.69846
Timestep Consumption Time: 4.02318
PPO Batch Consumption Time: 1.07400
Total Iteration Time: 6.72164
Cumulative Model Updates: 555
Cumulative Timesteps: 9306364
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15973
Policy Entropy: 4.49952
Value Function Loss: 0.00427
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08528
Value Function Update Magnitude: 0.06340
Collected Steps per Second: 20963.34178
Overall Steps per Second: 8112.84123
Timestep Collection Time: 2.38512
Timestep Consumption Time: 3.77795
PPO Batch Consumption Time: 1.05457
Total Iteration Time: 6.16307
Cumulative Model Updates: 558
Cumulative Timesteps: 9356364
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01169
Policy Entropy: 4.49953
Value Function Loss: 0.00212
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08653
Value Function Update Magnitude: 0.07150
Collected Steps per Second: 19477.98408
Overall Steps per Second: 7479.03014
Timestep Collection Time: 2.57111
Timestep Consumption Time: 4.12495
PPO Batch Consumption Time: 1.12382
Total Iteration Time: 6.69606
Cumulative Model Updates: 561
Cumulative Timesteps: 9406444
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00277
Policy Entropy: 4.49953
Value Function Loss: 0.00191
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07934
Value Function Update Magnitude: 0.07886
Collected Steps per Second: 20640.22221
Overall Steps per Second: 7853.60629
Timestep Collection Time: 2.42342
Timestep Consumption Time: 3.94563
PPO Batch Consumption Time: 1.07879
Total Iteration Time: 6.36905
Cumulative Model Updates: 564
Cumulative Timesteps: 9456464
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04784
Policy Entropy: 4.49954
Value Function Loss: 0.00336
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07460
Value Function Update Magnitude: 0.07430
Collected Steps per Second: 19720.65547
Overall Steps per Second: 7783.90204
Timestep Collection Time: 2.53805
Timestep Consumption Time: 3.89214
PPO Batch Consumption Time: 1.08437
Total Iteration Time: 6.43019
Cumulative Model Updates: 567
Cumulative Timesteps: 9506516
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02655
Policy Entropy: 4.49955
Value Function Loss: 0.00581
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08580
Value Function Update Magnitude: 0.11086
Collected Steps per Second: 18403.21701
Overall Steps per Second: 7309.96631
Timestep Collection Time: 2.72018
Timestep Consumption Time: 4.12801
PPO Batch Consumption Time: 1.13423
Total Iteration Time: 6.84818
Cumulative Model Updates: 570
Cumulative Timesteps: 9556576
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00390
Policy Entropy: 4.49955
Value Function Loss: 0.00595
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09967
Value Function Update Magnitude: 0.15238
Collected Steps per Second: 19500.28789
Overall Steps per Second: 7578.59071
Timestep Collection Time: 2.56755
Timestep Consumption Time: 4.03895
PPO Batch Consumption Time: 1.13343
Total Iteration Time: 6.60651
Cumulative Model Updates: 573
Cumulative Timesteps: 9606644
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00477
Policy Entropy: 4.49954
Value Function Loss: 0.00464
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10554
Value Function Update Magnitude: 0.16271
Collected Steps per Second: 19737.06841
Overall Steps per Second: 7405.09087
Timestep Collection Time: 2.53371
Timestep Consumption Time: 4.21948
PPO Batch Consumption Time: 1.16578
Total Iteration Time: 6.75319
Cumulative Model Updates: 576
Cumulative Timesteps: 9656652
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01390
Policy Entropy: 4.49952
Value Function Loss: 0.00269
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10211
Value Function Update Magnitude: 0.16383
Collected Steps per Second: 19864.71876
Overall Steps per Second: 7596.78542
Timestep Collection Time: 2.51924
Timestep Consumption Time: 4.06828
PPO Batch Consumption Time: 1.11082
Total Iteration Time: 6.58752
Cumulative Model Updates: 579
Cumulative Timesteps: 9706696
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01430
Policy Entropy: 4.49949
Value Function Loss: 0.00389
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09292
Value Function Update Magnitude: 0.13529
Collected Steps per Second: 18299.92936
Overall Steps per Second: 7358.41344
Timestep Collection Time: 2.73269
Timestep Consumption Time: 4.06334
PPO Batch Consumption Time: 1.11724
Total Iteration Time: 6.79603
Cumulative Model Updates: 582
Cumulative Timesteps: 9756704
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05171
Policy Entropy: 4.49948
Value Function Loss: 0.00435
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08989
Value Function Update Magnitude: 0.14937
Collected Steps per Second: 20031.77580
Overall Steps per Second: 7564.46079
Timestep Collection Time: 2.49603
Timestep Consumption Time: 4.11382
PPO Batch Consumption Time: 1.12973
Total Iteration Time: 6.60986
Cumulative Model Updates: 585
Cumulative Timesteps: 9806704
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00611
Policy Entropy: 4.49948
Value Function Loss: 0.00499
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09842
Value Function Update Magnitude: 0.17199
Collected Steps per Second: 20325.07746
Overall Steps per Second: 7734.08814
Timestep Collection Time: 2.46297
Timestep Consumption Time: 4.00968
PPO Batch Consumption Time: 1.09646
Total Iteration Time: 6.47264
Cumulative Model Updates: 588
Cumulative Timesteps: 9856764
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00053
Policy Entropy: 4.49946
Value Function Loss: 0.00292
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09735
Value Function Update Magnitude: 0.17858
Collected Steps per Second: 20951.62021
Overall Steps per Second: 8847.78331
Timestep Collection Time: 2.39065
Timestep Consumption Time: 3.27043
PPO Batch Consumption Time: 0.88241
Total Iteration Time: 5.66108
Cumulative Model Updates: 591
Cumulative Timesteps: 9906852
Timesteps Collected: 50088
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.34669
Policy Entropy: 4.49944
Value Function Loss: 0.00240
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08822
Value Function Update Magnitude: 0.16174
Collected Steps per Second: 24061.30901
Overall Steps per Second: 8996.77560
Timestep Collection Time: 2.07935
Timestep Consumption Time: 3.48175
PPO Batch Consumption Time: 0.89492
Total Iteration Time: 5.56110
Cumulative Model Updates: 594
Cumulative Timesteps: 9956884
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05535
Policy Entropy: 4.49943
Value Function Loss: 0.00196
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08012
Value Function Update Magnitude: 0.14747
Collected Steps per Second: 18792.79308
Overall Steps per Second: 7416.32093
Timestep Collection Time: 2.66208
Timestep Consumption Time: 4.08358
PPO Batch Consumption Time: 1.12905
Total Iteration Time: 6.74566
Cumulative Model Updates: 597
Cumulative Timesteps: 10006912
Timesteps Collected: 50028
--------END ITERATION REPORT--------
Saving checkpoint 10006912...
Checkpoint 10006912 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00377
Policy Entropy: 4.49943
Value Function Loss: 0.00193
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07914
Value Function Update Magnitude: 0.15475
Collected Steps per Second: 19185.03572
Overall Steps per Second: 7537.91597
Timestep Collection Time: 2.60661
Timestep Consumption Time: 4.02758
PPO Batch Consumption Time: 1.09411
Total Iteration Time: 6.63419
Cumulative Model Updates: 600
Cumulative Timesteps: 10056920
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22178
Policy Entropy: 4.49942
Value Function Loss: 0.00216
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07598
Value Function Update Magnitude: 0.15563
Collected Steps per Second: 20238.34731
Overall Steps per Second: 7680.78947
Timestep Collection Time: 2.47115
Timestep Consumption Time: 4.04016
PPO Batch Consumption Time: 1.10911
Total Iteration Time: 6.51131
Cumulative Model Updates: 603
Cumulative Timesteps: 10106932
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00848
Policy Entropy: 4.49942
Value Function Loss: 0.00345
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07659
Value Function Update Magnitude: 0.14705
Collected Steps per Second: 18240.82985
Overall Steps per Second: 7325.98570
Timestep Collection Time: 2.74176
Timestep Consumption Time: 4.08490
PPO Batch Consumption Time: 1.14351
Total Iteration Time: 6.82666
Cumulative Model Updates: 606
Cumulative Timesteps: 10156944
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10643
Policy Entropy: 4.49943
Value Function Loss: 0.00526
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09176
Value Function Update Magnitude: 0.15319
Collected Steps per Second: 18878.77858
Overall Steps per Second: 7456.86066
Timestep Collection Time: 2.64848
Timestep Consumption Time: 4.05676
PPO Batch Consumption Time: 1.10116
Total Iteration Time: 6.70523
Cumulative Model Updates: 609
Cumulative Timesteps: 10206944
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07929
Policy Entropy: 4.49944
Value Function Loss: 0.00734
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10505
Value Function Update Magnitude: 0.16253
Collected Steps per Second: 19432.40793
Overall Steps per Second: 7616.14161
Timestep Collection Time: 2.57467
Timestep Consumption Time: 3.99454
PPO Batch Consumption Time: 1.09094
Total Iteration Time: 6.56921
Cumulative Model Updates: 612
Cumulative Timesteps: 10256976
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00336
Policy Entropy: 4.49943
Value Function Loss: 0.00631
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11273
Value Function Update Magnitude: 0.16276
Collected Steps per Second: 19427.32377
Overall Steps per Second: 7850.96106
Timestep Collection Time: 2.57493
Timestep Consumption Time: 3.79677
PPO Batch Consumption Time: 1.05565
Total Iteration Time: 6.37170
Cumulative Model Updates: 615
Cumulative Timesteps: 10307000
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00551
Policy Entropy: 4.49942
Value Function Loss: 0.00525
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11025
Value Function Update Magnitude: 0.15366
Collected Steps per Second: 19495.34335
Overall Steps per Second: 7788.98808
Timestep Collection Time: 2.56677
Timestep Consumption Time: 3.85769
PPO Batch Consumption Time: 1.05068
Total Iteration Time: 6.42445
Cumulative Model Updates: 618
Cumulative Timesteps: 10357040
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.35019
Policy Entropy: 4.49942
Value Function Loss: 0.00302
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10221
Value Function Update Magnitude: 0.14135
Collected Steps per Second: 20362.79188
Overall Steps per Second: 7735.71240
Timestep Collection Time: 2.45801
Timestep Consumption Time: 4.01224
PPO Batch Consumption Time: 1.11739
Total Iteration Time: 6.47025
Cumulative Model Updates: 621
Cumulative Timesteps: 10407092
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00044
Policy Entropy: 4.49943
Value Function Loss: 0.00320
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09466
Value Function Update Magnitude: 0.13994
Collected Steps per Second: 17742.13326
Overall Steps per Second: 7399.19799
Timestep Collection Time: 2.82243
Timestep Consumption Time: 3.94533
PPO Batch Consumption Time: 1.08746
Total Iteration Time: 6.76776
Cumulative Model Updates: 624
Cumulative Timesteps: 10457168
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01832
Policy Entropy: 4.49946
Value Function Loss: 0.00329
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09140
Value Function Update Magnitude: 0.13935
Collected Steps per Second: 21995.30584
Overall Steps per Second: 8837.02606
Timestep Collection Time: 2.27503
Timestep Consumption Time: 3.38751
PPO Batch Consumption Time: 0.88349
Total Iteration Time: 5.66254
Cumulative Model Updates: 627
Cumulative Timesteps: 10507208
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06766
Policy Entropy: 4.49950
Value Function Loss: 0.00433
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09261
Value Function Update Magnitude: 0.14066
Collected Steps per Second: 23701.49009
Overall Steps per Second: 9222.82404
Timestep Collection Time: 2.11092
Timestep Consumption Time: 3.31388
PPO Batch Consumption Time: 0.90644
Total Iteration Time: 5.42480
Cumulative Model Updates: 630
Cumulative Timesteps: 10557240
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03001
Policy Entropy: 4.49954
Value Function Loss: 0.00339
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09452
Value Function Update Magnitude: 0.13534
Collected Steps per Second: 21254.27580
Overall Steps per Second: 7696.91099
Timestep Collection Time: 2.35322
Timestep Consumption Time: 4.14497
PPO Batch Consumption Time: 1.14018
Total Iteration Time: 6.49819
Cumulative Model Updates: 633
Cumulative Timesteps: 10607256
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01484
Policy Entropy: 4.49958
Value Function Loss: 0.00321
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09175
Value Function Update Magnitude: 0.11932
Collected Steps per Second: 19873.24682
Overall Steps per Second: 7620.07031
Timestep Collection Time: 2.51735
Timestep Consumption Time: 4.04794
PPO Batch Consumption Time: 1.09859
Total Iteration Time: 6.56529
Cumulative Model Updates: 636
Cumulative Timesteps: 10657284
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00640
Policy Entropy: 4.49960
Value Function Loss: 0.00233
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08541
Value Function Update Magnitude: 0.11615
Collected Steps per Second: 17648.92112
Overall Steps per Second: 7205.64374
Timestep Collection Time: 2.83303
Timestep Consumption Time: 4.10597
PPO Batch Consumption Time: 1.14063
Total Iteration Time: 6.93901
Cumulative Model Updates: 639
Cumulative Timesteps: 10707284
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00938
Policy Entropy: 4.49962
Value Function Loss: 0.00326
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08324
Value Function Update Magnitude: 0.13513
Collected Steps per Second: 19850.08874
Overall Steps per Second: 7560.61298
Timestep Collection Time: 2.52170
Timestep Consumption Time: 4.09893
PPO Batch Consumption Time: 1.12352
Total Iteration Time: 6.62063
Cumulative Model Updates: 642
Cumulative Timesteps: 10757340
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11960
Policy Entropy: 4.49962
Value Function Loss: 0.00337
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08445
Value Function Update Magnitude: 0.14351
Collected Steps per Second: 19549.84551
Overall Steps per Second: 7630.37396
Timestep Collection Time: 2.56186
Timestep Consumption Time: 4.00191
PPO Batch Consumption Time: 1.11422
Total Iteration Time: 6.56377
Cumulative Model Updates: 645
Cumulative Timesteps: 10807424
Timesteps Collected: 50084
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00384
Policy Entropy: 4.49962
Value Function Loss: 0.00312
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08445
Value Function Update Magnitude: 0.13382
Collected Steps per Second: 19651.34010
Overall Steps per Second: 7582.10625
Timestep Collection Time: 2.54436
Timestep Consumption Time: 4.05012
PPO Batch Consumption Time: 1.10720
Total Iteration Time: 6.59447
Cumulative Model Updates: 648
Cumulative Timesteps: 10857424
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.39407
Policy Entropy: 4.49960
Value Function Loss: 0.00453
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08424
Value Function Update Magnitude: 0.14206
Collected Steps per Second: 20290.33168
Overall Steps per Second: 7618.66836
Timestep Collection Time: 2.46600
Timestep Consumption Time: 4.10155
PPO Batch Consumption Time: 1.10473
Total Iteration Time: 6.56755
Cumulative Model Updates: 651
Cumulative Timesteps: 10907460
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10306
Policy Entropy: 4.49958
Value Function Loss: 0.00566
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09409
Value Function Update Magnitude: 0.16527
Collected Steps per Second: 20042.58827
Overall Steps per Second: 7522.34563
Timestep Collection Time: 2.49848
Timestep Consumption Time: 4.15849
PPO Batch Consumption Time: 1.16824
Total Iteration Time: 6.65697
Cumulative Model Updates: 654
Cumulative Timesteps: 10957536
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00942
Policy Entropy: 4.49955
Value Function Loss: 0.00557
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10646
Value Function Update Magnitude: 0.18208
Collected Steps per Second: 19710.43393
Overall Steps per Second: 7555.68730
Timestep Collection Time: 2.54058
Timestep Consumption Time: 4.08701
PPO Batch Consumption Time: 1.11772
Total Iteration Time: 6.62759
Cumulative Model Updates: 657
Cumulative Timesteps: 11007612
Timesteps Collected: 50076
--------END ITERATION REPORT--------
Saving checkpoint 11007612...
Checkpoint 11007612 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02233
Policy Entropy: 4.49951
Value Function Loss: 0.00473
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10615
Value Function Update Magnitude: 0.19278
Collected Steps per Second: 19955.83259
Overall Steps per Second: 7532.62252
Timestep Collection Time: 2.50714
Timestep Consumption Time: 4.13491
PPO Batch Consumption Time: 1.13870
Total Iteration Time: 6.64204
Cumulative Model Updates: 660
Cumulative Timesteps: 11057644
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03091
Policy Entropy: 4.49948
Value Function Loss: 0.00346
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09953
Value Function Update Magnitude: 0.19073
Collected Steps per Second: 22045.00905
Overall Steps per Second: 8971.84501
Timestep Collection Time: 2.26990
Timestep Consumption Time: 3.30755
PPO Batch Consumption Time: 0.89823
Total Iteration Time: 5.57745
Cumulative Model Updates: 663
Cumulative Timesteps: 11107684
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00047
Policy Entropy: 4.49947
Value Function Loss: 0.00496
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09961
Value Function Update Magnitude: 0.19057
Collected Steps per Second: 22087.14762
Overall Steps per Second: 8216.49634
Timestep Collection Time: 2.26575
Timestep Consumption Time: 3.82492
PPO Batch Consumption Time: 1.02907
Total Iteration Time: 6.09067
Cumulative Model Updates: 666
Cumulative Timesteps: 11157728
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02432
Policy Entropy: 4.49949
Value Function Loss: 0.00413
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09947
Value Function Update Magnitude: 0.18206
Collected Steps per Second: 19597.44462
Overall Steps per Second: 7500.10455
Timestep Collection Time: 2.55299
Timestep Consumption Time: 4.11785
PPO Batch Consumption Time: 1.15244
Total Iteration Time: 6.67084
Cumulative Model Updates: 669
Cumulative Timesteps: 11207760
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37852
Policy Entropy: 4.49951
Value Function Loss: 0.00404
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09931
Value Function Update Magnitude: 0.19105
Collected Steps per Second: 19098.13567
Overall Steps per Second: 7604.66893
Timestep Collection Time: 2.61868
Timestep Consumption Time: 3.95780
PPO Batch Consumption Time: 1.07905
Total Iteration Time: 6.57649
Cumulative Model Updates: 672
Cumulative Timesteps: 11257772
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01006
Policy Entropy: 4.49951
Value Function Loss: 0.00291
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09253
Value Function Update Magnitude: 0.18911
Collected Steps per Second: 20144.09357
Overall Steps per Second: 7787.79641
Timestep Collection Time: 2.48450
Timestep Consumption Time: 3.94196
PPO Batch Consumption Time: 1.08155
Total Iteration Time: 6.42646
Cumulative Model Updates: 675
Cumulative Timesteps: 11307820
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00618
Policy Entropy: 4.49952
Value Function Loss: 0.00270
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08714
Value Function Update Magnitude: 0.18727
Collected Steps per Second: 19662.84961
Overall Steps per Second: 7783.68588
Timestep Collection Time: 2.54449
Timestep Consumption Time: 3.88331
PPO Batch Consumption Time: 1.07603
Total Iteration Time: 6.42780
Cumulative Model Updates: 678
Cumulative Timesteps: 11357852
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00215
Policy Entropy: 4.49953
Value Function Loss: 0.00354
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08610
Value Function Update Magnitude: 0.18974
Collected Steps per Second: 19269.26683
Overall Steps per Second: 7603.78695
Timestep Collection Time: 2.59792
Timestep Consumption Time: 3.98564
PPO Batch Consumption Time: 1.08842
Total Iteration Time: 6.58356
Cumulative Model Updates: 681
Cumulative Timesteps: 11407912
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00606
Policy Entropy: 4.49953
Value Function Loss: 0.00357
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08966
Value Function Update Magnitude: 0.19464
Collected Steps per Second: 19881.32969
Overall Steps per Second: 7406.18083
Timestep Collection Time: 2.51512
Timestep Consumption Time: 4.23653
PPO Batch Consumption Time: 1.17772
Total Iteration Time: 6.75166
Cumulative Model Updates: 684
Cumulative Timesteps: 11457916
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00631
Policy Entropy: 4.49953
Value Function Loss: 0.00316
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09433
Value Function Update Magnitude: 0.19732
Collected Steps per Second: 19537.45222
Overall Steps per Second: 7894.61760
Timestep Collection Time: 2.56062
Timestep Consumption Time: 3.77636
PPO Batch Consumption Time: 1.04288
Total Iteration Time: 6.33698
Cumulative Model Updates: 687
Cumulative Timesteps: 11507944
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00148
Policy Entropy: 4.49954
Value Function Loss: 0.00243
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09182
Value Function Update Magnitude: 0.16921
Collected Steps per Second: 22674.23838
Overall Steps per Second: 8799.81179
Timestep Collection Time: 2.20532
Timestep Consumption Time: 3.47707
PPO Batch Consumption Time: 0.93100
Total Iteration Time: 5.68239
Cumulative Model Updates: 690
Cumulative Timesteps: 11557948
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06140
Policy Entropy: 4.49955
Value Function Loss: 0.00254
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08476
Value Function Update Magnitude: 0.14241
Collected Steps per Second: 22589.32385
Overall Steps per Second: 8731.94979
Timestep Collection Time: 2.21503
Timestep Consumption Time: 3.51519
PPO Batch Consumption Time: 0.94334
Total Iteration Time: 5.73022
Cumulative Model Updates: 693
Cumulative Timesteps: 11607984
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00236
Policy Entropy: 4.49956
Value Function Loss: 0.00290
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08268
Value Function Update Magnitude: 0.12174
Collected Steps per Second: 21867.96701
Overall Steps per Second: 8738.50614
Timestep Collection Time: 2.28736
Timestep Consumption Time: 3.43673
PPO Batch Consumption Time: 0.90866
Total Iteration Time: 5.72409
Cumulative Model Updates: 696
Cumulative Timesteps: 11658004
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02227
Policy Entropy: 4.49957
Value Function Loss: 0.00298
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08293
Value Function Update Magnitude: 0.12610
Collected Steps per Second: 23126.72855
Overall Steps per Second: 8919.79648
Timestep Collection Time: 2.16459
Timestep Consumption Time: 3.44764
PPO Batch Consumption Time: 0.91957
Total Iteration Time: 5.61224
Cumulative Model Updates: 699
Cumulative Timesteps: 11708064
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01514
Policy Entropy: 4.49958
Value Function Loss: 0.00375
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08240
Value Function Update Magnitude: 0.14372
Collected Steps per Second: 23434.36373
Overall Steps per Second: 9020.78918
Timestep Collection Time: 2.13447
Timestep Consumption Time: 3.41050
PPO Batch Consumption Time: 0.93576
Total Iteration Time: 5.54497
Cumulative Model Updates: 702
Cumulative Timesteps: 11758084
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00871
Policy Entropy: 4.49959
Value Function Loss: 0.00505
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08905
Value Function Update Magnitude: 0.17200
Collected Steps per Second: 23833.34561
Overall Steps per Second: 9031.56482
Timestep Collection Time: 2.09891
Timestep Consumption Time: 3.43989
PPO Batch Consumption Time: 0.90866
Total Iteration Time: 5.53880
Cumulative Model Updates: 705
Cumulative Timesteps: 11808108
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.33941
Policy Entropy: 4.49959
Value Function Loss: 0.00556
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09733
Value Function Update Magnitude: 0.17544
Collected Steps per Second: 23594.92109
Overall Steps per Second: 8983.86310
Timestep Collection Time: 2.12147
Timestep Consumption Time: 3.45029
PPO Batch Consumption Time: 0.92114
Total Iteration Time: 5.57177
Cumulative Model Updates: 708
Cumulative Timesteps: 11858164
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.27384
Policy Entropy: 4.49957
Value Function Loss: 0.00518
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10385
Value Function Update Magnitude: 0.18347
Collected Steps per Second: 20512.55996
Overall Steps per Second: 8632.90090
Timestep Collection Time: 2.43792
Timestep Consumption Time: 3.35480
PPO Batch Consumption Time: 0.90782
Total Iteration Time: 5.79272
Cumulative Model Updates: 711
Cumulative Timesteps: 11908172
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04212
Policy Entropy: 4.49954
Value Function Loss: 0.00693
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10644
Value Function Update Magnitude: 0.20517
Collected Steps per Second: 23332.52890
Overall Steps per Second: 9024.19606
Timestep Collection Time: 2.14310
Timestep Consumption Time: 3.39800
PPO Batch Consumption Time: 0.89936
Total Iteration Time: 5.54110
Cumulative Model Updates: 714
Cumulative Timesteps: 11958176
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00058
Policy Entropy: 4.49953
Value Function Loss: 0.00545
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11502
Value Function Update Magnitude: 0.21541
Collected Steps per Second: 24476.85178
Overall Steps per Second: 9157.15073
Timestep Collection Time: 2.04291
Timestep Consumption Time: 3.41774
PPO Batch Consumption Time: 0.91309
Total Iteration Time: 5.46065
Cumulative Model Updates: 717
Cumulative Timesteps: 12008180
Timesteps Collected: 50004
--------END ITERATION REPORT--------
Saving checkpoint 12008180...
Checkpoint 12008180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01103
Policy Entropy: 4.49952
Value Function Loss: 0.00349
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11733
Value Function Update Magnitude: 0.19934
Collected Steps per Second: 28280.47856
Overall Steps per Second: 11834.30063
Timestep Collection Time: 1.76857
Timestep Consumption Time: 2.45779
PPO Batch Consumption Time: 0.63843
Total Iteration Time: 4.22636
Cumulative Model Updates: 720
Cumulative Timesteps: 12058196
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.23291
Policy Entropy: 4.49950
Value Function Loss: 0.00296
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10356
Value Function Update Magnitude: 0.16603
Collected Steps per Second: 22881.69054
Overall Steps per Second: 8700.32263
Timestep Collection Time: 2.18603
Timestep Consumption Time: 3.56318
PPO Batch Consumption Time: 0.89630
Total Iteration Time: 5.74921
Cumulative Model Updates: 723
Cumulative Timesteps: 12108216
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00798
Policy Entropy: 4.49947
Value Function Loss: 0.00266
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09260
Value Function Update Magnitude: 0.16162
Collected Steps per Second: 21761.96430
Overall Steps per Second: 8104.03967
Timestep Collection Time: 2.29906
Timestep Consumption Time: 3.87465
PPO Batch Consumption Time: 1.07370
Total Iteration Time: 6.17371
Cumulative Model Updates: 726
Cumulative Timesteps: 12158248
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.38499
Policy Entropy: 4.49945
Value Function Loss: 0.00414
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09387
Value Function Update Magnitude: 0.16727
Collected Steps per Second: 22542.88399
Overall Steps per Second: 8516.64156
Timestep Collection Time: 2.22012
Timestep Consumption Time: 3.65637
PPO Batch Consumption Time: 1.01538
Total Iteration Time: 5.87649
Cumulative Model Updates: 729
Cumulative Timesteps: 12208296
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17252
Policy Entropy: 4.49943
Value Function Loss: 0.00316
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09066
Value Function Update Magnitude: 0.15911
Collected Steps per Second: 22347.02752
Overall Steps per Second: 8186.78293
Timestep Collection Time: 2.24101
Timestep Consumption Time: 3.87616
PPO Batch Consumption Time: 1.06038
Total Iteration Time: 6.11718
Cumulative Model Updates: 732
Cumulative Timesteps: 12258376
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01337
Policy Entropy: 4.49944
Value Function Loss: 0.00275
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09212
Value Function Update Magnitude: 0.15647
Collected Steps per Second: 21082.64992
Overall Steps per Second: 7964.05832
Timestep Collection Time: 2.37257
Timestep Consumption Time: 3.90815
PPO Batch Consumption Time: 1.09476
Total Iteration Time: 6.28072
Cumulative Model Updates: 735
Cumulative Timesteps: 12308396
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00299
Policy Entropy: 4.49945
Value Function Loss: 0.00287
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08898
Value Function Update Magnitude: 0.15590
Collected Steps per Second: 21170.93890
Overall Steps per Second: 7874.33799
Timestep Collection Time: 2.36324
Timestep Consumption Time: 3.99056
PPO Batch Consumption Time: 1.08841
Total Iteration Time: 6.35380
Cumulative Model Updates: 738
Cumulative Timesteps: 12358428
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02791
Policy Entropy: 4.49947
Value Function Loss: 0.00325
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08738
Value Function Update Magnitude: 0.14638
Collected Steps per Second: 20043.67135
Overall Steps per Second: 7851.35593
Timestep Collection Time: 2.49894
Timestep Consumption Time: 3.88059
PPO Batch Consumption Time: 1.04350
Total Iteration Time: 6.37954
Cumulative Model Updates: 741
Cumulative Timesteps: 12408516
Timesteps Collected: 50088
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00610
Policy Entropy: 4.49949
Value Function Loss: 0.00388
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09327
Value Function Update Magnitude: 0.14587
Collected Steps per Second: 21657.33184
Overall Steps per Second: 8267.24511
Timestep Collection Time: 2.30906
Timestep Consumption Time: 3.73988
PPO Batch Consumption Time: 1.04060
Total Iteration Time: 6.04893
Cumulative Model Updates: 744
Cumulative Timesteps: 12458524
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00197
Policy Entropy: 4.49950
Value Function Loss: 0.00244
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09429
Value Function Update Magnitude: 0.14288
Collected Steps per Second: 21506.37952
Overall Steps per Second: 8085.90831
Timestep Collection Time: 2.32619
Timestep Consumption Time: 3.86087
PPO Batch Consumption Time: 1.05123
Total Iteration Time: 6.18706
Cumulative Model Updates: 747
Cumulative Timesteps: 12508552
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00004
Policy Entropy: 4.49950
Value Function Loss: 0.00144
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08576
Value Function Update Magnitude: 0.13293
Collected Steps per Second: 21545.62535
Overall Steps per Second: 8161.61384
Timestep Collection Time: 2.32251
Timestep Consumption Time: 3.80863
PPO Batch Consumption Time: 1.02581
Total Iteration Time: 6.13114
Cumulative Model Updates: 750
Cumulative Timesteps: 12558592
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17082
Policy Entropy: 4.49949
Value Function Loss: 0.00306
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.10691
Collected Steps per Second: 21557.03897
Overall Steps per Second: 8200.12392
Timestep Collection Time: 2.32073
Timestep Consumption Time: 3.78016
PPO Batch Consumption Time: 1.04943
Total Iteration Time: 6.10088
Cumulative Model Updates: 753
Cumulative Timesteps: 12608620
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00083
Policy Entropy: 4.49948
Value Function Loss: 0.00346
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08232
Value Function Update Magnitude: 0.14360
Collected Steps per Second: 18895.27020
Overall Steps per Second: 7619.91451
Timestep Collection Time: 2.64638
Timestep Consumption Time: 3.91590
PPO Batch Consumption Time: 1.05600
Total Iteration Time: 6.56228
Cumulative Model Updates: 756
Cumulative Timesteps: 12658624
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16466
Policy Entropy: 4.49948
Value Function Loss: 0.00430
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09618
Value Function Update Magnitude: 0.18339
Collected Steps per Second: 21200.24999
Overall Steps per Second: 8014.94893
Timestep Collection Time: 2.35959
Timestep Consumption Time: 3.88174
PPO Batch Consumption Time: 1.07549
Total Iteration Time: 6.24134
Cumulative Model Updates: 759
Cumulative Timesteps: 12708648
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01594
Policy Entropy: 4.49947
Value Function Loss: 0.00232
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09517
Value Function Update Magnitude: 0.18429
Collected Steps per Second: 20855.65880
Overall Steps per Second: 8100.03876
Timestep Collection Time: 2.40012
Timestep Consumption Time: 3.77961
PPO Batch Consumption Time: 1.04699
Total Iteration Time: 6.17972
Cumulative Model Updates: 762
Cumulative Timesteps: 12758704
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13269
Policy Entropy: 4.49947
Value Function Loss: 0.00296
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09120
Value Function Update Magnitude: 0.16714
Collected Steps per Second: 20885.40473
Overall Steps per Second: 7941.32271
Timestep Collection Time: 2.39631
Timestep Consumption Time: 3.90591
PPO Batch Consumption Time: 1.06597
Total Iteration Time: 6.30222
Cumulative Model Updates: 765
Cumulative Timesteps: 12808752
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.35467
Policy Entropy: 4.49948
Value Function Loss: 0.00265
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08740
Value Function Update Magnitude: 0.15385
Collected Steps per Second: 20559.79942
Overall Steps per Second: 7683.03005
Timestep Collection Time: 2.43426
Timestep Consumption Time: 4.07983
PPO Batch Consumption Time: 1.13746
Total Iteration Time: 6.51410
Cumulative Model Updates: 768
Cumulative Timesteps: 12858800
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00845
Policy Entropy: 4.49948
Value Function Loss: 0.00248
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08423
Value Function Update Magnitude: 0.15250
Collected Steps per Second: 26351.56020
Overall Steps per Second: 11230.89624
Timestep Collection Time: 1.89955
Timestep Consumption Time: 2.55744
PPO Batch Consumption Time: 0.63506
Total Iteration Time: 4.45699
Cumulative Model Updates: 771
Cumulative Timesteps: 12908856
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00860
Policy Entropy: 4.49948
Value Function Loss: 0.00284
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08334
Value Function Update Magnitude: 0.15485
Collected Steps per Second: 29109.49205
Overall Steps per Second: 8954.60168
Timestep Collection Time: 1.71820
Timestep Consumption Time: 3.86731
PPO Batch Consumption Time: 1.01337
Total Iteration Time: 5.58551
Cumulative Model Updates: 774
Cumulative Timesteps: 12958872
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00921
Policy Entropy: 4.49948
Value Function Loss: 0.00354
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08571
Value Function Update Magnitude: 0.16310
Collected Steps per Second: 28710.53264
Overall Steps per Second: 11925.59319
Timestep Collection Time: 1.74333
Timestep Consumption Time: 2.45369
PPO Batch Consumption Time: 0.62394
Total Iteration Time: 4.19702
Cumulative Model Updates: 777
Cumulative Timesteps: 13008924
Timesteps Collected: 50052
--------END ITERATION REPORT--------
Saving checkpoint 13008924...
Checkpoint 13008924 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02785
Policy Entropy: 4.49948
Value Function Loss: 0.00344
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09120
Value Function Update Magnitude: 0.16202
Collected Steps per Second: 27769.06277
Overall Steps per Second: 11586.19082
Timestep Collection Time: 1.80172
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.62881
Total Iteration Time: 4.31824
Cumulative Model Updates: 780
Cumulative Timesteps: 13058956
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00315
Policy Entropy: 4.49948
Value Function Loss: 0.00297
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09399
Value Function Update Magnitude: 0.16218
Collected Steps per Second: 29499.25447
Overall Steps per Second: 11868.73586
Timestep Collection Time: 1.69523
Timestep Consumption Time: 2.51819
PPO Batch Consumption Time: 0.64212
Total Iteration Time: 4.21342
Cumulative Model Updates: 783
Cumulative Timesteps: 13108964
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00167
Policy Entropy: 4.49948
Value Function Loss: 0.00310
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09308
Value Function Update Magnitude: 0.16590
Collected Steps per Second: 31063.96490
Overall Steps per Second: 12030.22522
Timestep Collection Time: 1.61177
Timestep Consumption Time: 2.55008
PPO Batch Consumption Time: 0.61797
Total Iteration Time: 4.16185
Cumulative Model Updates: 786
Cumulative Timesteps: 13159032
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00317
Policy Entropy: 4.49946
Value Function Loss: 0.00351
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09267
Value Function Update Magnitude: 0.17665
Collected Steps per Second: 33959.55257
Overall Steps per Second: 12411.50968
Timestep Collection Time: 1.47399
Timestep Consumption Time: 2.55904
PPO Batch Consumption Time: 0.63666
Total Iteration Time: 4.03303
Cumulative Model Updates: 789
Cumulative Timesteps: 13209088
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03650
Policy Entropy: 4.49946
Value Function Loss: 0.00439
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09881
Value Function Update Magnitude: 0.17702
Collected Steps per Second: 26013.29847
Overall Steps per Second: 11145.00437
Timestep Collection Time: 1.92302
Timestep Consumption Time: 2.56545
PPO Batch Consumption Time: 0.65001
Total Iteration Time: 4.48847
Cumulative Model Updates: 792
Cumulative Timesteps: 13259112
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00094
Policy Entropy: 4.49945
Value Function Loss: 0.00350
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10346
Value Function Update Magnitude: 0.18080
Collected Steps per Second: 30194.89754
Overall Steps per Second: 11878.89611
Timestep Collection Time: 1.65750
Timestep Consumption Time: 2.55569
PPO Batch Consumption Time: 0.63474
Total Iteration Time: 4.21319
Cumulative Model Updates: 795
Cumulative Timesteps: 13309160
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03031
Policy Entropy: 4.49944
Value Function Loss: 0.00411
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10506
Value Function Update Magnitude: 0.17715
Collected Steps per Second: 28706.82509
Overall Steps per Second: 11808.12422
Timestep Collection Time: 1.74244
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.63676
Total Iteration Time: 4.23607
Cumulative Model Updates: 798
Cumulative Timesteps: 13359180
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00270
Policy Entropy: 4.49944
Value Function Loss: 0.00364
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10260
Value Function Update Magnitude: 0.18975
Collected Steps per Second: 31391.75319
Overall Steps per Second: 12233.53193
Timestep Collection Time: 1.59354
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.65270
Total Iteration Time: 4.08909
Cumulative Model Updates: 801
Cumulative Timesteps: 13409204
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00032
Policy Entropy: 4.49945
Value Function Loss: 0.00317
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10333
Value Function Update Magnitude: 0.18542
Collected Steps per Second: 29942.02286
Overall Steps per Second: 11508.28787
Timestep Collection Time: 1.67150
Timestep Consumption Time: 2.67737
PPO Batch Consumption Time: 0.66582
Total Iteration Time: 4.34887
Cumulative Model Updates: 804
Cumulative Timesteps: 13459252
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01327
Policy Entropy: 4.49947
Value Function Loss: 0.00528
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10120
Value Function Update Magnitude: 0.20297
Collected Steps per Second: 29817.73368
Overall Steps per Second: 12051.64097
Timestep Collection Time: 1.67699
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.62980
Total Iteration Time: 4.14914
Cumulative Model Updates: 807
Cumulative Timesteps: 13509256
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.34349
Policy Entropy: 4.49947
Value Function Loss: 0.00522
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10191
Value Function Update Magnitude: 0.17733
Collected Steps per Second: 27933.10009
Overall Steps per Second: 11281.98978
Timestep Collection Time: 1.79099
Timestep Consumption Time: 2.64333
PPO Batch Consumption Time: 0.65586
Total Iteration Time: 4.43432
Cumulative Model Updates: 810
Cumulative Timesteps: 13559284
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01257
Policy Entropy: 4.49947
Value Function Loss: 0.00544
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11032
Value Function Update Magnitude: 0.17908
Collected Steps per Second: 31593.75547
Overall Steps per Second: 12145.90483
Timestep Collection Time: 1.58373
Timestep Consumption Time: 2.53585
PPO Batch Consumption Time: 0.63801
Total Iteration Time: 4.11958
Cumulative Model Updates: 813
Cumulative Timesteps: 13609320
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00071
Policy Entropy: 4.49945
Value Function Loss: 0.00321
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10726
Value Function Update Magnitude: 0.17525
Collected Steps per Second: 31992.12577
Overall Steps per Second: 12459.68668
Timestep Collection Time: 1.56313
Timestep Consumption Time: 2.45045
PPO Batch Consumption Time: 0.63434
Total Iteration Time: 4.01358
Cumulative Model Updates: 816
Cumulative Timesteps: 13659328
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26203
Policy Entropy: 4.49943
Value Function Loss: 0.00304
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09973
Value Function Update Magnitude: 0.15967
Collected Steps per Second: 31692.56346
Overall Steps per Second: 12053.68950
Timestep Collection Time: 1.57841
Timestep Consumption Time: 2.57168
PPO Batch Consumption Time: 0.62768
Total Iteration Time: 4.15010
Cumulative Model Updates: 819
Cumulative Timesteps: 13709352
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00965
Policy Entropy: 4.49944
Value Function Loss: 0.00345
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09308
Value Function Update Magnitude: 0.14111
Collected Steps per Second: 34294.85342
Overall Steps per Second: 13093.74922
Timestep Collection Time: 1.45888
Timestep Consumption Time: 2.36218
PPO Batch Consumption Time: 0.61417
Total Iteration Time: 3.82106
Cumulative Model Updates: 822
Cumulative Timesteps: 13759384
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01165
Policy Entropy: 4.49946
Value Function Loss: 0.00255
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09259
Value Function Update Magnitude: 0.13443
Collected Steps per Second: 29985.38122
Overall Steps per Second: 11793.92557
Timestep Collection Time: 1.66828
Timestep Consumption Time: 2.57323
PPO Batch Consumption Time: 0.62574
Total Iteration Time: 4.24151
Cumulative Model Updates: 825
Cumulative Timesteps: 13809408
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05312
Policy Entropy: 4.49948
Value Function Loss: 0.00350
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08697
Value Function Update Magnitude: 0.12302
Collected Steps per Second: 33212.50884
Overall Steps per Second: 12510.70459
Timestep Collection Time: 1.50594
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.62938
Total Iteration Time: 3.99786
Cumulative Model Updates: 828
Cumulative Timesteps: 13859424
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00488
Policy Entropy: 4.49950
Value Function Loss: 0.00237
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08349
Value Function Update Magnitude: 0.11659
Collected Steps per Second: 36193.23346
Overall Steps per Second: 13406.51347
Timestep Collection Time: 1.38258
Timestep Consumption Time: 2.34994
PPO Batch Consumption Time: 0.61501
Total Iteration Time: 3.73251
Cumulative Model Updates: 831
Cumulative Timesteps: 13909464
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22816
Policy Entropy: 4.49951
Value Function Loss: 0.00288
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08504
Value Function Update Magnitude: 0.12067
Collected Steps per Second: 31750.98436
Overall Steps per Second: 12287.11076
Timestep Collection Time: 1.57475
Timestep Consumption Time: 2.49455
PPO Batch Consumption Time: 0.60676
Total Iteration Time: 4.06930
Cumulative Model Updates: 834
Cumulative Timesteps: 13959464
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02286
Policy Entropy: 4.49952
Value Function Loss: 0.00190
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07906
Value Function Update Magnitude: 0.12056
Collected Steps per Second: 33509.57840
Overall Steps per Second: 12376.79905
Timestep Collection Time: 1.49414
Timestep Consumption Time: 2.55117
PPO Batch Consumption Time: 0.63653
Total Iteration Time: 4.04531
Cumulative Model Updates: 837
Cumulative Timesteps: 14009532
Timesteps Collected: 50068
--------END ITERATION REPORT--------
Saving checkpoint 14009532...
Checkpoint 14009532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02603
Policy Entropy: 4.49951
Value Function Loss: 0.00405
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08257
Value Function Update Magnitude: 0.13959
Collected Steps per Second: 32907.93938
Overall Steps per Second: 12721.73415
Timestep Collection Time: 1.52000
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.60817
Total Iteration Time: 3.93185
Cumulative Model Updates: 840
Cumulative Timesteps: 14059552
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12382
Policy Entropy: 4.49949
Value Function Loss: 0.00555
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09488
Value Function Update Magnitude: 0.16696
Collected Steps per Second: 33519.06556
Overall Steps per Second: 12656.83793
Timestep Collection Time: 1.49384
Timestep Consumption Time: 2.46229
PPO Batch Consumption Time: 0.60770
Total Iteration Time: 3.95612
Cumulative Model Updates: 843
Cumulative Timesteps: 14109624
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06275
Policy Entropy: 4.49946
Value Function Loss: 0.00557
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11219
Value Function Update Magnitude: 0.18672
Collected Steps per Second: 36988.19970
Overall Steps per Second: 13250.43149
Timestep Collection Time: 1.35297
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.61200
Total Iteration Time: 3.77678
Cumulative Model Updates: 846
Cumulative Timesteps: 14159668
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00096
Policy Entropy: 4.49941
Value Function Loss: 0.00334
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11592
Value Function Update Magnitude: 0.18861
Collected Steps per Second: 34673.08657
Overall Steps per Second: 13022.08057
Timestep Collection Time: 1.44366
Timestep Consumption Time: 2.40028
PPO Batch Consumption Time: 0.63345
Total Iteration Time: 3.84393
Cumulative Model Updates: 849
Cumulative Timesteps: 14209724
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06947
Policy Entropy: 4.49935
Value Function Loss: 0.00256
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10813
Value Function Update Magnitude: 0.17469
Collected Steps per Second: 31569.87857
Overall Steps per Second: 11913.20103
Timestep Collection Time: 1.58531
Timestep Consumption Time: 2.61575
PPO Batch Consumption Time: 0.64112
Total Iteration Time: 4.20105
Cumulative Model Updates: 852
Cumulative Timesteps: 14259772
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00068
Policy Entropy: 4.49931
Value Function Loss: 0.00266
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09658
Value Function Update Magnitude: 0.16237
Collected Steps per Second: 29227.76264
Overall Steps per Second: 11629.16814
Timestep Collection Time: 1.71084
Timestep Consumption Time: 2.58904
PPO Batch Consumption Time: 0.67016
Total Iteration Time: 4.29988
Cumulative Model Updates: 855
Cumulative Timesteps: 14309776
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01120
Policy Entropy: 4.49932
Value Function Loss: 0.00264
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09680
Value Function Update Magnitude: 0.15786
Collected Steps per Second: 28801.73964
Overall Steps per Second: 11606.75466
Timestep Collection Time: 1.73851
Timestep Consumption Time: 2.57553
PPO Batch Consumption Time: 0.64807
Total Iteration Time: 4.31404
Cumulative Model Updates: 858
Cumulative Timesteps: 14359848
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25920
Policy Entropy: 4.49936
Value Function Loss: 0.00280
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09971
Value Function Update Magnitude: 0.16343
Collected Steps per Second: 32309.73543
Overall Steps per Second: 12007.37118
Timestep Collection Time: 1.54764
Timestep Consumption Time: 2.61680
PPO Batch Consumption Time: 0.64841
Total Iteration Time: 4.16444
Cumulative Model Updates: 861
Cumulative Timesteps: 14409852
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02800
Policy Entropy: 4.49943
Value Function Loss: 0.00394
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09650
Value Function Update Magnitude: 0.15993
Collected Steps per Second: 30443.68511
Overall Steps per Second: 12220.26490
Timestep Collection Time: 1.64238
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.61824
Total Iteration Time: 4.09156
Cumulative Model Updates: 864
Cumulative Timesteps: 14459852
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01824
Policy Entropy: 4.49948
Value Function Loss: 0.00367
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10022
Value Function Update Magnitude: 0.17748
Collected Steps per Second: 34393.07130
Overall Steps per Second: 12486.25581
Timestep Collection Time: 1.45460
Timestep Consumption Time: 2.55205
PPO Batch Consumption Time: 0.65055
Total Iteration Time: 4.00665
Cumulative Model Updates: 867
Cumulative Timesteps: 14509880
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01515
Policy Entropy: 4.49951
Value Function Loss: 0.00514
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10480
Value Function Update Magnitude: 0.18645
Collected Steps per Second: 32838.56951
Overall Steps per Second: 12353.27257
Timestep Collection Time: 1.52431
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.64007
Total Iteration Time: 4.05204
Cumulative Model Updates: 870
Cumulative Timesteps: 14559936
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06707
Policy Entropy: 4.49951
Value Function Loss: 0.00647
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10609
Value Function Update Magnitude: 0.18323
Collected Steps per Second: 35573.78293
Overall Steps per Second: 13244.14283
Timestep Collection Time: 1.40699
Timestep Consumption Time: 2.37219
PPO Batch Consumption Time: 0.61687
Total Iteration Time: 3.77918
Cumulative Model Updates: 873
Cumulative Timesteps: 14609988
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11973
Policy Entropy: 4.49950
Value Function Loss: 0.00563
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11240
Value Function Update Magnitude: 0.19780
Collected Steps per Second: 35464.66073
Overall Steps per Second: 12703.37666
Timestep Collection Time: 1.41008
Timestep Consumption Time: 2.52651
PPO Batch Consumption Time: 0.63702
Total Iteration Time: 3.93659
Cumulative Model Updates: 876
Cumulative Timesteps: 14659996
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00211
Policy Entropy: 4.49947
Value Function Loss: 0.00385
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.11408
Value Function Update Magnitude: 0.19721
Collected Steps per Second: 32742.11797
Overall Steps per Second: 12977.41338
Timestep Collection Time: 1.52818
Timestep Consumption Time: 2.32744
PPO Batch Consumption Time: 0.60812
Total Iteration Time: 3.85562
Cumulative Model Updates: 879
Cumulative Timesteps: 14710032
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07697
Policy Entropy: 4.49944
Value Function Loss: 0.00288
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10300
Value Function Update Magnitude: 0.17884
Collected Steps per Second: 36539.30437
Overall Steps per Second: 13416.75791
Timestep Collection Time: 1.36894
Timestep Consumption Time: 2.35924
PPO Batch Consumption Time: 0.61357
Total Iteration Time: 3.72817
Cumulative Model Updates: 882
Cumulative Timesteps: 14760052
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01682
Policy Entropy: 4.49940
Value Function Loss: 0.00279
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09396
Value Function Update Magnitude: 0.16317
Collected Steps per Second: 34878.31851
Overall Steps per Second: 13061.99552
Timestep Collection Time: 1.43436
Timestep Consumption Time: 2.39568
PPO Batch Consumption Time: 0.60875
Total Iteration Time: 3.83004
Cumulative Model Updates: 885
Cumulative Timesteps: 14810080
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17336
Policy Entropy: 4.49937
Value Function Loss: 0.00351
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09119
Value Function Update Magnitude: 0.16295
Collected Steps per Second: 34223.44885
Overall Steps per Second: 12864.41004
Timestep Collection Time: 1.46239
Timestep Consumption Time: 2.42803
PPO Batch Consumption Time: 0.62239
Total Iteration Time: 3.89042
Cumulative Model Updates: 888
Cumulative Timesteps: 14860128
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01020
Policy Entropy: 4.49936
Value Function Loss: 0.00273
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08868
Value Function Update Magnitude: 0.15148
Collected Steps per Second: 32508.27015
Overall Steps per Second: 12412.97147
Timestep Collection Time: 1.53832
Timestep Consumption Time: 2.49037
PPO Batch Consumption Time: 0.61677
Total Iteration Time: 4.02869
Cumulative Model Updates: 891
Cumulative Timesteps: 14910136
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00009
Policy Entropy: 4.49938
Value Function Loss: 0.00242
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08809
Value Function Update Magnitude: 0.16041
Collected Steps per Second: 35123.52522
Overall Steps per Second: 12218.00363
Timestep Collection Time: 1.42378
Timestep Consumption Time: 2.66920
PPO Batch Consumption Time: 0.68298
Total Iteration Time: 4.09298
Cumulative Model Updates: 894
Cumulative Timesteps: 14960144
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04229
Policy Entropy: 4.49939
Value Function Loss: 0.00191
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08247
Value Function Update Magnitude: 0.13906
Collected Steps per Second: 30217.88067
Overall Steps per Second: 11958.40084
Timestep Collection Time: 1.65597
Timestep Consumption Time: 2.52853
PPO Batch Consumption Time: 0.65927
Total Iteration Time: 4.18451
Cumulative Model Updates: 897
Cumulative Timesteps: 15010184
Timesteps Collected: 50040
--------END ITERATION REPORT--------
Saving checkpoint 15010184...
Checkpoint 15010184 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00060
Policy Entropy: 4.49940
Value Function Loss: 0.00224
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.13415
Collected Steps per Second: 31069.65492
Overall Steps per Second: 12205.72978
Timestep Collection Time: 1.60993
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.61361
Total Iteration Time: 4.09808
Cumulative Model Updates: 900
Cumulative Timesteps: 15060204
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17946
Policy Entropy: 4.49942
Value Function Loss: 0.00217
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07988
Value Function Update Magnitude: 0.13753
Collected Steps per Second: 35936.18019
Overall Steps per Second: 13351.82935
Timestep Collection Time: 1.39325
Timestep Consumption Time: 2.35665
PPO Batch Consumption Time: 0.61431
Total Iteration Time: 3.74990
Cumulative Model Updates: 903
Cumulative Timesteps: 15110272
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18713
Policy Entropy: 4.49945
Value Function Loss: 0.00309
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08255
Value Function Update Magnitude: 0.14978
Collected Steps per Second: 35998.33352
Overall Steps per Second: 13158.22381
Timestep Collection Time: 1.38973
Timestep Consumption Time: 2.41230
PPO Batch Consumption Time: 0.61442
Total Iteration Time: 3.80203
Cumulative Model Updates: 906
Cumulative Timesteps: 15160300
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00040
Policy Entropy: 4.49948
Value Function Loss: 0.00393
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08492
Value Function Update Magnitude: 0.15088
Collected Steps per Second: 36831.38746
Overall Steps per Second: 12929.54103
Timestep Collection Time: 1.35786
Timestep Consumption Time: 2.51018
PPO Batch Consumption Time: 0.63296
Total Iteration Time: 3.86804
Cumulative Model Updates: 909
Cumulative Timesteps: 15210312
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37192
Policy Entropy: 4.49950
Value Function Loss: 0.00359
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09301
Value Function Update Magnitude: 0.16187
Collected Steps per Second: 34515.43083
Overall Steps per Second: 13041.18248
Timestep Collection Time: 1.44863
Timestep Consumption Time: 2.38538
PPO Batch Consumption Time: 0.61955
Total Iteration Time: 3.83401
Cumulative Model Updates: 912
Cumulative Timesteps: 15260312
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00746
Policy Entropy: 4.49950
Value Function Loss: 0.00251
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09338
Value Function Update Magnitude: 0.16081
Collected Steps per Second: 34357.83674
Overall Steps per Second: 12746.95554
Timestep Collection Time: 1.45585
Timestep Consumption Time: 2.46822
PPO Batch Consumption Time: 0.62567
Total Iteration Time: 3.92407
Cumulative Model Updates: 915
Cumulative Timesteps: 15310332
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00128
Policy Entropy: 4.49949
Value Function Loss: 0.00160
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08188
Value Function Update Magnitude: 0.14290
Collected Steps per Second: 37415.93796
Overall Steps per Second: 12986.65966
Timestep Collection Time: 1.33772
Timestep Consumption Time: 2.51639
PPO Batch Consumption Time: 0.64627
Total Iteration Time: 3.85411
Cumulative Model Updates: 918
Cumulative Timesteps: 15360384
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01900
Policy Entropy: 4.49949
Value Function Loss: 0.00267
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07508
Value Function Update Magnitude: 0.12602
Collected Steps per Second: 35542.99028
Overall Steps per Second: 12883.70074
Timestep Collection Time: 1.40787
Timestep Consumption Time: 2.47610
PPO Batch Consumption Time: 0.63815
Total Iteration Time: 3.88398
Cumulative Model Updates: 921
Cumulative Timesteps: 15410424
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00408
Policy Entropy: 4.49949
Value Function Loss: 0.00222
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08230
Value Function Update Magnitude: 0.14779
Collected Steps per Second: 36446.56206
Overall Steps per Second: 12777.45801
Timestep Collection Time: 1.37286
Timestep Consumption Time: 2.54310
PPO Batch Consumption Time: 0.65486
Total Iteration Time: 3.91596
Cumulative Model Updates: 924
Cumulative Timesteps: 15460460
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01122
Policy Entropy: 4.49951
Value Function Loss: 0.00256
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08852
Value Function Update Magnitude: 0.15223
Collected Steps per Second: 36288.46349
Overall Steps per Second: 13273.70771
Timestep Collection Time: 1.37829
Timestep Consumption Time: 2.38976
PPO Batch Consumption Time: 0.61695
Total Iteration Time: 3.76805
Cumulative Model Updates: 927
Cumulative Timesteps: 15510476
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02234
Policy Entropy: 4.49953
Value Function Loss: 0.00277
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08381
Value Function Update Magnitude: 0.12557
Collected Steps per Second: 33493.35624
Overall Steps per Second: 12320.43306
Timestep Collection Time: 1.49391
Timestep Consumption Time: 2.56731
PPO Batch Consumption Time: 0.65456
Total Iteration Time: 4.06122
Cumulative Model Updates: 930
Cumulative Timesteps: 15560512
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00341
Policy Entropy: 4.49955
Value Function Loss: 0.00264
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08509
Value Function Update Magnitude: 0.13894
Collected Steps per Second: 33923.08596
Overall Steps per Second: 12530.19702
Timestep Collection Time: 1.47557
Timestep Consumption Time: 2.51926
PPO Batch Consumption Time: 0.63692
Total Iteration Time: 3.99483
Cumulative Model Updates: 933
Cumulative Timesteps: 15610568
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00219
Policy Entropy: 4.49956
Value Function Loss: 0.00162
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08514
Value Function Update Magnitude: 0.13118
Collected Steps per Second: 34318.22666
Overall Steps per Second: 12930.31516
Timestep Collection Time: 1.45707
Timestep Consumption Time: 2.41012
PPO Batch Consumption Time: 0.63578
Total Iteration Time: 3.86719
Cumulative Model Updates: 936
Cumulative Timesteps: 15660572
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00917
Policy Entropy: 4.49956
Value Function Loss: 0.00196
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08108
Value Function Update Magnitude: 0.13163
Collected Steps per Second: 35045.16195
Overall Steps per Second: 12634.03636
Timestep Collection Time: 1.42799
Timestep Consumption Time: 2.53306
PPO Batch Consumption Time: 0.64580
Total Iteration Time: 3.96105
Cumulative Model Updates: 939
Cumulative Timesteps: 15710616
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10898
Policy Entropy: 4.49956
Value Function Loss: 0.00324
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08108
Value Function Update Magnitude: 0.14108
Collected Steps per Second: 37699.89296
Overall Steps per Second: 13181.49141
Timestep Collection Time: 1.32690
Timestep Consumption Time: 2.46812
PPO Batch Consumption Time: 0.62725
Total Iteration Time: 3.79502
Cumulative Model Updates: 942
Cumulative Timesteps: 15760640
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00113
Policy Entropy: 4.49956
Value Function Loss: 0.00308
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08680
Value Function Update Magnitude: 0.17321
Collected Steps per Second: 35512.17707
Overall Steps per Second: 12892.97662
Timestep Collection Time: 1.41022
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.65477
Total Iteration Time: 3.88429
Cumulative Model Updates: 945
Cumulative Timesteps: 15810720
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00453
Policy Entropy: 4.49954
Value Function Loss: 0.00270
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09117
Value Function Update Magnitude: 0.15408
Collected Steps per Second: 30280.51169
Overall Steps per Second: 11959.25742
Timestep Collection Time: 1.65176
Timestep Consumption Time: 2.53044
PPO Batch Consumption Time: 0.62872
Total Iteration Time: 4.18220
Cumulative Model Updates: 948
Cumulative Timesteps: 15860736
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00008
Policy Entropy: 4.49952
Value Function Loss: 0.00217
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08652
Value Function Update Magnitude: 0.12893
Collected Steps per Second: 34097.74615
Overall Steps per Second: 12511.11786
Timestep Collection Time: 1.46778
Timestep Consumption Time: 2.53250
PPO Batch Consumption Time: 0.63130
Total Iteration Time: 4.00028
Cumulative Model Updates: 951
Cumulative Timesteps: 15910784
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00208
Policy Entropy: 4.49950
Value Function Loss: 0.00140
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07911
Value Function Update Magnitude: 0.12745
Collected Steps per Second: 26474.70818
Overall Steps per Second: 11501.41935
Timestep Collection Time: 1.88995
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.63118
Total Iteration Time: 4.35042
Cumulative Model Updates: 954
Cumulative Timesteps: 15960820
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00474
Policy Entropy: 4.49949
Value Function Loss: 0.00088
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07086
Value Function Update Magnitude: 0.10277
Collected Steps per Second: 33279.92362
Overall Steps per Second: 12513.40096
Timestep Collection Time: 1.50277
Timestep Consumption Time: 2.49391
PPO Batch Consumption Time: 0.62543
Total Iteration Time: 3.99668
Cumulative Model Updates: 957
Cumulative Timesteps: 16010832
Timesteps Collected: 50012
--------END ITERATION REPORT--------
Saving checkpoint 16010832...
Checkpoint 16010832 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02877
Policy Entropy: 4.49948
Value Function Loss: 0.00269
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.09168
Collected Steps per Second: 36942.89896
Overall Steps per Second: 12650.90029
Timestep Collection Time: 1.35528
Timestep Consumption Time: 2.60238
PPO Batch Consumption Time: 0.63297
Total Iteration Time: 3.95766
Cumulative Model Updates: 960
Cumulative Timesteps: 16060900
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00715
Policy Entropy: 4.49947
Value Function Loss: 0.00271
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07649
Value Function Update Magnitude: 0.08618
Collected Steps per Second: 33767.87509
Overall Steps per Second: 12811.44129
Timestep Collection Time: 1.48153
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.64003
Total Iteration Time: 3.90495
Cumulative Model Updates: 963
Cumulative Timesteps: 16110928
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00156
Policy Entropy: 4.49944
Value Function Loss: 0.00435
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09359
Value Function Update Magnitude: 0.11111
Collected Steps per Second: 30849.23128
Overall Steps per Second: 12209.78563
Timestep Collection Time: 1.62247
Timestep Consumption Time: 2.47686
PPO Batch Consumption Time: 0.61616
Total Iteration Time: 4.09933
Cumulative Model Updates: 966
Cumulative Timesteps: 16160980
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00066
Policy Entropy: 4.49939
Value Function Loss: 0.00234
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09581
Value Function Update Magnitude: 0.13035
Collected Steps per Second: 31436.01757
Overall Steps per Second: 12239.35946
Timestep Collection Time: 1.59130
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.63128
Total Iteration Time: 4.08714
Cumulative Model Updates: 969
Cumulative Timesteps: 16211004
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00252
Policy Entropy: 4.49934
Value Function Loss: 0.00368
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09691
Value Function Update Magnitude: 0.14016
Collected Steps per Second: 33998.43400
Overall Steps per Second: 12945.11390
Timestep Collection Time: 1.47219
Timestep Consumption Time: 2.39429
PPO Batch Consumption Time: 0.62194
Total Iteration Time: 3.86648
Cumulative Model Updates: 972
Cumulative Timesteps: 16261056
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00788
Policy Entropy: 4.49931
Value Function Loss: 0.00293
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09355
Value Function Update Magnitude: 0.14282
Collected Steps per Second: 33470.67011
Overall Steps per Second: 12389.85179
Timestep Collection Time: 1.49456
Timestep Consumption Time: 2.54294
PPO Batch Consumption Time: 0.63847
Total Iteration Time: 4.03750
Cumulative Model Updates: 975
Cumulative Timesteps: 16311080
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16566
Policy Entropy: 4.49933
Value Function Loss: 0.00453
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09930
Value Function Update Magnitude: 0.15653
Collected Steps per Second: 32546.23861
Overall Steps per Second: 12776.39580
Timestep Collection Time: 1.53800
Timestep Consumption Time: 2.37985
PPO Batch Consumption Time: 0.61155
Total Iteration Time: 3.91785
Cumulative Model Updates: 978
Cumulative Timesteps: 16361136
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01060
Policy Entropy: 4.49935
Value Function Loss: 0.00363
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10163
Value Function Update Magnitude: 0.14446
Collected Steps per Second: 33979.62960
Overall Steps per Second: 12662.12986
Timestep Collection Time: 1.47324
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.62299
Total Iteration Time: 3.95352
Cumulative Model Updates: 981
Cumulative Timesteps: 16411196
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25682
Policy Entropy: 4.49938
Value Function Loss: 0.00318
Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10348
Value Function Update Magnitude: 0.14253
Collected Steps per Second: 29384.01825
Overall Steps per Second: 11813.92974
Timestep Collection Time: 1.70310
Timestep Consumption Time: 2.53291
PPO Batch Consumption Time: 0.61715
Total Iteration Time: 4.23602
Cumulative Model Updates: 984
Cumulative Timesteps: 16461240
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00411
Policy Entropy: 4.49939
Value Function Loss: 0.00224
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09693
Value Function Update Magnitude: 0.13769
Collected Steps per Second: 32641.93725
Overall Steps per Second: 12716.56387
Timestep Collection Time: 1.53287
Timestep Consumption Time: 2.40184
PPO Batch Consumption Time: 0.62916
Total Iteration Time: 3.93471
Cumulative Model Updates: 987
Cumulative Timesteps: 16511276
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00044
Policy Entropy: 4.49942
Value Function Loss: 0.00185
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08882
Value Function Update Magnitude: 0.13589
Collected Steps per Second: 28013.26093
Overall Steps per Second: 11659.27255
Timestep Collection Time: 1.78615
Timestep Consumption Time: 2.50537
PPO Batch Consumption Time: 0.61328
Total Iteration Time: 4.29152
Cumulative Model Updates: 990
Cumulative Timesteps: 16561312
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01172
Policy Entropy: 4.49943
Value Function Loss: 0.00162
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08201
Value Function Update Magnitude: 0.12874
Collected Steps per Second: 34669.38439
Overall Steps per Second: 12982.68874
Timestep Collection Time: 1.44300
Timestep Consumption Time: 2.41044
PPO Batch Consumption Time: 0.61599
Total Iteration Time: 3.85344
Cumulative Model Updates: 993
Cumulative Timesteps: 16611340
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01424
Policy Entropy: 4.49946
Value Function Loss: 0.00145
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07807
Value Function Update Magnitude: 0.11920
Collected Steps per Second: 31733.14112
Overall Steps per Second: 12324.95729
Timestep Collection Time: 1.57703
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.63197
Total Iteration Time: 4.06038
Cumulative Model Updates: 996
Cumulative Timesteps: 16661384
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.35096
Policy Entropy: 4.49948
Value Function Loss: 0.00147
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07452
Value Function Update Magnitude: 0.11071
Collected Steps per Second: 33774.96104
Overall Steps per Second: 12464.48116
Timestep Collection Time: 1.48157
Timestep Consumption Time: 2.53304
PPO Batch Consumption Time: 0.62577
Total Iteration Time: 4.01461
Cumulative Model Updates: 999
Cumulative Timesteps: 16711424
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00174
Policy Entropy: 4.49951
Value Function Loss: 0.00204
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07239
Value Function Update Magnitude: 0.11173
Collected Steps per Second: 31856.08824
Overall Steps per Second: 12619.54197
Timestep Collection Time: 1.57006
Timestep Consumption Time: 2.39332
PPO Batch Consumption Time: 0.61085
Total Iteration Time: 3.96338
Cumulative Model Updates: 1002
Cumulative Timesteps: 16761440
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02107
Policy Entropy: 4.49952
Value Function Loss: 0.00177
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.11201
Collected Steps per Second: 33922.78507
Overall Steps per Second: 12661.98757
Timestep Collection Time: 1.47405
Timestep Consumption Time: 2.47509
PPO Batch Consumption Time: 0.61922
Total Iteration Time: 3.94914
Cumulative Model Updates: 1005
Cumulative Timesteps: 16811444
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01249
Policy Entropy: 4.49953
Value Function Loss: 0.00111
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07058
Value Function Update Magnitude: 0.11419
Collected Steps per Second: 32548.63295
Overall Steps per Second: 12576.94098
Timestep Collection Time: 1.53665
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.61190
Total Iteration Time: 3.97680
Cumulative Model Updates: 1008
Cumulative Timesteps: 16861460
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00244
Policy Entropy: 4.49953
Value Function Loss: 0.00229
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.10093
Collected Steps per Second: 35339.60925
Overall Steps per Second: 13243.26727
Timestep Collection Time: 1.41484
Timestep Consumption Time: 2.36066
PPO Batch Consumption Time: 0.61234
Total Iteration Time: 3.77550
Cumulative Model Updates: 1011
Cumulative Timesteps: 16911460
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00299
Policy Entropy: 4.49954
Value Function Loss: 0.00361
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.10851
Collected Steps per Second: 36373.65384
Overall Steps per Second: 13142.86973
Timestep Collection Time: 1.37594
Timestep Consumption Time: 2.43206
PPO Batch Consumption Time: 0.61332
Total Iteration Time: 3.80800
Cumulative Model Updates: 1014
Cumulative Timesteps: 16961508
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00429
Policy Entropy: 4.49954
Value Function Loss: 0.00316
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08378
Value Function Update Magnitude: 0.13514
Collected Steps per Second: 34803.78446
Overall Steps per Second: 13071.42573
Timestep Collection Time: 1.43720
Timestep Consumption Time: 2.38947
PPO Batch Consumption Time: 0.61698
Total Iteration Time: 3.82667
Cumulative Model Updates: 1017
Cumulative Timesteps: 17011528
Timesteps Collected: 50020
--------END ITERATION REPORT--------
Saving checkpoint 17011528...
Checkpoint 17011528 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06682
Policy Entropy: 4.49954
Value Function Loss: 0.00167
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08477
Value Function Update Magnitude: 0.13948
Collected Steps per Second: 33826.94829
Overall Steps per Second: 12332.87600
Timestep Collection Time: 1.47965
Timestep Consumption Time: 2.57877
PPO Batch Consumption Time: 0.63730
Total Iteration Time: 4.05842
Cumulative Model Updates: 1020
Cumulative Timesteps: 17061580
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00099
Policy Entropy: 4.49954
Value Function Loss: 0.00057
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07097
Value Function Update Magnitude: 0.11609
Collected Steps per Second: 36135.03112
Overall Steps per Second: 12890.37281
Timestep Collection Time: 1.38403
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.63040
Total Iteration Time: 3.87979
Cumulative Model Updates: 1023
Cumulative Timesteps: 17111592
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21700
Policy Entropy: 4.49953
Value Function Loss: 0.00225
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.10948
Collected Steps per Second: 33463.75358
Overall Steps per Second: 12822.66650
Timestep Collection Time: 1.49487
Timestep Consumption Time: 2.40635
PPO Batch Consumption Time: 0.62235
Total Iteration Time: 3.90122
Cumulative Model Updates: 1026
Cumulative Timesteps: 17161616
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01647
Policy Entropy: 4.49953
Value Function Loss: 0.00486
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07051
Value Function Update Magnitude: 0.12211
Collected Steps per Second: 34899.06315
Overall Steps per Second: 12908.85068
Timestep Collection Time: 1.43373
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.62127
Total Iteration Time: 3.87610
Cumulative Model Updates: 1029
Cumulative Timesteps: 17211652
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01307
Policy Entropy: 4.49953
Value Function Loss: 0.00499
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09389
Value Function Update Magnitude: 0.15551
Collected Steps per Second: 38130.75558
Overall Steps per Second: 13266.61804
Timestep Collection Time: 1.31149
Timestep Consumption Time: 2.45797
PPO Batch Consumption Time: 0.62204
Total Iteration Time: 3.76946
Cumulative Model Updates: 1032
Cumulative Timesteps: 17261660
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00625
Policy Entropy: 4.49952
Value Function Loss: 0.00376
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10762
Value Function Update Magnitude: 0.17054
Collected Steps per Second: 33879.98527
Overall Steps per Second: 12673.69732
Timestep Collection Time: 1.47580
Timestep Consumption Time: 2.46938
PPO Batch Consumption Time: 0.64425
Total Iteration Time: 3.94518
Cumulative Model Updates: 1035
Cumulative Timesteps: 17311660
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00859
Policy Entropy: 4.49950
Value Function Loss: 0.00289
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09881
Value Function Update Magnitude: 0.14751
Collected Steps per Second: 34695.09893
Overall Steps per Second: 12840.69018
Timestep Collection Time: 1.44228
Timestep Consumption Time: 2.45471
PPO Batch Consumption Time: 0.62018
Total Iteration Time: 3.89699
Cumulative Model Updates: 1038
Cumulative Timesteps: 17361700
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01141
Policy Entropy: 4.49949
Value Function Loss: 0.00263
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09133
Value Function Update Magnitude: 0.14561
Collected Steps per Second: 34867.54132
Overall Steps per Second: 12579.40339
Timestep Collection Time: 1.43503
Timestep Consumption Time: 2.54258
PPO Batch Consumption Time: 0.63207
Total Iteration Time: 3.97761
Cumulative Model Updates: 1041
Cumulative Timesteps: 17411736
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00348
Policy Entropy: 4.49947
Value Function Loss: 0.00199
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08531
Value Function Update Magnitude: 0.13791
Collected Steps per Second: 34740.05422
Overall Steps per Second: 13177.37817
Timestep Collection Time: 1.44110
Timestep Consumption Time: 2.35814
PPO Batch Consumption Time: 0.61685
Total Iteration Time: 3.79924
Cumulative Model Updates: 1044
Cumulative Timesteps: 17461800
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01307
Policy Entropy: 4.49945
Value Function Loss: 0.00114
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07902
Value Function Update Magnitude: 0.13308
Collected Steps per Second: 36644.68646
Overall Steps per Second: 13144.49887
Timestep Collection Time: 1.36620
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.61926
Total Iteration Time: 3.80874
Cumulative Model Updates: 1047
Cumulative Timesteps: 17511864
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17640
Policy Entropy: 4.49943
Value Function Loss: 0.00211
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07024
Value Function Update Magnitude: 0.10506
Collected Steps per Second: 37693.95403
Overall Steps per Second: 13454.87725
Timestep Collection Time: 1.32764
Timestep Consumption Time: 2.39175
PPO Batch Consumption Time: 0.60834
Total Iteration Time: 3.71939
Cumulative Model Updates: 1050
Cumulative Timesteps: 17561908
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00108
Policy Entropy: 4.49942
Value Function Loss: 0.00253
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07304
Value Function Update Magnitude: 0.09802
Collected Steps per Second: 32520.85328
Overall Steps per Second: 12976.61581
Timestep Collection Time: 1.53821
Timestep Consumption Time: 2.31672
PPO Batch Consumption Time: 0.60695
Total Iteration Time: 3.85493
Cumulative Model Updates: 1053
Cumulative Timesteps: 17611932
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00664
Policy Entropy: 4.49940
Value Function Loss: 0.00271
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07945
Value Function Update Magnitude: 0.11301
Collected Steps per Second: 34786.95562
Overall Steps per Second: 12928.52159
Timestep Collection Time: 1.43767
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.62026
Total Iteration Time: 3.86835
Cumulative Model Updates: 1056
Cumulative Timesteps: 17661944
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03443
Policy Entropy: 4.49935
Value Function Loss: 0.00168
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07825
Value Function Update Magnitude: 0.11956
Collected Steps per Second: 34691.18464
Overall Steps per Second: 13219.41360
Timestep Collection Time: 1.44256
Timestep Consumption Time: 2.34309
PPO Batch Consumption Time: 0.60751
Total Iteration Time: 3.78564
Cumulative Model Updates: 1059
Cumulative Timesteps: 17711988
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26841
Policy Entropy: 4.49931
Value Function Loss: 0.00122
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07095
Value Function Update Magnitude: 0.11270
Collected Steps per Second: 32614.73746
Overall Steps per Second: 12406.91841
Timestep Collection Time: 1.53440
Timestep Consumption Time: 2.49916
PPO Batch Consumption Time: 0.60836
Total Iteration Time: 4.03356
Cumulative Model Updates: 1062
Cumulative Timesteps: 17762032
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02034
Policy Entropy: 4.49929
Value Function Loss: 0.00265
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06791
Value Function Update Magnitude: 0.10867
Collected Steps per Second: 34695.18809
Overall Steps per Second: 12772.94188
Timestep Collection Time: 1.44274
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.60868
Total Iteration Time: 3.91891
Cumulative Model Updates: 1065
Cumulative Timesteps: 17812088
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02377
Policy Entropy: 4.49928
Value Function Loss: 0.00218
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07421
Value Function Update Magnitude: 0.11309
Collected Steps per Second: 33684.28860
Overall Steps per Second: 12983.69276
Timestep Collection Time: 1.48592
Timestep Consumption Time: 2.36907
PPO Batch Consumption Time: 0.61430
Total Iteration Time: 3.85499
Cumulative Model Updates: 1068
Cumulative Timesteps: 17862140
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00400
Policy Entropy: 4.49929
Value Function Loss: 0.00334
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08417
Value Function Update Magnitude: 0.11435
Collected Steps per Second: 33833.63823
Overall Steps per Second: 12205.75648
Timestep Collection Time: 1.47900
Timestep Consumption Time: 2.62070
PPO Batch Consumption Time: 0.65632
Total Iteration Time: 4.09970
Cumulative Model Updates: 1071
Cumulative Timesteps: 17912180
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00293
Policy Entropy: 4.49932
Value Function Loss: 0.00185
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08450
Value Function Update Magnitude: 0.11449
Collected Steps per Second: 26759.44319
Overall Steps per Second: 11150.48210
Timestep Collection Time: 1.86910
Timestep Consumption Time: 2.61645
PPO Batch Consumption Time: 0.63411
Total Iteration Time: 4.48555
Cumulative Model Updates: 1074
Cumulative Timesteps: 17962196
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04959
Policy Entropy: 4.49935
Value Function Loss: 0.00272
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08578
Value Function Update Magnitude: 0.12467
Collected Steps per Second: 29727.96457
Overall Steps per Second: 12342.59632
Timestep Collection Time: 1.68394
Timestep Consumption Time: 2.37194
PPO Batch Consumption Time: 0.61006
Total Iteration Time: 4.05587
Cumulative Model Updates: 1077
Cumulative Timesteps: 18012256
Timesteps Collected: 50060
--------END ITERATION REPORT--------
Saving checkpoint 18012256...
Checkpoint 18012256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00013
Policy Entropy: 4.49939
Value Function Loss: 0.00204
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07977
Value Function Update Magnitude: 0.12960
Collected Steps per Second: 34350.16769
Overall Steps per Second: 12419.20376
Timestep Collection Time: 1.45641
Timestep Consumption Time: 2.57187
PPO Batch Consumption Time: 0.65061
Total Iteration Time: 4.02828
Cumulative Model Updates: 1080
Cumulative Timesteps: 18062284
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01096
Policy Entropy: 4.49942
Value Function Loss: 0.00240
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07805
Value Function Update Magnitude: 0.13373
Collected Steps per Second: 34371.62087
Overall Steps per Second: 12705.67774
Timestep Collection Time: 1.45574
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.65029
Total Iteration Time: 3.93808
Cumulative Model Updates: 1083
Cumulative Timesteps: 18112320
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00115
Policy Entropy: 4.49945
Value Function Loss: 0.00127
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07819
Value Function Update Magnitude: 0.13308
Collected Steps per Second: 32324.34338
Overall Steps per Second: 12527.33559
Timestep Collection Time: 1.54707
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.61534
Total Iteration Time: 3.99191
Cumulative Model Updates: 1086
Cumulative Timesteps: 18162328
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00621
Policy Entropy: 4.49949
Value Function Loss: 0.00284
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.13097
Collected Steps per Second: 38129.67360
Overall Steps per Second: 13329.38613
Timestep Collection Time: 1.31278
Timestep Consumption Time: 2.44253
PPO Batch Consumption Time: 0.62633
Total Iteration Time: 3.75531
Cumulative Model Updates: 1089
Cumulative Timesteps: 18212384
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16539
Policy Entropy: 4.49950
Value Function Loss: 0.00277
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07733
Value Function Update Magnitude: 0.12912
Collected Steps per Second: 25206.30307
Overall Steps per Second: 11211.58870
Timestep Collection Time: 1.98569
Timestep Consumption Time: 2.47862
PPO Batch Consumption Time: 0.63221
Total Iteration Time: 4.46431
Cumulative Model Updates: 1092
Cumulative Timesteps: 18262436
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02463
Policy Entropy: 4.49950
Value Function Loss: 0.00272
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08515
Value Function Update Magnitude: 0.13033
Collected Steps per Second: 26394.73664
Overall Steps per Second: 11221.04266
Timestep Collection Time: 1.89614
Timestep Consumption Time: 2.56406
PPO Batch Consumption Time: 0.62920
Total Iteration Time: 4.46019
Cumulative Model Updates: 1095
Cumulative Timesteps: 18312484
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00012
Policy Entropy: 4.49948
Value Function Loss: 0.00121
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07920
Value Function Update Magnitude: 0.11861
Collected Steps per Second: 32633.59146
Overall Steps per Second: 12593.51437
Timestep Collection Time: 1.53327
Timestep Consumption Time: 2.43989
PPO Batch Consumption Time: 0.63117
Total Iteration Time: 3.97316
Cumulative Model Updates: 1098
Cumulative Timesteps: 18362520
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00455
Policy Entropy: 4.49946
Value Function Loss: 0.00087
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06772
Value Function Update Magnitude: 0.11333
Collected Steps per Second: 32056.32120
Overall Steps per Second: 12702.84739
Timestep Collection Time: 1.56100
Timestep Consumption Time: 2.37827
PPO Batch Consumption Time: 0.61881
Total Iteration Time: 3.93927
Cumulative Model Updates: 1101
Cumulative Timesteps: 18412560
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04757
Policy Entropy: 4.49947
Value Function Loss: 0.00164
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.09362
Collected Steps per Second: 32741.16691
Overall Steps per Second: 12293.34111
Timestep Collection Time: 1.52908
Timestep Consumption Time: 2.54336
PPO Batch Consumption Time: 0.64055
Total Iteration Time: 4.07245
Cumulative Model Updates: 1104
Cumulative Timesteps: 18462624
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01062
Policy Entropy: 4.49949
Value Function Loss: 0.00136
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.09458
Collected Steps per Second: 31503.19969
Overall Steps per Second: 12149.72108
Timestep Collection Time: 1.58778
Timestep Consumption Time: 2.52919
PPO Batch Consumption Time: 0.65225
Total Iteration Time: 4.11697
Cumulative Model Updates: 1107
Cumulative Timesteps: 18512644
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05027
Policy Entropy: 4.49953
Value Function Loss: 0.00182
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07442
Value Function Update Magnitude: 0.10013
Collected Steps per Second: 31384.70206
Overall Steps per Second: 12325.58111
Timestep Collection Time: 1.59555
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.61333
Total Iteration Time: 4.06277
Cumulative Model Updates: 1110
Cumulative Timesteps: 18562720
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02138
Policy Entropy: 4.49957
Value Function Loss: 0.00300
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.11615
Collected Steps per Second: 34076.27096
Overall Steps per Second: 12774.87956
Timestep Collection Time: 1.46788
Timestep Consumption Time: 2.44761
PPO Batch Consumption Time: 0.63899
Total Iteration Time: 3.91550
Cumulative Model Updates: 1113
Cumulative Timesteps: 18612740
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00331
Policy Entropy: 4.49960
Value Function Loss: 0.00339
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08386
Value Function Update Magnitude: 0.14434
Collected Steps per Second: 33285.69486
Overall Steps per Second: 12523.28701
Timestep Collection Time: 1.50287
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.65518
Total Iteration Time: 3.99448
Cumulative Model Updates: 1116
Cumulative Timesteps: 18662764
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00535
Policy Entropy: 4.49963
Value Function Loss: 0.00275
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09305
Value Function Update Magnitude: 0.15715
Collected Steps per Second: 33472.55228
Overall Steps per Second: 12403.03819
Timestep Collection Time: 1.49496
Timestep Consumption Time: 2.53954
PPO Batch Consumption Time: 0.63158
Total Iteration Time: 4.03450
Cumulative Model Updates: 1119
Cumulative Timesteps: 18712804
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01834
Policy Entropy: 4.49965
Value Function Loss: 0.00162
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09065
Value Function Update Magnitude: 0.14773
Collected Steps per Second: 33785.42432
Overall Steps per Second: 13001.80191
Timestep Collection Time: 1.47993
Timestep Consumption Time: 2.36569
PPO Batch Consumption Time: 0.61963
Total Iteration Time: 3.84562
Cumulative Model Updates: 1122
Cumulative Timesteps: 18762804
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11784
Policy Entropy: 4.49966
Value Function Loss: 0.00205
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07899
Value Function Update Magnitude: 0.12163
Collected Steps per Second: 31381.18398
Overall Steps per Second: 12221.99658
Timestep Collection Time: 1.59331
Timestep Consumption Time: 2.49767
PPO Batch Consumption Time: 0.62397
Total Iteration Time: 4.09098
Cumulative Model Updates: 1125
Cumulative Timesteps: 18812804
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00053
Policy Entropy: 4.49967
Value Function Loss: 0.00144
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07066
Value Function Update Magnitude: 0.11286
Collected Steps per Second: 30925.18107
Overall Steps per Second: 12042.76670
Timestep Collection Time: 1.61823
Timestep Consumption Time: 2.53730
PPO Batch Consumption Time: 0.62537
Total Iteration Time: 4.15552
Cumulative Model Updates: 1128
Cumulative Timesteps: 18862848
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00063
Policy Entropy: 4.49968
Value Function Loss: 0.00172
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.10551
Collected Steps per Second: 35167.79932
Overall Steps per Second: 13268.30537
Timestep Collection Time: 1.42232
Timestep Consumption Time: 2.34756
PPO Batch Consumption Time: 0.61036
Total Iteration Time: 3.76989
Cumulative Model Updates: 1131
Cumulative Timesteps: 18912868
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01502
Policy Entropy: 4.49968
Value Function Loss: 0.00209
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.10616
Collected Steps per Second: 32376.05180
Overall Steps per Second: 11829.61607
Timestep Collection Time: 1.54719
Timestep Consumption Time: 2.68726
PPO Batch Consumption Time: 0.63676
Total Iteration Time: 4.23446
Cumulative Model Updates: 1134
Cumulative Timesteps: 18962960
Timesteps Collected: 50092
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03354
Policy Entropy: 4.49968
Value Function Loss: 0.00213
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.12455
Collected Steps per Second: 34526.65155
Overall Steps per Second: 12936.48960
Timestep Collection Time: 1.44908
Timestep Consumption Time: 2.41843
PPO Batch Consumption Time: 0.61783
Total Iteration Time: 3.86751
Cumulative Model Updates: 1137
Cumulative Timesteps: 19012992
Timesteps Collected: 50032
--------END ITERATION REPORT--------
Saving checkpoint 19012992...
Checkpoint 19012992 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14593
Policy Entropy: 4.49968
Value Function Loss: 0.00268
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.14804
Collected Steps per Second: 33309.06555
Overall Steps per Second: 12755.93966
Timestep Collection Time: 1.50145
Timestep Consumption Time: 2.41923
PPO Batch Consumption Time: 0.61528
Total Iteration Time: 3.92068
Cumulative Model Updates: 1140
Cumulative Timesteps: 19063004
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07450
Policy Entropy: 4.49967
Value Function Loss: 0.00338
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07537
Value Function Update Magnitude: 0.14513
Collected Steps per Second: 33452.15309
Overall Steps per Second: 12790.90789
Timestep Collection Time: 1.49503
Timestep Consumption Time: 2.41493
PPO Batch Consumption Time: 0.61109
Total Iteration Time: 3.90996
Cumulative Model Updates: 1143
Cumulative Timesteps: 19113016
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01832
Policy Entropy: 4.49967
Value Function Loss: 0.00288
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08122
Value Function Update Magnitude: 0.14895
Collected Steps per Second: 34002.73472
Overall Steps per Second: 13006.36346
Timestep Collection Time: 1.47082
Timestep Consumption Time: 2.37437
PPO Batch Consumption Time: 0.61002
Total Iteration Time: 3.84519
Cumulative Model Updates: 1146
Cumulative Timesteps: 19163028
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00769
Policy Entropy: 4.49966
Value Function Loss: 0.00213
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08086
Value Function Update Magnitude: 0.14223
Collected Steps per Second: 36177.56445
Overall Steps per Second: 13481.05708
Timestep Collection Time: 1.38229
Timestep Consumption Time: 2.32721
PPO Batch Consumption Time: 0.60344
Total Iteration Time: 3.70950
Cumulative Model Updates: 1149
Cumulative Timesteps: 19213036
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00008
Policy Entropy: 4.49965
Value Function Loss: 0.00092
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.13580
Collected Steps per Second: 33873.90134
Overall Steps per Second: 12671.91434
Timestep Collection Time: 1.47713
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.61395
Total Iteration Time: 3.94857
Cumulative Model Updates: 1152
Cumulative Timesteps: 19263072
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00048
Policy Entropy: 4.49964
Value Function Loss: 0.00196
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.09717
Collected Steps per Second: 33365.56954
Overall Steps per Second: 13005.55802
Timestep Collection Time: 1.50035
Timestep Consumption Time: 2.34877
PPO Batch Consumption Time: 0.61247
Total Iteration Time: 3.84912
Cumulative Model Updates: 1155
Cumulative Timesteps: 19313132
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01828
Policy Entropy: 4.49964
Value Function Loss: 0.00237
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.10780
Collected Steps per Second: 34186.98260
Overall Steps per Second: 12865.79625
Timestep Collection Time: 1.46407
Timestep Consumption Time: 2.42625
PPO Batch Consumption Time: 0.61547
Total Iteration Time: 3.89031
Cumulative Model Updates: 1158
Cumulative Timesteps: 19363184
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10459
Policy Entropy: 4.49963
Value Function Loss: 0.00232
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07148
Value Function Update Magnitude: 0.11567
Collected Steps per Second: 34878.83014
Overall Steps per Second: 12968.99925
Timestep Collection Time: 1.43525
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.61106
Total Iteration Time: 3.85997
Cumulative Model Updates: 1161
Cumulative Timesteps: 19413244
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00374
Policy Entropy: 4.49962
Value Function Loss: 0.00257
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.13383
Collected Steps per Second: 33188.63999
Overall Steps per Second: 12487.02040
Timestep Collection Time: 1.50702
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.63901
Total Iteration Time: 4.00544
Cumulative Model Updates: 1164
Cumulative Timesteps: 19463260
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16750
Policy Entropy: 4.49962
Value Function Loss: 0.00310
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07767
Value Function Update Magnitude: 0.15214
Collected Steps per Second: 25948.42517
Overall Steps per Second: 10856.23560
Timestep Collection Time: 1.92859
Timestep Consumption Time: 2.68111
PPO Batch Consumption Time: 0.62829
Total Iteration Time: 4.60970
Cumulative Model Updates: 1167
Cumulative Timesteps: 19513304
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00225
Policy Entropy: 4.49961
Value Function Loss: 0.00282
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08555
Value Function Update Magnitude: 0.16020
Collected Steps per Second: 27518.29408
Overall Steps per Second: 11831.05252
Timestep Collection Time: 1.81930
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.60759
Total Iteration Time: 4.23158
Cumulative Model Updates: 1170
Cumulative Timesteps: 19563368
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00887
Policy Entropy: 4.49959
Value Function Loss: 0.00172
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08943
Value Function Update Magnitude: 0.13890
Collected Steps per Second: 34801.64454
Overall Steps per Second: 12991.82801
Timestep Collection Time: 1.43706
Timestep Consumption Time: 2.41244
PPO Batch Consumption Time: 0.60732
Total Iteration Time: 3.84950
Cumulative Model Updates: 1173
Cumulative Timesteps: 19613380
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04501
Policy Entropy: 4.49958
Value Function Loss: 0.00125
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08386
Value Function Update Magnitude: 0.12129
Collected Steps per Second: 31510.54964
Overall Steps per Second: 12116.28148
Timestep Collection Time: 1.58753
Timestep Consumption Time: 2.54113
PPO Batch Consumption Time: 0.62765
Total Iteration Time: 4.12866
Cumulative Model Updates: 1176
Cumulative Timesteps: 19663404
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01803
Policy Entropy: 4.49957
Value Function Loss: 0.00081
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.10800
Collected Steps per Second: 32963.55225
Overall Steps per Second: 12430.30850
Timestep Collection Time: 1.51780
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.64304
Total Iteration Time: 4.02500
Cumulative Model Updates: 1179
Cumulative Timesteps: 19713436
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00750
Policy Entropy: 4.49957
Value Function Loss: 0.00092
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.09812
Collected Steps per Second: 29194.62834
Overall Steps per Second: 12044.66199
Timestep Collection Time: 1.71333
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.61581
Total Iteration Time: 4.15288
Cumulative Model Updates: 1182
Cumulative Timesteps: 19763456
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01659
Policy Entropy: 4.49957
Value Function Loss: 0.00097
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.09419
Collected Steps per Second: 31185.38605
Overall Steps per Second: 12198.78673
Timestep Collection Time: 1.60601
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.63575
Total Iteration Time: 4.10565
Cumulative Model Updates: 1185
Cumulative Timesteps: 19813540
Timesteps Collected: 50084
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01764
Policy Entropy: 4.49957
Value Function Loss: 0.00106
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.08934
Collected Steps per Second: 28613.31889
Overall Steps per Second: 11822.22017
Timestep Collection Time: 1.74912
Timestep Consumption Time: 2.48427
PPO Batch Consumption Time: 0.61134
Total Iteration Time: 4.23338
Cumulative Model Updates: 1188
Cumulative Timesteps: 19863588
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11145
Policy Entropy: 4.49957
Value Function Loss: 0.00244
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.10165
Collected Steps per Second: 36344.71618
Overall Steps per Second: 13009.35392
Timestep Collection Time: 1.37583
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.62555
Total Iteration Time: 3.84370
Cumulative Model Updates: 1191
Cumulative Timesteps: 19913592
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11107
Policy Entropy: 4.49957
Value Function Loss: 0.00237
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06935
Value Function Update Magnitude: 0.11811
Collected Steps per Second: 30784.86184
Overall Steps per Second: 12456.81202
Timestep Collection Time: 1.62482
Timestep Consumption Time: 2.39065
PPO Batch Consumption Time: 0.61051
Total Iteration Time: 4.01547
Cumulative Model Updates: 1194
Cumulative Timesteps: 19963612
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.38336
Policy Entropy: 4.49956
Value Function Loss: 0.00367
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08063
Value Function Update Magnitude: 0.12793
Collected Steps per Second: 34362.23446
Overall Steps per Second: 12932.66601
Timestep Collection Time: 1.45578
Timestep Consumption Time: 2.41225
PPO Batch Consumption Time: 0.61345
Total Iteration Time: 3.86803
Cumulative Model Updates: 1197
Cumulative Timesteps: 20013636
Timesteps Collected: 50024
--------END ITERATION REPORT--------
Saving checkpoint 20013636...
Checkpoint 20013636 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00114
Policy Entropy: 4.49956
Value Function Loss: 0.00226
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08219
Value Function Update Magnitude: 0.13831
Collected Steps per Second: 33705.35775
Overall Steps per Second: 12462.95430
Timestep Collection Time: 1.48463
Timestep Consumption Time: 2.53047
PPO Batch Consumption Time: 0.63001
Total Iteration Time: 4.01510
Cumulative Model Updates: 1200
Cumulative Timesteps: 20063676
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00967
Policy Entropy: 4.49955
Value Function Loss: 0.00280
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08561
Value Function Update Magnitude: 0.14896
Collected Steps per Second: 33724.28012
Overall Steps per Second: 12919.85112
Timestep Collection Time: 1.48380
Timestep Consumption Time: 2.38931
PPO Batch Consumption Time: 0.62183
Total Iteration Time: 3.87311
Cumulative Model Updates: 1203
Cumulative Timesteps: 20113716
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01473
Policy Entropy: 4.49954
Value Function Loss: 0.00104
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08062
Value Function Update Magnitude: 0.13807
Collected Steps per Second: 31286.44467
Overall Steps per Second: 12251.61802
Timestep Collection Time: 1.59980
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.62052
Total Iteration Time: 4.08534
Cumulative Model Updates: 1206
Cumulative Timesteps: 20163768
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02132
Policy Entropy: 4.49954
Value Function Loss: 0.00261
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07753
Value Function Update Magnitude: 0.11248
Collected Steps per Second: 33007.22633
Overall Steps per Second: 12591.00866
Timestep Collection Time: 1.51494
Timestep Consumption Time: 2.45646
PPO Batch Consumption Time: 0.62458
Total Iteration Time: 3.97141
Cumulative Model Updates: 1209
Cumulative Timesteps: 20213772
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01858
Policy Entropy: 4.49954
Value Function Loss: 0.00325
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07900
Value Function Update Magnitude: 0.11725
Collected Steps per Second: 30646.37006
Overall Steps per Second: 12340.59710
Timestep Collection Time: 1.63321
Timestep Consumption Time: 2.42267
PPO Batch Consumption Time: 0.62496
Total Iteration Time: 4.05588
Cumulative Model Updates: 1212
Cumulative Timesteps: 20263824
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00746
Policy Entropy: 4.49955
Value Function Loss: 0.00284
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08918
Value Function Update Magnitude: 0.11869
Collected Steps per Second: 30877.83637
Overall Steps per Second: 11944.52167
Timestep Collection Time: 1.61980
Timestep Consumption Time: 2.56756
PPO Batch Consumption Time: 0.64435
Total Iteration Time: 4.18736
Cumulative Model Updates: 1215
Cumulative Timesteps: 20313840
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01946
Policy Entropy: 4.49956
Value Function Loss: 0.00233
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08794
Value Function Update Magnitude: 0.10464
Collected Steps per Second: 31554.19497
Overall Steps per Second: 12527.06040
Timestep Collection Time: 1.58559
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.61337
Total Iteration Time: 3.99391
Cumulative Model Updates: 1218
Cumulative Timesteps: 20363872
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15312
Policy Entropy: 4.49956
Value Function Loss: 0.00297
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07996
Value Function Update Magnitude: 0.10577
Collected Steps per Second: 33630.90130
Overall Steps per Second: 12501.36899
Timestep Collection Time: 1.48673
Timestep Consumption Time: 2.51283
PPO Batch Consumption Time: 0.60919
Total Iteration Time: 3.99956
Cumulative Model Updates: 1221
Cumulative Timesteps: 20413872
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07463
Policy Entropy: 4.49956
Value Function Loss: 0.00335
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08286
Value Function Update Magnitude: 0.12323
Collected Steps per Second: 33743.80742
Overall Steps per Second: 12683.70223
Timestep Collection Time: 1.48341
Timestep Consumption Time: 2.46307
PPO Batch Consumption Time: 0.60613
Total Iteration Time: 3.94648
Cumulative Model Updates: 1224
Cumulative Timesteps: 20463928
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00482
Policy Entropy: 4.49955
Value Function Loss: 0.00226
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08959
Value Function Update Magnitude: 0.13032
Collected Steps per Second: 34171.91041
Overall Steps per Second: 13068.69179
Timestep Collection Time: 1.46471
Timestep Consumption Time: 2.36520
PPO Batch Consumption Time: 0.61975
Total Iteration Time: 3.82992
Cumulative Model Updates: 1227
Cumulative Timesteps: 20513980
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01326
Policy Entropy: 4.49955
Value Function Loss: 0.00157
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08190
Value Function Update Magnitude: 0.11240
Collected Steps per Second: 35464.09453
Overall Steps per Second: 12900.35693
Timestep Collection Time: 1.40988
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.61350
Total Iteration Time: 3.87586
Cumulative Model Updates: 1230
Cumulative Timesteps: 20563980
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03266
Policy Entropy: 4.49955
Value Function Loss: 0.00145
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.09616
Collected Steps per Second: 36227.79768
Overall Steps per Second: 13208.53423
Timestep Collection Time: 1.38104
Timestep Consumption Time: 2.40682
PPO Batch Consumption Time: 0.61615
Total Iteration Time: 3.78785
Cumulative Model Updates: 1233
Cumulative Timesteps: 20614012
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00016
Policy Entropy: 4.49955
Value Function Loss: 0.00160
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.09457
Collected Steps per Second: 35846.96111
Overall Steps per Second: 13280.31989
Timestep Collection Time: 1.39560
Timestep Consumption Time: 2.37148
PPO Batch Consumption Time: 0.61965
Total Iteration Time: 3.76708
Cumulative Model Updates: 1236
Cumulative Timesteps: 20664040
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01025
Policy Entropy: 4.49955
Value Function Loss: 0.00169
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.11105
Collected Steps per Second: 32223.37539
Overall Steps per Second: 12076.66996
Timestep Collection Time: 1.55328
Timestep Consumption Time: 2.59124
PPO Batch Consumption Time: 0.63967
Total Iteration Time: 4.14452
Cumulative Model Updates: 1239
Cumulative Timesteps: 20714092
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00514
Policy Entropy: 4.49956
Value Function Loss: 0.00147
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06823
Value Function Update Magnitude: 0.09948
Collected Steps per Second: 25446.00790
Overall Steps per Second: 11257.80856
Timestep Collection Time: 1.96715
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.63459
Total Iteration Time: 4.44634
Cumulative Model Updates: 1242
Cumulative Timesteps: 20764148
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01176
Policy Entropy: 4.49956
Value Function Loss: 0.00235
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07416
Value Function Update Magnitude: 0.10356
Collected Steps per Second: 29562.08532
Overall Steps per Second: 11783.22167
Timestep Collection Time: 1.69176
Timestep Consumption Time: 2.55258
PPO Batch Consumption Time: 0.62466
Total Iteration Time: 4.24434
Cumulative Model Updates: 1245
Cumulative Timesteps: 20814160
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00524
Policy Entropy: 4.49957
Value Function Loss: 0.00205
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07794
Value Function Update Magnitude: 0.09902
Collected Steps per Second: 32771.18593
Overall Steps per Second: 12465.49713
Timestep Collection Time: 1.52622
Timestep Consumption Time: 2.48614
PPO Batch Consumption Time: 0.62403
Total Iteration Time: 4.01236
Cumulative Model Updates: 1248
Cumulative Timesteps: 20864176
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22754
Policy Entropy: 4.49957
Value Function Loss: 0.00199
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07626
Value Function Update Magnitude: 0.10799
Collected Steps per Second: 32426.58403
Overall Steps per Second: 12538.76302
Timestep Collection Time: 1.54429
Timestep Consumption Time: 2.44941
PPO Batch Consumption Time: 0.63575
Total Iteration Time: 3.99370
Cumulative Model Updates: 1251
Cumulative Timesteps: 20914252
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02241
Policy Entropy: 4.49956
Value Function Loss: 0.00115
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07177
Value Function Update Magnitude: 0.09592
Collected Steps per Second: 34175.71517
Overall Steps per Second: 12646.22122
Timestep Collection Time: 1.46408
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.63309
Total Iteration Time: 3.95660
Cumulative Model Updates: 1254
Cumulative Timesteps: 20964288
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.24949
Policy Entropy: 4.49955
Value Function Loss: 0.00108
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.09234
Collected Steps per Second: 35245.44768
Overall Steps per Second: 12981.47392
Timestep Collection Time: 1.41908
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.60923
Total Iteration Time: 3.85288
Cumulative Model Updates: 1257
Cumulative Timesteps: 21014304
Timesteps Collected: 50016
--------END ITERATION REPORT--------
Saving checkpoint 21014304...
Checkpoint 21014304 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04091
Policy Entropy: 4.49956
Value Function Loss: 0.00167
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.09336
Collected Steps per Second: 30928.88779
Overall Steps per Second: 12237.51408
Timestep Collection Time: 1.61752
Timestep Consumption Time: 2.47057
PPO Batch Consumption Time: 0.63124
Total Iteration Time: 4.08809
Cumulative Model Updates: 1260
Cumulative Timesteps: 21064332
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00112
Policy Entropy: 4.49956
Value Function Loss: 0.00132
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.09351
Collected Steps per Second: 31957.43156
Overall Steps per Second: 12283.63248
Timestep Collection Time: 1.56558
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.62113
Total Iteration Time: 4.07306
Cumulative Model Updates: 1263
Cumulative Timesteps: 21114364
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04278
Policy Entropy: 4.49957
Value Function Loss: 0.00128
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.09734
Collected Steps per Second: 35624.07260
Overall Steps per Second: 13236.89735
Timestep Collection Time: 1.40512
Timestep Consumption Time: 2.37643
PPO Batch Consumption Time: 0.62557
Total Iteration Time: 3.78155
Cumulative Model Updates: 1266
Cumulative Timesteps: 21164420
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00730
Policy Entropy: 4.49957
Value Function Loss: 0.00117
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.09773
Collected Steps per Second: 35399.05772
Overall Steps per Second: 12997.85396
Timestep Collection Time: 1.41416
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.61435
Total Iteration Time: 3.85141
Cumulative Model Updates: 1269
Cumulative Timesteps: 21214480
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00123
Policy Entropy: 4.49958
Value Function Loss: 0.00152
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.08359
Collected Steps per Second: 38143.89075
Overall Steps per Second: 13310.99716
Timestep Collection Time: 1.31198
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.62005
Total Iteration Time: 3.75960
Cumulative Model Updates: 1272
Cumulative Timesteps: 21264524
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00898
Policy Entropy: 4.49959
Value Function Loss: 0.00203
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.08889
Collected Steps per Second: 36258.30224
Overall Steps per Second: 13336.53419
Timestep Collection Time: 1.37910
Timestep Consumption Time: 2.37030
PPO Batch Consumption Time: 0.61261
Total Iteration Time: 3.74940
Cumulative Model Updates: 1275
Cumulative Timesteps: 21314528
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.28965
Policy Entropy: 4.49960
Value Function Loss: 0.00267
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07300
Value Function Update Magnitude: 0.10396
Collected Steps per Second: 34664.08505
Overall Steps per Second: 12416.34509
Timestep Collection Time: 1.44276
Timestep Consumption Time: 2.58516
PPO Batch Consumption Time: 0.62409
Total Iteration Time: 4.02792
Cumulative Model Updates: 1278
Cumulative Timesteps: 21364540
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16795
Policy Entropy: 4.49961
Value Function Loss: 0.00202
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08129
Value Function Update Magnitude: 0.11473
Collected Steps per Second: 35780.96679
Overall Steps per Second: 12946.70378
Timestep Collection Time: 1.39773
Timestep Consumption Time: 2.46519
PPO Batch Consumption Time: 0.62475
Total Iteration Time: 3.86291
Cumulative Model Updates: 1281
Cumulative Timesteps: 21414552
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09333
Policy Entropy: 4.49962
Value Function Loss: 0.00373
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08831
Value Function Update Magnitude: 0.12792
Collected Steps per Second: 31345.53831
Overall Steps per Second: 12231.88882
Timestep Collection Time: 1.59653
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.62908
Total Iteration Time: 4.09127
Cumulative Model Updates: 1284
Cumulative Timesteps: 21464596
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00475
Policy Entropy: 4.49961
Value Function Loss: 0.00355
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09047
Value Function Update Magnitude: 0.14197
Collected Steps per Second: 26827.75373
Overall Steps per Second: 10952.71824
Timestep Collection Time: 1.86404
Timestep Consumption Time: 2.70177
PPO Batch Consumption Time: 0.67608
Total Iteration Time: 4.56581
Cumulative Model Updates: 1287
Cumulative Timesteps: 21514604
Timesteps Collected: 50008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01202
Policy Entropy: 4.49960
Value Function Loss: 0.00471
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10222
Value Function Update Magnitude: 0.16502
Collected Steps per Second: 30345.61966
Overall Steps per Second: 11919.81630
Timestep Collection Time: 1.64821
Timestep Consumption Time: 2.54783
PPO Batch Consumption Time: 0.66108
Total Iteration Time: 4.19604
Cumulative Model Updates: 1290
Cumulative Timesteps: 21564620
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00887
Policy Entropy: 4.49958
Value Function Loss: 0.00284
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10565
Value Function Update Magnitude: 0.15849
Collected Steps per Second: 29224.74859
Overall Steps per Second: 11814.72577
Timestep Collection Time: 1.71156
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.61763
Total Iteration Time: 4.23370
Cumulative Model Updates: 1293
Cumulative Timesteps: 21614640
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00146
Policy Entropy: 4.49956
Value Function Loss: 0.00309
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10287
Value Function Update Magnitude: 0.13959
Collected Steps per Second: 36922.34661
Overall Steps per Second: 13144.44464
Timestep Collection Time: 1.35452
Timestep Consumption Time: 2.45028
PPO Batch Consumption Time: 0.61272
Total Iteration Time: 3.80480
Cumulative Model Updates: 1296
Cumulative Timesteps: 21664652
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00770
Policy Entropy: 4.49955
Value Function Loss: 0.00292
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09414
Value Function Update Magnitude: 0.12590
Collected Steps per Second: 34826.23671
Overall Steps per Second: 13155.63163
Timestep Collection Time: 1.43696
Timestep Consumption Time: 2.36704
PPO Batch Consumption Time: 0.61213
Total Iteration Time: 3.80400
Cumulative Model Updates: 1299
Cumulative Timesteps: 21714696
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15939
Policy Entropy: 4.49954
Value Function Loss: 0.00271
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09074
Value Function Update Magnitude: 0.12442
Collected Steps per Second: 34055.30491
Overall Steps per Second: 12425.91425
Timestep Collection Time: 1.46867
Timestep Consumption Time: 2.55647
PPO Batch Consumption Time: 0.64714
Total Iteration Time: 4.02514
Cumulative Model Updates: 1302
Cumulative Timesteps: 21764712
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00073
Policy Entropy: 4.49954
Value Function Loss: 0.00341
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08880
Value Function Update Magnitude: 0.11864
Collected Steps per Second: 30434.45820
Overall Steps per Second: 11885.28958
Timestep Collection Time: 1.64419
Timestep Consumption Time: 2.56606
PPO Batch Consumption Time: 0.64792
Total Iteration Time: 4.21025
Cumulative Model Updates: 1305
Cumulative Timesteps: 21814752
Timesteps Collected: 50040
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02076
Policy Entropy: 4.49953
Value Function Loss: 0.00340
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08793
Value Function Update Magnitude: 0.10858
Collected Steps per Second: 32916.51760
Overall Steps per Second: 12763.14072
Timestep Collection Time: 1.51997
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.61873
Total Iteration Time: 3.92004
Cumulative Model Updates: 1308
Cumulative Timesteps: 21864784
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01219
Policy Entropy: 4.49952
Value Function Loss: 0.00385
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08998
Value Function Update Magnitude: 0.11165
Collected Steps per Second: 31444.72922
Overall Steps per Second: 12538.42567
Timestep Collection Time: 1.59111
Timestep Consumption Time: 2.39918
PPO Batch Consumption Time: 0.62387
Total Iteration Time: 3.99029
Cumulative Model Updates: 1311
Cumulative Timesteps: 21914816
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13430
Policy Entropy: 4.49952
Value Function Loss: 0.00250
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08809
Value Function Update Magnitude: 0.11635
Collected Steps per Second: 33036.51932
Overall Steps per Second: 12725.39499
Timestep Collection Time: 1.51505
Timestep Consumption Time: 2.41819
PPO Batch Consumption Time: 0.65524
Total Iteration Time: 3.93324
Cumulative Model Updates: 1314
Cumulative Timesteps: 21964868
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00103
Policy Entropy: 4.49951
Value Function Loss: 0.00155
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08296
Value Function Update Magnitude: 0.12702
Collected Steps per Second: 30730.44993
Overall Steps per Second: 12016.93299
Timestep Collection Time: 1.62731
Timestep Consumption Time: 2.53415
PPO Batch Consumption Time: 0.63583
Total Iteration Time: 4.16146
Cumulative Model Updates: 1317
Cumulative Timesteps: 22014876
Timesteps Collected: 50008
--------END ITERATION REPORT--------
Saving checkpoint 22014876...
Checkpoint 22014876 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01382
Policy Entropy: 4.49951
Value Function Loss: 0.00163
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07717
Value Function Update Magnitude: 0.10865
Collected Steps per Second: 24921.89441
Overall Steps per Second: 10969.25071
Timestep Collection Time: 2.00803
Timestep Consumption Time: 2.55417
PPO Batch Consumption Time: 0.67947
Total Iteration Time: 4.56221
Cumulative Model Updates: 1320
Cumulative Timesteps: 22064920
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00463
Policy Entropy: 4.49950
Value Function Loss: 0.00117
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07178
Value Function Update Magnitude: 0.09453
Collected Steps per Second: 27271.83149
Overall Steps per Second: 11306.34445
Timestep Collection Time: 1.83413
Timestep Consumption Time: 2.58994
PPO Batch Consumption Time: 0.68610
Total Iteration Time: 4.42406
Cumulative Model Updates: 1323
Cumulative Timesteps: 22114940
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00428
Policy Entropy: 4.49949
Value Function Loss: 0.00222
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06906
Value Function Update Magnitude: 0.09440
Collected Steps per Second: 29685.57613
Overall Steps per Second: 11833.51992
Timestep Collection Time: 1.68648
Timestep Consumption Time: 2.54422
PPO Batch Consumption Time: 0.66066
Total Iteration Time: 4.23069
Cumulative Model Updates: 1326
Cumulative Timesteps: 22165004
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00225
Policy Entropy: 4.49948
Value Function Loss: 0.00175
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.09798
Collected Steps per Second: 28072.83914
Overall Steps per Second: 12290.41955
Timestep Collection Time: 1.78365
Timestep Consumption Time: 2.29042
PPO Batch Consumption Time: 0.61047
Total Iteration Time: 4.07407
Cumulative Model Updates: 1329
Cumulative Timesteps: 22215076
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01629
Policy Entropy: 4.49946
Value Function Loss: 0.00183
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07037
Value Function Update Magnitude: 0.09587
Collected Steps per Second: 35036.83193
Overall Steps per Second: 13344.43053
Timestep Collection Time: 1.42707
Timestep Consumption Time: 2.31981
PPO Batch Consumption Time: 0.61233
Total Iteration Time: 3.74688
Cumulative Model Updates: 1332
Cumulative Timesteps: 22265076
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00381
Policy Entropy: 4.49945
Value Function Loss: 0.00121
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.09854
Collected Steps per Second: 38061.05994
Overall Steps per Second: 13641.56925
Timestep Collection Time: 1.31568
Timestep Consumption Time: 2.35516
PPO Batch Consumption Time: 0.62085
Total Iteration Time: 3.67084
Cumulative Model Updates: 1335
Cumulative Timesteps: 22315152
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00002
Policy Entropy: 4.49944
Value Function Loss: 0.00156
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.10651
Collected Steps per Second: 35617.82982
Overall Steps per Second: 13537.55870
Timestep Collection Time: 1.40514
Timestep Consumption Time: 2.29183
PPO Batch Consumption Time: 0.61725
Total Iteration Time: 3.69697
Cumulative Model Updates: 1338
Cumulative Timesteps: 22365200
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00497
Policy Entropy: 4.49944
Value Function Loss: 0.00142
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07167
Value Function Update Magnitude: 0.11369
Collected Steps per Second: 35673.87766
Overall Steps per Second: 13290.68441
Timestep Collection Time: 1.40248
Timestep Consumption Time: 2.36196
PPO Batch Consumption Time: 0.62212
Total Iteration Time: 3.76444
Cumulative Model Updates: 1341
Cumulative Timesteps: 22415232
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01032
Policy Entropy: 4.49946
Value Function Loss: 0.00121
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.11341
Collected Steps per Second: 36229.05398
Overall Steps per Second: 13544.25269
Timestep Collection Time: 1.38077
Timestep Consumption Time: 2.31260
PPO Batch Consumption Time: 0.60986
Total Iteration Time: 3.69337
Cumulative Model Updates: 1344
Cumulative Timesteps: 22465256
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00192
Policy Entropy: 4.49948
Value Function Loss: 0.00148
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07070
Value Function Update Magnitude: 0.10331
Collected Steps per Second: 35318.57172
Overall Steps per Second: 13612.08520
Timestep Collection Time: 1.41569
Timestep Consumption Time: 2.25752
PPO Batch Consumption Time: 0.61204
Total Iteration Time: 3.67321
Cumulative Model Updates: 1347
Cumulative Timesteps: 22515256
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03361
Policy Entropy: 4.49951
Value Function Loss: 0.00228
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.10805
Collected Steps per Second: 35975.56860
Overall Steps per Second: 13399.95375
Timestep Collection Time: 1.39128
Timestep Consumption Time: 2.34396
PPO Batch Consumption Time: 0.61554
Total Iteration Time: 3.73524
Cumulative Model Updates: 1350
Cumulative Timesteps: 22565308
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01219
Policy Entropy: 4.49954
Value Function Loss: 0.00394
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08215
Value Function Update Magnitude: 0.13360
Collected Steps per Second: 37094.94736
Overall Steps per Second: 13476.81854
Timestep Collection Time: 1.34789
Timestep Consumption Time: 2.36218
PPO Batch Consumption Time: 0.62779
Total Iteration Time: 3.71007
Cumulative Model Updates: 1353
Cumulative Timesteps: 22615308
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02170
Policy Entropy: 4.49955
Value Function Loss: 0.00311
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09114
Value Function Update Magnitude: 0.14884
Collected Steps per Second: 35499.13139
Overall Steps per Second: 13520.53741
Timestep Collection Time: 1.40849
Timestep Consumption Time: 2.28959
PPO Batch Consumption Time: 0.62601
Total Iteration Time: 3.69808
Cumulative Model Updates: 1356
Cumulative Timesteps: 22665308
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13544
Policy Entropy: 4.49955
Value Function Loss: 0.00480
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09808
Value Function Update Magnitude: 0.14348
Collected Steps per Second: 32271.38212
Overall Steps per Second: 12571.27739
Timestep Collection Time: 1.55023
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.63371
Total Iteration Time: 3.97955
Cumulative Model Updates: 1359
Cumulative Timesteps: 22715336
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01076
Policy Entropy: 4.49954
Value Function Loss: 0.00492
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09889
Value Function Update Magnitude: 0.15617
Collected Steps per Second: 32168.82752
Overall Steps per Second: 12887.24504
Timestep Collection Time: 1.55579
Timestep Consumption Time: 2.32774
PPO Batch Consumption Time: 0.63383
Total Iteration Time: 3.88353
Cumulative Model Updates: 1362
Cumulative Timesteps: 22765384
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00001
Policy Entropy: 4.49954
Value Function Loss: 0.00406
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10670
Value Function Update Magnitude: 0.17043
Collected Steps per Second: 34744.00603
Overall Steps per Second: 12847.17458
Timestep Collection Time: 1.44071
Timestep Consumption Time: 2.45556
PPO Batch Consumption Time: 0.63647
Total Iteration Time: 3.89627
Cumulative Model Updates: 1365
Cumulative Timesteps: 22815440
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16470
Policy Entropy: 4.49955
Value Function Loss: 0.00228
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10389
Value Function Update Magnitude: 0.16255
Collected Steps per Second: 31416.42977
Overall Steps per Second: 12411.30455
Timestep Collection Time: 1.59152
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.62782
Total Iteration Time: 4.02859
Cumulative Model Updates: 1368
Cumulative Timesteps: 22865440
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00419
Policy Entropy: 4.49955
Value Function Loss: 0.00124
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08708
Value Function Update Magnitude: 0.11963
Collected Steps per Second: 33791.10247
Overall Steps per Second: 13170.42866
Timestep Collection Time: 1.47980
Timestep Consumption Time: 2.31689
PPO Batch Consumption Time: 0.62420
Total Iteration Time: 3.79669
Cumulative Model Updates: 1371
Cumulative Timesteps: 22915444
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.50059
Policy Entropy: 4.49956
Value Function Loss: 0.00248
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07716
Value Function Update Magnitude: 0.10570
Collected Steps per Second: 31684.81570
Overall Steps per Second: 12470.36906
Timestep Collection Time: 1.57893
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.62777
Total Iteration Time: 4.01175
Cumulative Model Updates: 1374
Cumulative Timesteps: 22965472
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01211
Policy Entropy: 4.49956
Value Function Loss: 0.00205
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07672
Value Function Update Magnitude: 0.11495
Collected Steps per Second: 35958.29102
Overall Steps per Second: 13537.18701
Timestep Collection Time: 1.39217
Timestep Consumption Time: 2.30579
PPO Batch Consumption Time: 0.62631
Total Iteration Time: 3.69796
Cumulative Model Updates: 1377
Cumulative Timesteps: 23015532
Timesteps Collected: 50060
--------END ITERATION REPORT--------
Saving checkpoint 23015532...
Checkpoint 23015532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00210
Policy Entropy: 4.49956
Value Function Loss: 0.00213
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07967
Value Function Update Magnitude: 0.12214
Collected Steps per Second: 35363.93426
Overall Steps per Second: 12820.32763
Timestep Collection Time: 1.41489
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.63627
Total Iteration Time: 3.90286
Cumulative Model Updates: 1380
Cumulative Timesteps: 23065568
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00147
Policy Entropy: 4.49955
Value Function Loss: 0.00120
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07695
Value Function Update Magnitude: 0.11629
Collected Steps per Second: 36437.25128
Overall Steps per Second: 13253.34757
Timestep Collection Time: 1.37442
Timestep Consumption Time: 2.40425
PPO Batch Consumption Time: 0.63336
Total Iteration Time: 3.77867
Cumulative Model Updates: 1383
Cumulative Timesteps: 23115648
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01282
Policy Entropy: 4.49954
Value Function Loss: 0.00092
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07401
Value Function Update Magnitude: 0.10604
Collected Steps per Second: 34076.49428
Overall Steps per Second: 12984.38444
Timestep Collection Time: 1.46823
Timestep Consumption Time: 2.38502
PPO Batch Consumption Time: 0.64304
Total Iteration Time: 3.85324
Cumulative Model Updates: 1386
Cumulative Timesteps: 23165680
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02425
Policy Entropy: 4.49952
Value Function Loss: 0.00059
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.08634
Collected Steps per Second: 31285.56070
Overall Steps per Second: 12425.73294
Timestep Collection Time: 1.59882
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.62086
Total Iteration Time: 4.02552
Cumulative Model Updates: 1389
Cumulative Timesteps: 23215700
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03529
Policy Entropy: 4.49951
Value Function Loss: 0.00064
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.07296
Collected Steps per Second: 33396.35604
Overall Steps per Second: 13124.25855
Timestep Collection Time: 1.49849
Timestep Consumption Time: 2.31460
PPO Batch Consumption Time: 0.62738
Total Iteration Time: 3.81309
Cumulative Model Updates: 1392
Cumulative Timesteps: 23265744
Timesteps Collected: 50044
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00982
Policy Entropy: 4.49951
Value Function Loss: 0.00087
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.06693
Collected Steps per Second: 32706.11716
Overall Steps per Second: 12734.96479
Timestep Collection Time: 1.53048
Timestep Consumption Time: 2.40012
PPO Batch Consumption Time: 0.64110
Total Iteration Time: 3.93060
Cumulative Model Updates: 1395
Cumulative Timesteps: 23315800
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01560
Policy Entropy: 4.49952
Value Function Loss: 0.00092
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.06966
Collected Steps per Second: 33101.10267
Overall Steps per Second: 12584.16432
Timestep Collection Time: 1.51113
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.62441
Total Iteration Time: 3.97484
Cumulative Model Updates: 1398
Cumulative Timesteps: 23365820
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04007
Policy Entropy: 4.49954
Value Function Loss: 0.00223
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.08514
Collected Steps per Second: 33206.77494
Overall Steps per Second: 13230.30683
Timestep Collection Time: 1.50632
Timestep Consumption Time: 2.27439
PPO Batch Consumption Time: 0.61023
Total Iteration Time: 3.78071
Cumulative Model Updates: 1401
Cumulative Timesteps: 23415840
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01038
Policy Entropy: 4.49956
Value Function Loss: 0.00299
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.11516
Collected Steps per Second: 34566.53687
Overall Steps per Second: 12740.18758
Timestep Collection Time: 1.44718
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.65327
Total Iteration Time: 3.92647
Cumulative Model Updates: 1404
Cumulative Timesteps: 23465864
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01248
Policy Entropy: 4.49957
Value Function Loss: 0.00217
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08061
Value Function Update Magnitude: 0.13587
Collected Steps per Second: 31071.72726
Overall Steps per Second: 12446.13413
Timestep Collection Time: 1.61072
Timestep Consumption Time: 2.41044
PPO Batch Consumption Time: 0.63508
Total Iteration Time: 4.02117
Cumulative Model Updates: 1407
Cumulative Timesteps: 23515912
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01408
Policy Entropy: 4.49958
Value Function Loss: 0.00112
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08042
Value Function Update Magnitude: 0.12596
Collected Steps per Second: 31707.88353
Overall Steps per Second: 12702.09885
Timestep Collection Time: 1.57853
Timestep Consumption Time: 2.36192
PPO Batch Consumption Time: 0.62830
Total Iteration Time: 3.94045
Cumulative Model Updates: 1410
Cumulative Timesteps: 23565964
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01175
Policy Entropy: 4.49959
Value Function Loss: 0.00027
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06687
Value Function Update Magnitude: 0.10106
Collected Steps per Second: 28886.69513
Overall Steps per Second: 11731.44650
Timestep Collection Time: 1.73145
Timestep Consumption Time: 2.53196
PPO Batch Consumption Time: 0.65180
Total Iteration Time: 4.26341
Cumulative Model Updates: 1413
Cumulative Timesteps: 23615980
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16021
Policy Entropy: 4.49960
Value Function Loss: 0.00217
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.08911
Collected Steps per Second: 30137.90869
Overall Steps per Second: 12344.09707
Timestep Collection Time: 1.66063
Timestep Consumption Time: 2.39377
PPO Batch Consumption Time: 0.63857
Total Iteration Time: 4.05441
Cumulative Model Updates: 1416
Cumulative Timesteps: 23666028
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02996
Policy Entropy: 4.49960
Value Function Loss: 0.00321
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.09699
Collected Steps per Second: 31291.85834
Overall Steps per Second: 12483.62804
Timestep Collection Time: 1.60003
Timestep Consumption Time: 2.41066
PPO Batch Consumption Time: 0.62061
Total Iteration Time: 4.01069
Cumulative Model Updates: 1419
Cumulative Timesteps: 23716096
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07302
Policy Entropy: 4.49961
Value Function Loss: 0.00367
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08942
Value Function Update Magnitude: 0.12543
Collected Steps per Second: 37223.92339
Overall Steps per Second: 13644.07088
Timestep Collection Time: 1.34505
Timestep Consumption Time: 2.32453
PPO Batch Consumption Time: 0.61010
Total Iteration Time: 3.66958
Cumulative Model Updates: 1422
Cumulative Timesteps: 23766164
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17728
Policy Entropy: 4.49960
Value Function Loss: 0.00407
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09786
Value Function Update Magnitude: 0.13847
Collected Steps per Second: 35918.08194
Overall Steps per Second: 13642.36697
Timestep Collection Time: 1.39250
Timestep Consumption Time: 2.27372
PPO Batch Consumption Time: 0.61459
Total Iteration Time: 3.66623
Cumulative Model Updates: 1425
Cumulative Timesteps: 23816180
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22119
Policy Entropy: 4.49959
Value Function Loss: 0.00343
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10034
Value Function Update Magnitude: 0.14393
Collected Steps per Second: 34421.32357
Overall Steps per Second: 12900.40477
Timestep Collection Time: 1.45433
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.62719
Total Iteration Time: 3.88050
Cumulative Model Updates: 1428
Cumulative Timesteps: 23866240
Timesteps Collected: 50060
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37372
Policy Entropy: 4.49957
Value Function Loss: 0.00257
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10068
Value Function Update Magnitude: 0.14054
Collected Steps per Second: 36093.40300
Overall Steps per Second: 13490.13157
Timestep Collection Time: 1.38563
Timestep Consumption Time: 2.32168
PPO Batch Consumption Time: 0.63057
Total Iteration Time: 3.70730
Cumulative Model Updates: 1431
Cumulative Timesteps: 23916252
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10624
Policy Entropy: 4.49954
Value Function Loss: 0.00177
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.09199
Value Function Update Magnitude: 0.12441
Collected Steps per Second: 35877.41728
Overall Steps per Second: 13378.94011
Timestep Collection Time: 1.39453
Timestep Consumption Time: 2.34508
PPO Batch Consumption Time: 0.62095
Total Iteration Time: 3.73961
Cumulative Model Updates: 1434
Cumulative Timesteps: 23966284
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02040
Policy Entropy: 4.49952
Value Function Loss: 0.00146
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08252
Value Function Update Magnitude: 0.10748
Collected Steps per Second: 29800.32455
Overall Steps per Second: 11996.21058
Timestep Collection Time: 1.67971
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.63309
Total Iteration Time: 4.17265
Cumulative Model Updates: 1437
Cumulative Timesteps: 24016340
Timesteps Collected: 50056
--------END ITERATION REPORT--------
Saving checkpoint 24016340...
Checkpoint 24016340 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00999
Policy Entropy: 4.49952
Value Function Loss: 0.00173
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07801
Value Function Update Magnitude: 0.10020
Collected Steps per Second: 32596.66989
Overall Steps per Second: 12832.49997
Timestep Collection Time: 1.53549
Timestep Consumption Time: 2.36491
PPO Batch Consumption Time: 0.62742
Total Iteration Time: 3.90041
Cumulative Model Updates: 1440
Cumulative Timesteps: 24066392
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01176
Policy Entropy: 4.49953
Value Function Loss: 0.00136
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07556
Value Function Update Magnitude: 0.09629
Collected Steps per Second: 36323.30193
Overall Steps per Second: 13470.13408
Timestep Collection Time: 1.37785
Timestep Consumption Time: 2.33763
PPO Batch Consumption Time: 0.61882
Total Iteration Time: 3.71548
Cumulative Model Updates: 1443
Cumulative Timesteps: 24116440
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01390
Policy Entropy: 4.49955
Value Function Loss: 0.00193
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07395
Value Function Update Magnitude: 0.09903
Collected Steps per Second: 37882.42538
Overall Steps per Second: 13514.31635
Timestep Collection Time: 1.32040
Timestep Consumption Time: 2.38086
PPO Batch Consumption Time: 0.62099
Total Iteration Time: 3.70126
Cumulative Model Updates: 1446
Cumulative Timesteps: 24166460
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00820
Policy Entropy: 4.49956
Value Function Loss: 0.00224
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07332
Value Function Update Magnitude: 0.10241
Collected Steps per Second: 36491.17286
Overall Steps per Second: 13600.78923
Timestep Collection Time: 1.37107
Timestep Consumption Time: 2.30754
PPO Batch Consumption Time: 0.61470
Total Iteration Time: 3.67861
Cumulative Model Updates: 1449
Cumulative Timesteps: 24216492
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01126
Policy Entropy: 4.49958
Value Function Loss: 0.00252
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07775
Value Function Update Magnitude: 0.10578
Collected Steps per Second: 32327.97249
Overall Steps per Second: 12673.98830
Timestep Collection Time: 1.54813
Timestep Consumption Time: 2.40074
PPO Batch Consumption Time: 0.61962
Total Iteration Time: 3.94888
Cumulative Model Updates: 1452
Cumulative Timesteps: 24266540
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00040
Policy Entropy: 4.49958
Value Function Loss: 0.00159
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07860
Value Function Update Magnitude: 0.11456
Collected Steps per Second: 34457.59513
Overall Steps per Second: 13396.96189
Timestep Collection Time: 1.45199
Timestep Consumption Time: 2.28259
PPO Batch Consumption Time: 0.61474
Total Iteration Time: 3.73458
Cumulative Model Updates: 1455
Cumulative Timesteps: 24316572
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00456
Policy Entropy: 4.49957
Value Function Loss: 0.00062
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07127
Value Function Update Magnitude: 0.10975
Collected Steps per Second: 34460.79007
Overall Steps per Second: 13236.19030
Timestep Collection Time: 1.45174
Timestep Consumption Time: 2.32790
PPO Batch Consumption Time: 0.61386
Total Iteration Time: 3.77964
Cumulative Model Updates: 1458
Cumulative Timesteps: 24366600
Timesteps Collected: 50028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00275
Policy Entropy: 4.49956
Value Function Loss: 0.00017
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.09043
Collected Steps per Second: 33162.43877
Overall Steps per Second: 12680.96547
Timestep Collection Time: 1.51014
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.62390
Total Iteration Time: 3.94923
Cumulative Model Updates: 1461
Cumulative Timesteps: 24416680
Timesteps Collected: 50080
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00343
Policy Entropy: 4.49957
Value Function Loss: 0.00043
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.08606
Collected Steps per Second: 33575.87222
Overall Steps per Second: 13219.19830
Timestep Collection Time: 1.49024
Timestep Consumption Time: 2.29486
PPO Batch Consumption Time: 0.62118
Total Iteration Time: 3.78510
Cumulative Model Updates: 1464
Cumulative Timesteps: 24466716
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00369
Policy Entropy: 4.49958
Value Function Loss: 0.00106
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.06719
Collected Steps per Second: 35496.90507
Overall Steps per Second: 13256.03867
Timestep Collection Time: 1.40959
Timestep Consumption Time: 2.36499
PPO Batch Consumption Time: 0.61971
Total Iteration Time: 3.77458
Cumulative Model Updates: 1467
Cumulative Timesteps: 24516752
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00745
Policy Entropy: 4.49960
Value Function Loss: 0.00088
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.08258
Collected Steps per Second: 36676.74506
Overall Steps per Second: 13238.75373
Timestep Collection Time: 1.36522
Timestep Consumption Time: 2.41700
PPO Batch Consumption Time: 0.63124
Total Iteration Time: 3.78223
Cumulative Model Updates: 1470
Cumulative Timesteps: 24566824
Timesteps Collected: 50072
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01844
Policy Entropy: 4.49962
Value Function Loss: 0.00176
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.09506
Collected Steps per Second: 34224.53651
Overall Steps per Second: 13258.60980
Timestep Collection Time: 1.46281
Timestep Consumption Time: 2.31315
PPO Batch Consumption Time: 0.61997
Total Iteration Time: 3.77596
Cumulative Model Updates: 1473
Cumulative Timesteps: 24616888
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00712
Policy Entropy: 4.49963
Value Function Loss: 0.00235
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.10780
Collected Steps per Second: 32003.25929
Overall Steps per Second: 12490.72851
Timestep Collection Time: 1.56234
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.62880
Total Iteration Time: 4.00297
Cumulative Model Updates: 1476
Cumulative Timesteps: 24666888
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00435
Policy Entropy: 4.49964
Value Function Loss: 0.00212
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07231
Value Function Update Magnitude: 0.12090
Collected Steps per Second: 33379.24728
Overall Steps per Second: 13140.95822
Timestep Collection Time: 1.49890
Timestep Consumption Time: 2.30844
PPO Batch Consumption Time: 0.62443
Total Iteration Time: 3.80733
Cumulative Model Updates: 1479
Cumulative Timesteps: 24716920
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00837
Policy Entropy: 4.49965
Value Function Loss: 0.00183
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07495
Value Function Update Magnitude: 0.11528
Collected Steps per Second: 35397.10197
Overall Steps per Second: 13258.56185
Timestep Collection Time: 1.41311
Timestep Consumption Time: 2.35955
PPO Batch Consumption Time: 0.62675
Total Iteration Time: 3.77266
Cumulative Model Updates: 1482
Cumulative Timesteps: 24766940
Timesteps Collected: 50020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00646
Policy Entropy: 4.49965
Value Function Loss: 0.00213
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07464
Value Function Update Magnitude: 0.12530
Collected Steps per Second: 32809.58592
Overall Steps per Second: 12821.79611
Timestep Collection Time: 1.52443
Timestep Consumption Time: 2.37643
PPO Batch Consumption Time: 0.60990
Total Iteration Time: 3.90086
Cumulative Model Updates: 1485
Cumulative Timesteps: 24816956
Timesteps Collected: 50016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00428
Policy Entropy: 4.49965
Value Function Loss: 0.00192
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07949
Value Function Update Magnitude: 0.11358
Collected Steps per Second: 31358.56802
Overall Steps per Second: 12572.06699
Timestep Collection Time: 1.59548
Timestep Consumption Time: 2.38414
PPO Batch Consumption Time: 0.62793
Total Iteration Time: 3.97962
Cumulative Model Updates: 1488
Cumulative Timesteps: 24866988
Timesteps Collected: 50032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00193
Policy Entropy: 4.49964
Value Function Loss: 0.00234
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08228
Value Function Update Magnitude: 0.11057
Collected Steps per Second: 33443.98212
Overall Steps per Second: 12722.58245
Timestep Collection Time: 1.49504
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.62632
Total Iteration Time: 3.93002
Cumulative Model Updates: 1491
Cumulative Timesteps: 24916988
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00022
Policy Entropy: 4.49962
Value Function Loss: 0.00139
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07502
Value Function Update Magnitude: 0.08854
Collected Steps per Second: 34619.62341
Overall Steps per Second: 12929.27622
Timestep Collection Time: 1.44565
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.64298
Total Iteration Time: 3.87091
Cumulative Model Updates: 1494
Cumulative Timesteps: 24967036
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.36701
Policy Entropy: 4.49962
Value Function Loss: 0.00241
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07223
Value Function Update Magnitude: 0.08983
Collected Steps per Second: 33552.64648
Overall Steps per Second: 13299.61566
Timestep Collection Time: 1.49163
Timestep Consumption Time: 2.27149
PPO Batch Consumption Time: 0.61520
Total Iteration Time: 3.76312
Cumulative Model Updates: 1497
Cumulative Timesteps: 25017084
Timesteps Collected: 50048
--------END ITERATION REPORT--------
Saving checkpoint 25017084...
Checkpoint 25017084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00461
Policy Entropy: 4.49962
Value Function Loss: 0.00174
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07226
Value Function Update Magnitude: 0.11022
Collected Steps per Second: 31156.15626
Overall Steps per Second: 12593.66452
Timestep Collection Time: 1.60482
Timestep Consumption Time: 2.36543
PPO Batch Consumption Time: 0.60888
Total Iteration Time: 3.97025
Cumulative Model Updates: 1500
Cumulative Timesteps: 25067084
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00212
Policy Entropy: 4.49964
Value Function Loss: 0.00186
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08051
Value Function Update Magnitude: 0.12728
Collected Steps per Second: 35821.67174
Overall Steps per Second: 13159.93771
Timestep Collection Time: 1.39759
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.62719
Total Iteration Time: 3.80427
Cumulative Model Updates: 1503
Cumulative Timesteps: 25117148
Timesteps Collected: 50064
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02582
Policy Entropy: 4.49965
Value Function Loss: 0.00187
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08394
Value Function Update Magnitude: 0.12727
Collected Steps per Second: 32140.73714
Overall Steps per Second: 12344.33080
Timestep Collection Time: 1.55777
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.65180
Total Iteration Time: 4.05595
Cumulative Model Updates: 1506
Cumulative Timesteps: 25167216
Timesteps Collected: 50068
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01110
Policy Entropy: 4.49967
Value Function Loss: 0.00192
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08237
Value Function Update Magnitude: 0.11063
Collected Steps per Second: 31807.35194
Overall Steps per Second: 12310.81490
Timestep Collection Time: 1.57360
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.65711
Total Iteration Time: 4.06569
Cumulative Model Updates: 1509
Cumulative Timesteps: 25217268
Timesteps Collected: 50052
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28972
Policy Entropy: 4.49968
Value Function Loss: 0.00285
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08221
Value Function Update Magnitude: 0.10341
Collected Steps per Second: 37315.79145
Overall Steps per Second: 13648.77893
Timestep Collection Time: 1.34002
Timestep Consumption Time: 2.32360
PPO Batch Consumption Time: 0.61152
Total Iteration Time: 3.66362
Cumulative Model Updates: 1512
Cumulative Timesteps: 25267272
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00061
Policy Entropy: 4.49970
Value Function Loss: 0.00215
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08415
Value Function Update Magnitude: 0.11780
Collected Steps per Second: 33490.75226
Overall Steps per Second: 12960.09139
Timestep Collection Time: 1.49331
Timestep Consumption Time: 2.36562
PPO Batch Consumption Time: 0.64754
Total Iteration Time: 3.85892
Cumulative Model Updates: 1515
Cumulative Timesteps: 25317284
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01213
Policy Entropy: 4.49971
Value Function Loss: 0.00150
Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.08304
Value Function Update Magnitude: 0.11388
Collected Steps per Second: 33897.65513
Overall Steps per Second: 13047.16240
Timestep Collection Time: 1.47515
Timestep Consumption Time: 2.35741
PPO Batch Consumption Time: 0.61907
Total Iteration Time: 3.83256
Cumulative Model Updates: 1518
Cumulative Timesteps: 25367288
Timesteps Collected: 50004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01682
Policy Entropy: 4.49971
Value Function Loss: 0.00155
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.07353
Value Function Update Magnitude: 0.11100
Collected Steps per Second: 35710.88966
Overall Steps per Second: 13222.44301
Timestep Collection Time: 1.40081
Timestep Consumption Time: 2.38246
PPO Batch Consumption Time: 0.64560
Total Iteration Time: 3.78326
Cumulative Model Updates: 1521
Cumulative Timesteps: 25417312
Timesteps Collected: 50024
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01141
Policy Entropy: 4.49972
Value Function Loss: 0.00124
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06903
Value Function Update Magnitude: 0.11490
Collected Steps per Second: 33291.87917
Overall Steps per Second: 12887.37485
Timestep Collection Time: 1.50355
Timestep Consumption Time: 2.38056
PPO Batch Consumption Time: 0.61441
Total Iteration Time: 3.88411
Cumulative Model Updates: 1524
Cumulative Timesteps: 25467368
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00536
Policy Entropy: 4.49972
Value Function Loss: 0.00063
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06695
Value Function Update Magnitude: 0.10843
Collected Steps per Second: 35225.15874
Overall Steps per Second: 13241.86911
Timestep Collection Time: 1.42103
Timestep Consumption Time: 2.35910
PPO Batch Consumption Time: 0.61960
Total Iteration Time: 3.78013
Cumulative Model Updates: 1527
Cumulative Timesteps: 25517424
Timesteps Collected: 50056
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00084
Policy Entropy: 4.49972
Value Function Loss: 0.00085
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.08896
Collected Steps per Second: 29829.74814
Overall Steps per Second: 12347.88644
Timestep Collection Time: 1.67873
Timestep Consumption Time: 2.37670
PPO Batch Consumption Time: 0.62840
Total Iteration Time: 4.05543
Cumulative Model Updates: 1530
Cumulative Timesteps: 25567500
Timesteps Collected: 50076
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00046
Policy Entropy: 4.49972
Value Function Loss: 0.00165
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.08126
Collected Steps per Second: 33746.83303
Overall Steps per Second: 12693.20477
Timestep Collection Time: 1.48269
Timestep Consumption Time: 2.45926
PPO Batch Consumption Time: 0.61853
Total Iteration Time: 3.94195
Cumulative Model Updates: 1533
Cumulative Timesteps: 25617536
Timesteps Collected: 50036
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03989
Policy Entropy: 4.49972
Value Function Loss: 0.00159
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.08560
Collected Steps per Second: 36865.50195
Overall Steps per Second: 13373.97996
Timestep Collection Time: 1.35661
Timestep Consumption Time: 2.38289
PPO Batch Consumption Time: 0.62479
Total Iteration Time: 3.73950
Cumulative Model Updates: 1536
Cumulative Timesteps: 25667548
Timesteps Collected: 50012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00275
Policy Entropy: 4.49973
Value Function Loss: 0.00189
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.09253
Collected Steps per Second: 35732.87104
Overall Steps per Second: 13580.60610
Timestep Collection Time: 1.39927
Timestep Consumption Time: 2.28245
PPO Batch Consumption Time: 0.61893
Total Iteration Time: 3.68172
Cumulative Model Updates: 1539
Cumulative Timesteps: 25717548
Timesteps Collected: 50000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05195
Policy Entropy: 4.49973
Value Function Loss: 0.00158
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.11167
Collected Steps per Second: 34309.03079
Overall Steps per Second: 12818.08757
Timestep Collection Time: 1.45874
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.63128
Total Iteration Time: 3.90448
Cumulative Model Updates: 1542
Cumulative Timesteps: 25767596
Timesteps Collected: 50048
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01191
Policy Entropy: 4.49973
Value Function Loss: 0.00169
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.10771
Collected Steps per Second: 29910.85323
Overall Steps per Second: 12278.09388
Timestep Collection Time: 1.67244
Timestep Consumption Time: 2.40181
PPO Batch Consumption Time: 0.64247
Total Iteration Time: 4.07425
Cumulative Model Updates: 1545
Cumulative Timesteps: 25817620
Timesteps Collected: 50024
--------END ITERATION REPORT--------