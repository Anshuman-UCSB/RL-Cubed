{"PPO Batch Consumption Time": 0.6424669424692789, "Cumulative Model Updates": 1545, "Policy Entropy": 4.499730587005615, "Mean KL Divergence": 1.3382108363657608e-06, "Value Function Loss": 0.0016891488727803032, "SB3 Clip Fraction": 0.0, "Policy Update Magnitude": 0.06312700361013412, "Value Function Update Magnitude": 0.10771293938159943, "Cumulative Timesteps": 25817620, "Total Iteration Time": 4.074248046999855, "Timesteps Collected": 50024, "Timestep Collection Time": 1.6724364100000457, "Timestep Consumption Time": 2.4018116369998097, "Collected Steps per Second": 29910.85323238008, "Overall Steps per Second": 12278.093877184541, "Policy Reward": 0.011911130245033975, "_timestamp": 1737766205.8745165, "_runtime": 2426.432415485382, "_step": 515, "_wandb": {"runtime": 2428}}